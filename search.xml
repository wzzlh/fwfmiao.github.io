<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>运行cv2.xfeatures2d.SIFT_create()时报错</title>
    <url>//posts/cv2-erroropencv.html</url>
    <content><![CDATA[<h1 id="异常"><a href="#异常" class="headerlink" title="异常"></a>异常</h1><p>错误代码</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cv2.error: OpenCV(3.4.3) C:\projects\opencv-python\opencv_contrib\modules\xfeatures2d\src\sift.cpp:1207: error: (-213:The function&#x2F;feature is not implemented) This algorithm is patented and is excluded in this configuration; Set OPENCV_ENABLE_NONFREE CMake option and rebuild the library in function &#39;cv::xfeatures2d::SIFT::create&#39;</span><br></pre></td></tr></table></figure>
<p>貌似是该算法被申请了专利还是咋的，将opencv版本退到3.4.2即可解决</p>
<h1 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h1><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pip install opencv-python&#x3D;&#x3D;3.4.2.16</span><br><span class="line">pip install opencv-contrib-python&#x3D;&#x3D;3.4.2.16</span><br></pre></td></tr></table></figure>

<h1 id="附件"><a href="#附件" class="headerlink" title="附件"></a>附件</h1><p>相关连接</p>
<ul>
<li><span class="exturl" data-url="aHR0cHM6Ly93d3cuamlhbnNodS5jb20vcC8wZjgxODVhMTYxNmY=">https://www.jianshu.com/p/0f8185a1616f<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzE2NzA0Ny9hcnRpY2xlL2RldGFpbHMvODI4NDE3NTA=">https://blog.csdn.net/weixin_43167047/article/details/82841750<i class="fa fa-external-link-alt"></i></span></li>
</ul>
]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>OpenCv</tag>
      </tags>
  </entry>
  <entry>
    <title>Github和Hexo配置</title>
    <url>//posts/github-hexo-configuration.html</url>
    <content><![CDATA[<h1 id="安装前提"><a href="#安装前提" class="headerlink" title="安装前提"></a>安装前提</h1><p>安装 Hexo 相当简单。然而在安装前，您必须检查电脑中是否已安装下列应用程序：</p>
<ul>
<li><span class="exturl" data-url="aHR0cHM6Ly9ub2RlanMub3JnL2VuLw==">Node.js<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly9naXQtc2NtLmNvbS8=">Git<i class="fa fa-external-link-alt"></i></span></li>
</ul>
<p>如果您的电脑中已安装 Node.js , Git 的话，那么接下来就要用npm来安装Hexo了</p>
<h2 id="GitHub-Pages-仓库"><a href="#GitHub-Pages-仓库" class="headerlink" title="GitHub Pages 仓库"></a>GitHub Pages 仓库</h2><p>在自己的GitHub账号下创建一个新的仓库，命名为username.github.io（username是你的账号名)。</p>
<p>在这里，要知道，GitHub Pages有两种类型：User/Organization Pages 和 Project Pages，而我所使用的是User Pages。</p>
<p>简单来说，User Pages 与 Project Pages的区别是：</p>
<ol>
<li>User Pages 是用来展示用户的，而 Project Pages 是用来展示项目的。</li>
<li>用于存放 User Pages 的仓库必须使用username.github.io的命名规则，而 Project Pages 则没有特殊的要求。</li>
<li>User Pages 将使用仓库的 master 分支，而 Project Pages 将使用 gh-pages 分支。</li>
<li>User Pages 通过 http(s)://username.github.io 进行访问，而 Projects Pages通过 http(s)://username.github.io/projectname 进行访问。</li>
</ol>
<h2 id="Git"><a href="#Git" class="headerlink" title="Git"></a>Git</h2><h3 id="配置name和email"><a href="#配置name和email" class="headerlink" title="配置name和email"></a>配置name和email</h3><p>当安装完Git应该做的第一件事情就是设置用户名称和邮件地址。这样做很重要，因为每一个Git的提交都会使用这些信息，并且它会写入你的每一次提交中，不可更改：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git config --global user.name &quot;username&quot;</span><br><span class="line">git config --global user.email &quot;username@example.com&quot;</span><br></pre></td></tr></table></figure>

<p>查看git配置可以使用 -l 参数(l 就是 list 的首字母,L的小写):</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git config -l</span><br></pre></td></tr></table></figure>
<p>在某个项目根路径下面可以设置单独的Email与姓名.</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git config user.name &quot;tiemaocsdn&quot;</span><br><span class="line">git config user.email &quot;tiemaocsdn@qq.com&quot;</span><br></pre></td></tr></table></figure>
<h3 id="ssh配置"><a href="#ssh配置" class="headerlink" title="ssh配置"></a>ssh配置</h3><p>查看是否已经有了ssh密钥：cd ~/.ssh</p>
<p>如果没有密钥则不会有此文件夹，有则备份删除</p>
<p>生存密钥：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ssh-keygen -t rsa -C &quot;username@example.com&quot;</span><br></pre></td></tr></table></figure>
<p>按3个回车，密码为空。</p>
<p>最后得到了两个文件：id_rsa和id_rsa.pub</p>
<p>添加密钥到ssh：ssh-add id_rsa</p>
<p>需要之前输入密码。</p>
<p>在github上添加ssh密钥，这要添加的是“id_rsa.pub”里面的公钥</p>
<p>git上进行测试</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ssh git@github.com</span><br></pre></td></tr></table></figure>
<p>返回结果</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">PTY allocation request failed on channel 0  </span><br><span class="line">Hi username! You&#39;ve successfully authenticated, but GitHub does not provide shell access.  </span><br><span class="line">Connection to github.com closed.  </span><br></pre></td></tr></table></figure>

<p>github ssh配置完毕</p>
<h1 id="Hexo安装"><a href="#Hexo安装" class="headerlink" title="Hexo安装"></a>Hexo安装</h1><p>如果上述必备程序已完成，那么接下来即可使用npm完成Hexo的安装</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">npm install -g hexo-cli</span><br></pre></td></tr></table></figure>

<h1 id="Hexo建站"><a href="#Hexo建站" class="headerlink" title="Hexo建站"></a>Hexo建站</h1><p>安装Hexo完成后，Hexo需要在指定的文件夹init初始化，在你喜欢的文件夹内（例如D：\Hexo），点击鼠标右键选择Git bash，输入以下指令：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hexo init</span><br></pre></td></tr></table></figure>
<p>接下来是安装依赖包，该命令会在当前文件夹内建立网站所需要的所有文件：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">npm install</span><br></pre></td></tr></table></figure>
<p>新建完成后，当前文件夹的目录如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">.</span><br><span class="line">├── _config.yml 网站的 配置 信息，您可以在此配置大部分的参数</span><br><span class="line">├── package.json    应用程序的信息</span><br><span class="line">├── scaffolds   模版文件夹。当您新建文章时，Hexo 会根据 scaffold 来建立文件</span><br><span class="line">├── source  资源文件夹是存放用户资源的地方</span><br><span class="line">└── themes  主题文件夹。Hexo 会根据主题来生成静态页面。</span><br></pre></td></tr></table></figure>
<p>现在可以通过下面的命令，搭建到本地预览一下</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hexo generate</span><br><span class="line">hexo server</span><br></pre></td></tr></table></figure>
<p>然后在浏览器输入localhost:4000查看</p>
<p>这个博客只是本地的，别人是浏览不了的，之后需要部署到GitHub上。</p>
<h1 id="Hexo配置"><a href="#Hexo配置" class="headerlink" title="Hexo配置"></a>Hexo配置</h1><p>您可以在 _config.yml 中修改大部份的配置</p>
<p>找到这一个部分</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">deploy:</span><br><span class="line">  type:</span><br></pre></td></tr></table></figure>
<p>然后在github上仓库的ssh地址复制过来，修改后</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">deploy:</span><br><span class="line">  type: git</span><br><span class="line">  repo: 对应仓库的SSH地址（可以在GitHub对应的仓库中复制）</span><br><span class="line">  branch: 分支（User Pages为master，Project Pages为gh-pages）</span><br></pre></td></tr></table></figure>
<p>为了能够使Hexo部署到GitHub上，需要安装一个插件：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">npm install hexo-deployer-git --save</span><br></pre></td></tr></table></figure>
<p>然后通过下面的命令发布到github的仓库上完成部署：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hexo generate</span><br><span class="line">hexo deploy</span><br></pre></td></tr></table></figure>
<h1 id="theme配置"><a href="#theme配置" class="headerlink" title="theme配置"></a>theme配置</h1><p>如果想要使用其他主题，可以使用git clone将别人的主题拷贝到站点目录的\themes下，然后将_config.yml中的theme: landscape改为对应的主题名字</p>
<p>个人推荐一个不错的主题：<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2lpc3NuYW4vaGV4by10aGVtZS1uZXh0">Next<i class="fa fa-external-link-alt"></i></span></p>
<p>详细步骤可以参考<span class="exturl" data-url="aHR0cDovL3RoZW1lLW5leHQuaWlzc25hbi5jb20v">Next官网<i class="fa fa-external-link-alt"></i></span>。</p>
<h1 id="命令"><a href="#命令" class="headerlink" title="命令"></a>命令</h1><p>常用命令</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">npm install -g hexo-cli</span><br><span class="line">hexo init</span><br><span class="line">npm install</span><br><span class="line">hexo generate</span><br><span class="line">hexo server</span><br><span class="line">hexo clean</span><br><span class="line">hexo deploy</span><br></pre></td></tr></table></figure>
<p>其他命令</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hexo new [layout] &lt;title&gt;</span><br><span class="line">hexo publish [layout] &lt;filename&gt;</span><br><span class="line">hexo render &lt;file1&gt; [file2] ...</span><br><span class="line">hexo list &lt;type&gt;</span><br><span class="line">hexo version</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>GitHub</tag>
      </tags>
  </entry>
  <entry>
    <title>Java后端开发学习路线</title>
    <url>//posts/java-learning.html</url>
    <content><![CDATA[<h1 id="Java后端开发学习路线"><a href="#Java后端开发学习路线" class="headerlink" title="Java后端开发学习路线"></a>Java后端开发学习路线</h1><h2 id="1-编程基础"><a href="#1-编程基础" class="headerlink" title="1.编程基础"></a>1.编程基础</h2><h3 id="Java语言"><a href="#Java语言" class="headerlink" title="Java语言"></a>Java语言</h3><ul>
<li><p>语言基础</p>
<ul>
<li>基础语法</li>
<li>面向对象</li>
<li>接口</li>
<li>容器</li>
<li>异常</li>
<li>泛型</li>
<li>反射</li>
<li>注解</li>
<li>I/O</li>
<li>图形化（如Swing）</li>
</ul>
</li>
<li><p>JVM</p>
<ul>
<li>类加载机制</li>
<li>字节码执行机制</li>
<li>jvm内存模型</li>
<li>GC垃圾回收</li>
<li>jvm性能监控与故障定位</li>
<li>jvm调优</li>
</ul>
</li>
<li><p>并发/多线程</p>
<ul>
<li>并发编程基础</li>
<li>线程池</li>
<li>锁</li>
<li>并发容器</li>
<li>原子类</li>
<li>juc并发工具类</li>
</ul>
</li>
</ul>
<h3 id="数据结构和算法"><a href="#数据结构和算法" class="headerlink" title="数据结构和算法"></a>数据结构和算法</h3><ul>
<li><p>数据结构</p>
<ul>
<li>字符串</li>
<li>数组</li>
<li>链表</li>
<li>二叉树</li>
<li>堆、栈、队列</li>
<li>哈希</li>
</ul>
</li>
<li><p>算法</p>
<ul>
<li>查找</li>
<li>排序</li>
<li>贪心</li>
<li>分治</li>
<li>动态规划</li>
<li>回溯</li>
</ul>
</li>
</ul>
<h3 id="计算机网络"><a href="#计算机网络" class="headerlink" title="计算机网络"></a>计算机网络</h3><ul>
<li>ARP协议</li>
<li>IP/ICMP协议</li>
<li>TCP/UDP协议</li>
<li>DNS/HTTP/HTTPS协议</li>
<li>Session/Cookie</li>
</ul>
<h3 id="数据库-SQL"><a href="#数据库-SQL" class="headerlink" title="数据库/SQL"></a>数据库/SQL</h3><ul>
<li>SQL语句书写</li>
<li>SQL语句优化</li>
<li>事务以及隔离级别</li>
<li>索引</li>
<li>锁</li>
</ul>
<h3 id="操作系统"><a href="#操作系统" class="headerlink" title="操作系统"></a>操作系统</h3><ul>
<li>进程/线程</li>
<li>并发/锁</li>
<li>内存管理和调度</li>
<li>I/O原理</li>
</ul>
<h3 id="设计模式"><a href="#设计模式" class="headerlink" title="设计模式"></a>设计模式</h3><ul>
<li>单例</li>
<li>工厂</li>
<li>代理</li>
<li>策略</li>
<li>模板方法</li>
<li>观察者</li>
<li>适配器</li>
<li>责任链</li>
<li>建造者</li>
</ul>
<h2 id="2-开发工具"><a href="#2-开发工具" class="headerlink" title="2.开发工具"></a>2.开发工具</h2><h3 id="集成开发环境"><a href="#集成开发环境" class="headerlink" title="集成开发环境"></a>集成开发环境</h3><ul>
<li>Eclipse</li>
<li>IDEA</li>
<li>VSCode</li>
</ul>
<h3 id="Linux系统"><a href="#Linux系统" class="headerlink" title="Linux系统"></a>Linux系统</h3><ul>
<li>Linux常用命令</li>
<li>基本Shell脚本</li>
</ul>
<h3 id="代码管理工具"><a href="#代码管理工具" class="headerlink" title="代码管理工具"></a>代码管理工具</h3><ul>
<li>Git</li>
<li>SVN</li>
</ul>
<h3 id="项目管理-构建工具"><a href="#项目管理-构建工具" class="headerlink" title="项目管理/构建工具"></a>项目管理/构建工具</h3><ul>
<li>Maven</li>
<li>Gradle</li>
</ul>
<h2 id="3-应用框架"><a href="#3-应用框架" class="headerlink" title="3.应用框架"></a>3.应用框架</h2><h3 id="后端"><a href="#后端" class="headerlink" title="后端"></a>后端</h3><ul>
<li><p>Spring家族</p>
<ul>
<li><p>Spring</p>
<ul>
<li>IOC</li>
<li>AOP</li>
</ul>
</li>
<li><p>SpringMVC</p>
</li>
<li><p>SpringBoot</p>
<ul>
<li><p>自动配置、开箱即用</p>
</li>
<li><p>整合Web</p>
</li>
<li><p>整合数据库（事务问题）</p>
</li>
<li><p>整合权限</p>
<ul>
<li>Shiro</li>
<li>SpringSecurity</li>
</ul>
</li>
<li><p>整合各种中间件</p>
<ul>
<li>缓存</li>
<li>MQ</li>
<li>RPC框架</li>
<li>NIO框架</li>
<li>等。。。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>服务器软件</p>
<ul>
<li><p>Web服务器</p>
<ul>
<li>Nginx</li>
</ul>
</li>
<li><p>应用服务器</p>
<ul>
<li>Tomcat</li>
<li>Jetty</li>
<li>Undertow</li>
</ul>
</li>
</ul>
</li>
<li><p>中间件</p>
<ul>
<li><p>缓存</p>
<ul>
<li><p>Redis</p>
<ul>
<li>5大数据类型</li>
<li>事务</li>
<li>消息通知</li>
<li>管道</li>
<li>持久化</li>
<li>集群</li>
</ul>
</li>
<li><p>memcache</p>
</li>
</ul>
</li>
<li><p>消息队列</p>
<ul>
<li>RocketMQ</li>
<li>RabbitMQ</li>
<li>Kafka</li>
</ul>
</li>
<li><p>RPC架构</p>
<ul>
<li>Dubbo</li>
<li>GRPC</li>
<li>Thrift</li>
<li>SpringCloud</li>
<li>Netty</li>
</ul>
</li>
</ul>
</li>
<li><p>数据库</p>
<ul>
<li><p>ORM层框架</p>
<ul>
<li>MyBatis</li>
<li>Hibernate</li>
<li>JPA</li>
</ul>
</li>
<li><p>连接池</p>
<ul>
<li>Druid</li>
<li>HikariCP</li>
<li>C3P0</li>
</ul>
</li>
<li><p>分库分表</p>
<ul>
<li>MyCat</li>
<li>Sharding-JDBC</li>
<li>Sharding-Sphere</li>
</ul>
</li>
</ul>
</li>
<li><p>搜索引擎</p>
<ul>
<li>Solr</li>
<li>ElasticSearch</li>
</ul>
</li>
<li><p>分布式/微服务</p>
<ul>
<li><p>服务发现/注册</p>
<ul>
<li>Eureka</li>
<li>Consul</li>
<li>Zookeeper</li>
<li>Nacos</li>
</ul>
</li>
<li><p>网关</p>
<ul>
<li>Zuul</li>
<li>Gateway</li>
</ul>
</li>
<li><p>服务调用（负载均衡）</p>
<ul>
<li>Ribbon</li>
<li>Feign</li>
</ul>
</li>
<li><p>熔断/降级</p>
<ul>
<li>Hystrix</li>
</ul>
</li>
<li><p>配置中心</p>
<ul>
<li>Config</li>
<li>Apollo</li>
<li>Nacos</li>
</ul>
</li>
<li><p>认证和鉴权</p>
<ul>
<li>Shiro</li>
<li>SpringSecurity</li>
<li>OAuth2</li>
<li>SSO</li>
</ul>
</li>
<li><p>分布式事务</p>
<ul>
<li><p>JTA接口</p>
<ul>
<li>Atomikos组件</li>
</ul>
</li>
<li><p>2PC、3PC</p>
</li>
<li><p>XA模式</p>
</li>
<li><p>TCC模式</p>
<ul>
<li>tcc-transaction</li>
<li>ByteTCC</li>
<li>EasyTransaction</li>
<li>Seata</li>
</ul>
</li>
<li><p>SAGA模式</p>
<ul>
<li>ServiceComb</li>
<li>Seata</li>
</ul>
</li>
<li><p>LCN模式</p>
<ul>
<li>tx-lcn</li>
</ul>
</li>
</ul>
</li>
<li><p>任务调度</p>
<ul>
<li>Quartz</li>
<li>Elastic-Job</li>
</ul>
</li>
<li><p>链路追踪与监控</p>
<ul>
<li>Zipkin</li>
<li>Sleuth</li>
<li>Skywalking</li>
</ul>
</li>
<li><p>日志分析与监控</p>
<ul>
<li><p>ELK</p>
<ul>
<li>ElasticSearch</li>
<li>Logstash</li>
<li>Kibana</li>
</ul>
</li>
</ul>
</li>
<li><p>虚拟化/容器化</p>
<ul>
<li><p>容器技术</p>
<ul>
<li>Docker</li>
</ul>
</li>
<li><p>容器编排技术</p>
<ul>
<li>Kubernetes</li>
<li>Swarm</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="前端"><a href="#前端" class="headerlink" title="前端"></a>前端</h3><ul>
<li><p>基础套餐</p>
<ul>
<li><p>三大件</p>
<ul>
<li>HTML</li>
<li>Javascript</li>
<li>CSS</li>
</ul>
</li>
<li><p>基础库</p>
<ul>
<li>Jquery</li>
<li>Ajax</li>
</ul>
</li>
</ul>
</li>
<li><p>模板框架</p>
<ul>
<li>JSP/JSTL</li>
<li>Thymeleaf</li>
<li>FreeMarker</li>
</ul>
</li>
<li><p>组件化框架</p>
<ul>
<li>Node</li>
<li>VUE</li>
<li>React</li>
<li>Angular</li>
</ul>
</li>
</ul>
<h2 id="4-运维知识"><a href="#4-运维知识" class="headerlink" title="4.运维知识"></a>4.运维知识</h2><ul>
<li>Web服务器<ul>
<li>Nginx</li>
</ul>
</li>
<li>应用服务器<ul>
<li>Tomcat</li>
<li>Jetty</li>
<li>Undertow</li>
</ul>
</li>
<li>CDN加速</li>
<li>持续集成/持续发布<ul>
<li>Jenkins</li>
</ul>
</li>
<li>代码质量检查<ul>
<li>sonar</li>
</ul>
</li>
<li>日志收集/分析<ul>
<li>ELK</li>
</ul>
</li>
</ul>
<h2 id="5-成神之路"><a href="#5-成神之路" class="headerlink" title="5.成神之路"></a>5.成神之路</h2><ul>
<li>徒手撕源码</li>
<li>光脚造轮子</li>
<li>闭眼深优化</li>
</ul>
<h2 id="6-平稳降落"><a href="#6-平稳降落" class="headerlink" title="6.平稳降落"></a>6.平稳降落</h2><ul>
<li>调节心态、注意健康</li>
<li>虚心学习</li>
<li>持之以恒</li>
</ul>
<p>转自：<span class="exturl" data-url="aHR0cHM6Ly93d3cuYmlsaWJpbGkuY29tL3ZpZGVvL0JWMUdRNHkxTjdIRA==">https://www.bilibili.com/video/BV1GQ4y1N7HD<i class="fa fa-external-link-alt"></i></span></p>
]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
      </tags>
  </entry>
  <entry>
    <title>JDK安装指南</title>
    <url>//posts/jdk-install.html</url>
    <content><![CDATA[<h1 id="JDK"><a href="#JDK" class="headerlink" title="JDK"></a>JDK</h1><h2 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h2><p>首先打开JDK的<span class="exturl" data-url="aHR0cHM6Ly93d3cub3JhY2xlLmNvbS90ZWNobmV0d29yay9qYXZhL2phdmFzZS9kb3dubG9hZHMvaW5kZXguaHRtbA==">下载页面<i class="fa fa-external-link-alt"></i></span></p>
<p><img data-src="jdk-install/01.jpg" alt="JDK"></p>
<p>这里我们选择的是Java SE Development Kit 8u191进行下载使用</p>
<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>下载完毕后，使用下面的命令解压到相应的目录下</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">tar -zxvf .&#x2F;jdk-8u191-linux-x64.tar.gz -C &#x2F;opt</span><br></pre></td></tr></table></figure>

<p>编辑.bashrc文件，将下面的文本添加进环境变量</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#add Java environment</span><br><span class="line">export JAVA_HOME&#x3D;&#x2F;opt&#x2F;jdk1.8.0_201</span><br><span class="line">export JRE_HOME&#x3D;$&#123;JAVA_HOME&#125;&#x2F;jre</span><br><span class="line">export CLASSPATH&#x3D;.:$&#123;JAVA_HOME&#125;&#x2F;lib:$&#123;JRE_HOME&#125;&#x2F;lib</span><br><span class="line">export PATH&#x3D;$&#123;JAVA_HOME&#125;&#x2F;bin:$PATH</span><br></pre></td></tr></table></figure>

<p><img data-src="jdk-install/02.jpg" alt="JAVA版本查看"></p>
<p>然后运行下面的命令，查看JDK是否安装成功</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">java -version</span><br></pre></td></tr></table></figure>

<h2 id="JDK没有JRE"><a href="#JDK没有JRE" class="headerlink" title="JDK没有JRE"></a>JDK没有JRE</h2><p>新版本的JDK（9,10,11,10）没有JRE，可以使用下面的命令，生成JRE模块</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">bin\jlink.exe --module-path jmods --add-modules java.desktop --output jre</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
        <tag>JDK</tag>
      </tags>
  </entry>
  <entry>
    <title>使用Travis持续集成你的Hexo博客</title>
    <url>//posts/travis-continuously-integrate-hexo.html</url>
    <content><![CDATA[<p>之前一直用hexo deploy更新博客，然后用git将hexo的源文件托管到另一个分支或者仓库，虽然这样可以让你能够备份下来hexo的源文件，但是这样实在太麻烦了，需要运行两次命令，还要切换分支什么的，十分麻烦。</p>
<p>后来在网上找到了一个十分简单得方法，就是持续集成</p>
<h1 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h1><p>每次原文件仓库或者分支更新文件后，Travis会把文件从Github上拉取下来，编译成静态文件后，然后直接Push到master的分支或者仓库，完成整个网页的更新。</p>
<h1 id="配置流程"><a href="#配置流程" class="headerlink" title="配置流程"></a>配置流程</h1><h2 id="Travis新建工程"><a href="#Travis新建工程" class="headerlink" title="Travis新建工程"></a>Travis新建工程</h2><p>首先登陆Travis的官网<span class="exturl" data-url="aHR0cHM6Ly93d3cudHJhdmlzLWNpLm9yZy8lRUYlQkMlOEMlRTklODAlODklRTYlOEIlQTklRTUlOEYlQjMlRTQlQjglOEElRTglQTclOTIlRTclOUElODRTaWdu">https://www.travis-ci.org/，选择右上角的Sign<i class="fa fa-external-link-alt"></i></span> in with GitHub登陆。</p>
<p><img data-src="travis-continuously-integrate-hexo/01.jpg" alt="Travis官网"></p>
<p>然后右上角个人头像，选择Setting，Sync Account同步Github上的Repo信息</p>
<p>选择hexo的仓库，也就是 xxxx.github.io，进行启用</p>
<p>选择Github登陆即可，然后选择 NEW PROJECT ，新建一个项目，选择Github上Hexo的原文件或者分支，我是选择的是2原文件和静态页面在同一个仓库的2个分支。</p>
<p><img data-src="travis-continuously-integrate-hexo/02.jpg" alt="启用工程"></p>
<h2 id="获取AccessToken"><a href="#获取AccessToken" class="headerlink" title="获取AccessToken"></a>获取AccessToken</h2><p>travis.yml文件中需要几个参数，如果之前设置了环境变量，可以通过${xxxx}来表示，比如仓库地址就是${GIT_URL}，因为这个travis.yml直接保存到Github上面的，直接写密码肯定是不行的，所以可以使用有授权的AccessToken保存到里面。</p>
<p>可以<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL3NldHRpbmdzL3Rva2Vucw==">点击这里<i class="fa fa-external-link-alt"></i></span>，进入Personal access tokens页面，然后点击Generate new token，获取一个新的token，Token description任意填写，下方的选项中全选repo即可。</p>
<p>将生成token保存起来，下面的流程会用到</p>
<h2 id="配置travis环境变量"><a href="#配置travis环境变量" class="headerlink" title="配置travis环境变量"></a>配置travis环境变量</h2><p>然后选择后面的Setting按钮，在Environment Variables栏下配置环境变量</p>
<p>填写完后保存，然后进入Environment设置，设置下面的环境变量，在之后配置.travis.yml文件会用到。</p>
<table>
<thead>
<tr>
<th>环境变量名</th>
<th>环境变量值</th>
<th>示例</th>
</tr>
</thead>
<tbody><tr>
<td>GIT_URL</td>
<td>仓库地址</td>
<td>github.com/fwfmiao/fwfmiao.github.io.git</td>
</tr>
<tr>
<td>GIT_USER_EMAIL</td>
<td>Github的用户邮箱</td>
<td><span class="exturl" data-url="bWFpbHRvOiYjMTIwOyYjMTIwOyYjMTIwOyYjeDc4OyYjNjQ7JiMxMjA7JiMxMjA7JiMxMjA7JiN4MmU7JiM5OTsmI3g2ZjsmI3g2ZDs=">&#120;&#120;&#120;&#x78;&#64;&#120;&#120;&#120;&#x2e;&#99;&#x6f;&#x6d;<i class="fa fa-external-link-alt"></i></span></td>
</tr>
<tr>
<td>GIT_USER_NAME</td>
<td>Github的用户名</td>
<td>fwfmiao</td>
</tr>
<tr>
<td>ACCESS_TOKEN</td>
<td>ACCESS_TOKEN</td>
<td>xxxxxxxxxxxxx</td>
</tr>
<tr>
<td>SOURCE_BRANCH</td>
<td>编译源代码</td>
<td>hexo</td>
</tr>
<tr>
<td>TARGET_BRANCH</td>
<td>编译后静态文件保存的分支</td>
<td>master</td>
</tr>
</tbody></table>
<p><img data-src="travis-continuously-integrate-hexo/03.jpg" alt="Environment Variables设置"></p>
<p>我填写的情况如下，然后保存。</p>
<h2 id="travis-yml配置"><a href="#travis-yml配置" class="headerlink" title=".travis.yml配置"></a>.travis.yml配置</h2><p>接下来是要把.travis.yml配置到原文件放置的分支根目录下，主要目的是在更新原文件后，能够让Travis按照.travis.yml里面写的内容，然后push到目标分支。</p>
<p>具体配置文件如下</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">language: node_js</span><br><span class="line">node_js: stable</span><br><span class="line"></span><br><span class="line">git:</span><br><span class="line">  depth: 5</span><br><span class="line">  quiet: true</span><br><span class="line"></span><br><span class="line">branches:</span><br><span class="line">  only:</span><br><span class="line">  - hexo</span><br><span class="line"></span><br><span class="line">install:</span><br><span class="line">  - npm install</span><br><span class="line"></span><br><span class="line">cache:</span><br><span class="line">  directories:</span><br><span class="line">    - node_modules</span><br><span class="line"></span><br><span class="line">script:</span><br><span class="line">  - hexo clean</span><br><span class="line">  - hexo generate</span><br><span class="line"></span><br><span class="line">after_success:</span><br><span class="line">  - cd .&#x2F;public</span><br><span class="line">  - git init</span><br><span class="line">  - git config user.name &quot;$&#123;GIT_USER_NAME&#125;&quot;</span><br><span class="line">  - git config user.email &quot;$&#123;GIT_USER_EMAIL&#125;&quot;</span><br><span class="line">  - git add .</span><br><span class="line">  - git commit -m &quot;Update Static Site&quot;</span><br><span class="line">  - git push --force --quiet &quot;https:&#x2F;&#x2F;$&#123;ACCESS_TOKEN&#125;@$&#123;GIT_URL&#125;&quot; $&#123;TARGET_BRANCH&#125;:$&#123;TARGET_BRANCH&#125;</span><br></pre></td></tr></table></figure>
<p>上面大概内容就是将github仓库的hexo分支拉取下来，编译成静态文件后，在push到目标(master)分支。由于Travis环境中是通过Access Token访问我们的仓库的，而Hexo自带的部署则在访问的过程中需要我们输入帐号密码，所以Hexo g -d的命令就不适合在这里使用。需要先编译成静态文件，然后直接把把public文件夹的静态文件push到目标分支。</p>
<h1 id="使用流程"><a href="#使用流程" class="headerlink" title="使用流程"></a>使用流程</h1><p><img data-src="travis-continuously-integrate-hexo/04.jpg" alt=".travis.yml路径"></p>
<p>将.travis.yml放到分支根路径，push上去就可以了。</p>
<p>这时候就可以看到Travis自动运行.travis.yml文件，并进行CONSOLE的打印。</p>
<p><img data-src="travis-continuously-integrate-hexo/05.jpg" alt="CONSOLE的打印"></p>
<p>以后每次只需要对HEXO原代码那个分支进行更新就可以了，他会自动编译成静态文件再发布，十分方便，我们还可以加上一个这个小徽章_(:з」∠)_信仰充值。</p>
<p><a href="https://www.travis-ci.org/fwfmiao/fwfmiao.github.io"><img data-src="https://www.travis-ci.org/fwfmiao/fwfmiao.github.io.svg" alt="Build Status"></a></p>
]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>GitHub</tag>
        <tag>Travis</tag>
      </tags>
  </entry>
  <entry>
    <title>如何在Ubuntu上安装配置Spark</title>
    <url>//posts/ubuntu-spark.html</url>
    <content><![CDATA[<h1 id="版本"><a href="#版本" class="headerlink" title="版本"></a>版本</h1><ul>
<li>JDK: 8u221</li>
<li>Scala: 2.12.9</li>
<li>Hadoop: 3.1.2</li>
<li>Spark: 2.4.4</li>
</ul>
<h1 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h1><p>首先<span class="exturl" data-url="aHR0cDovL3NwYXJrLmFwYWNoZS5vcmcvZG93bmxvYWRzLmh0bWw=">点击这里<i class="fa fa-external-link-alt"></i></span>，进入Spark官网下载页面。</p>
<p><img data-src="ubuntu-spark/01.jpg" alt="Spark下载页面"></p>
<p>选择下载版本，以及Hadoop版本，然后点击tgz地址进行下载</p>
<p><img data-src="ubuntu-spark/02.jpg" alt="Spark镜像选择页面"></p>
<p>选中官方推荐的地址即可下载，其他地址也可用（建议采用迅雷等下载工具下载，速度比较会快很多，上传至UBUNTU系统）</p>
<p>或者使用<code>wget</code>命令进行下载</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">wget http:&#x2F;&#x2F;mirror.bit.edu.cn&#x2F;apache&#x2F;spark&#x2F;spark-2.4.4&#x2F;spark-2.4.4-bin-hadoop2.7.tgz</span><br></pre></td></tr></table></figure>

<h1 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h1><p>Spark部署模式总共有下面就几种</p>
<ul>
<li>local模式(单机模式)<ul>
<li>local</li>
<li>local[k]</li>
<li>local[*]</li>
</ul>
</li>
<li>cluster模式(多机模式)<ul>
<li>standalone</li>
<li>mesos</li>
<li>yarn<ul>
<li>yarn cluster</li>
<li>yarn client</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>cluster模式肯定就是运行很多机器上了，但是它又分为以下三种模式，区别在于谁去管理资源调度。（说白了，就好像后勤管家，哪里需要资源，后勤管家要负责调度这些资源）</p>
<p>yarn模式又分为yarn cluster模式和yarn client模式：</p>
<ul>
<li>yarn cluster: 这个就是生产环境常用的模式，所有的资源调度和计算都在集群环境上运行。</li>
<li>yarn client: 这个是说Spark Driver和ApplicationMaster进程均在本机运行，而计算任务在cluster上。</li>
</ul>
<h2 id="单机模式"><a href="#单机模式" class="headerlink" title="单机模式"></a>单机模式</h2><p>local模式就是运行在一台计算机上的模式，通常就是用于在本机上练手和测试。它可以通过以下集中方式设置master。可以不进行任何配置，直接使用local部署模式运行</p>
<ul>
<li>local: 所有计算都运行在一个线程当中，没有任何并行计算，通常我们在本机执行一些测试代码，或者练手，就用这种模式。</li>
<li>local[K]: 指定使用几个线程来运行计算，比如local[4]就是运行4个worker线程。通常我们的cpu有几个core，就指定几个线程，最大化利用cpu的计算能力</li>
<li>local[*]: 这种模式直接帮你按照cpu最多cores来设置线程数了。</li>
</ul>
<h2 id="Standalone模式"><a href="#Standalone模式" class="headerlink" title="Standalone模式"></a>Standalone模式</h2><p>下载完毕后，使用下面的命令，将hadoop解压出来，并移动到合适的位置，我解压到了<code>/opt</code>目录下</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">tar -zxvf .&#x2F;spark-2.4.4-bin-hadoop2.7.tgz  -C &#x2F;opt</span><br></pre></td></tr></table></figure>

<p>之后，需要配置以下的环境变量</p>
<p>使用vi命令编辑<code>vi /etc/profile</code>，添加下面的环境变量</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># SPARK</span><br><span class="line">export SPARK_HOME&#x3D;&#x2F;opt&#x2F;spark-2.4.4</span><br><span class="line">export PATH&#x3D;$&#123;SPARK_HOME&#125;&#x2F;bin:$&#123;SPARK_HOME&#125;&#x2F;sbin:$PATH</span><br></pre></td></tr></table></figure>

<p>添加完毕保存后，使用<code>source /etc/profile</code>更新环境变量</p>
<p>下面我们来验证一下看spark是否能正常启动</p>
<p>打开<code>/opt/spark-2.4.4/conf/</code>这个目录，使用<code>cp spark-env.sh.template spark-env.sh</code>，在最后端加入下面的参数</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">export JAVA_HOME&#x3D;&#x2F;opt&#x2F;jdk1.8.0_221</span><br><span class="line">export SCALA_HOME&#x3D;&#x2F;opt&#x2F;scala-2.12.9</span><br><span class="line">export SPARK_HOME&#x3D;&#x2F;opt&#x2F;spark-2.4.4</span><br><span class="line">export HADOOP_HOME&#x3D;&#x2F;opt&#x2F;hadoop-3.1.2</span><br><span class="line">export HADOOP_CONF_DIR&#x3D;&#x2F;opt&#x2F;hadoop-3.1.2&#x2F;etc&#x2F;hadoop</span><br><span class="line">export YARN_CONF_DIR&#x3D;&#x2F;opt&#x2F;hadoop-3.1.2&#x2F;etc&#x2F;hadoop</span><br><span class="line">export SPARK_MASTER_IP&#x3D;master</span><br><span class="line">export SPARK_LOCAL_IP&#x3D;192.168.24.101</span><br><span class="line">export SPARK_WORKER_CORES&#x3D;1</span><br><span class="line">export SPARK_WORKER_MEMORY&#x3D;2g</span><br></pre></td></tr></table></figure>

<p>使用<code>cp slaves.template slaves</code>，然后将所有worker机器节点ip或者域名加入其中 ，单节点使用默认的localhost即可</p>
<h1 id="启动Spark"><a href="#启动Spark" class="headerlink" title="启动Spark"></a>启动Spark</h1><p>之后通过下面的命令启动Spark</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">start-mastar.sh</span><br><span class="line">start-slaves.sh</span><br></pre></td></tr></table></figure>

<p><img data-src="ubuntu-spark/03.jpg" alt="JPS"></p>
<p>启动完毕后可以使用<code>jps</code>命令查看启动的spark进程，如图表示，则说明我们已经将spark安装配置完毕了</p>
<p><img data-src="ubuntu-spark/04.jpg" alt="spark运行图"></p>
<p>可以访问 <span class="exturl" data-url="aHR0cDovL2xvY2FsaG9zdDo4MDg4Lw==">http://localhost:8088<i class="fa fa-external-link-alt"></i></span> 查看所有任务的运行情况</p>
<h1 id="案例测试"><a href="#案例测试" class="headerlink" title="案例测试"></a>案例测试</h1><p>在控制台输入<code>spark-shell</code></p>
<p><img data-src="ubuntu-spark/05.jpg" alt="spark-shell"></p>
<p>情况如图表示，则说明我们已经将spark安装配置完毕了</p>
<h2 id="PI值计算"><a href="#PI值计算" class="headerlink" title="PI值计算"></a>PI值计算</h2><p>可使用下面的命令来计算PI值</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">run-example SparkPi 10</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
        <tag>Spark</tag>
      </tags>
  </entry>
  <entry>
    <title>如何在Windows上安装配置Spark</title>
    <url>//posts/windows-spark.html</url>
    <content><![CDATA[<h1 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h1><ul>
<li>CPU: Intel(R) Core(TM) i7-4710MQ CPU @ 2.50GHz</li>
<li>MEM: 16.0 GB</li>
<li>System: Windows 10 Professional Edition</li>
<li>Spark: 2.4.0</li>
<li>Scala: 2.11.12</li>
</ul>
<blockquote>
<p>从2.0版开始，Spark默认使用Scala 2.11构建。Scala 2.10用户应该下载Spark源包并<span class="exturl" data-url="aHR0cHM6Ly9zcGFyay5hcGFjaGUub3JnL2RvY3MvbGF0ZXN0L2J1aWxkaW5nLXNwYXJrLmh0bWwjYnVpbGRpbmctZm9yLXNjYWxhLTIxMA==">使用Scala 2.10支持<i class="fa fa-external-link-alt"></i></span>构建。</p>
</blockquote>
<h1 id="JDK配置"><a href="#JDK配置" class="headerlink" title="JDK配置"></a>JDK配置</h1><p>关于JDK的安装教程，可以<a href="/posts/jdk-install.html">点击这里</a>查看。</p>
<p>请注意hadoop不能识别空格，如果你安装在<code>C:\Program Files\Java\jdk1.8.0_191</code>这里，你需要将环境变量修改成<code>C:\Progra~1\Java\jdk1.8.0_191</code></p>
<h1 id="Hadoop"><a href="#Hadoop" class="headerlink" title="Hadoop"></a>Hadoop</h1><h2 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h2><p>首先<span class="exturl" data-url="aHR0cHM6Ly9oYWRvb3AuYXBhY2hlLm9yZy9yZWxlYXNlcy5odG1s">点击这里<i class="fa fa-external-link-alt"></i></span>，进入Hadoop官网下载页面。</p>
<blockquote>
<p>在windows下，我们需要hadoop.dll和winutils.exe，hadoop.dll防止报nativeio异常、winutils.exe没有的话报空指针异常<br>可以<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL3N0ZXZlbG91Z2hyYW4vd2ludXRpbHM=">点击这里<i class="fa fa-external-link-alt"></i></span>进行下载</p>
</blockquote>
<p><img data-src="windows-spark/01.jpg" alt="Hadoop下载页面"></p>
<p>选择3.0.3版本进行下载，然后点击binary地址进行下载</p>
<p><img data-src="windows-spark/02.jpg" alt="Hadoop镜像选择页面"></p>
<p>选中官方推荐的地址即可下载，其他地址也可用（建议采用迅雷等下载工具下载，速度比较会快很多）</p>
<h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><p><img data-src="windows-spark/03.jpg" alt="Hadoop放置目录"></p>
<p>将Spark解压到常用软件的目录下，比如我就保存在<code>D:\Programs\hadoop-3.0.3</code>这里，并修改了文件名，方便查看</p>
<p>接下来需要进行环境变量配置，变量如下：</p>
<table>
<thead>
<tr>
<th>变量名</th>
<th>变量值</th>
</tr>
</thead>
<tbody><tr>
<td>HADOOP_HOME</td>
<td>D:\Programs\hadoop-3.0.3</td>
</tr>
<tr>
<td>Path</td>
<td>%HADOOP_HOME%\bin</td>
</tr>
<tr>
<td>Path</td>
<td>%HADOOP_HOME%\sbin</td>
</tr>
</tbody></table>
<blockquote>
<p>注意：path进行添加，而不是新建</p>
</blockquote>
<p>环境变量修改后，我们需要对Hadoop进行参数配置，我配置的是单节点，所以不需要配置hosts</p>
<p>首先打开<code>D:\Programs\hadoop-3.0.3\etc\hadoop</code>这个目录，分别编辑下面几个文件，根据个人需求更改参数：</p>
<p>core-site.xml</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;fs.defaultFS&lt;&#x2F;name&gt;</span><br><span class="line">    &lt;value&gt;hdfs:&#x2F;&#x2F;localhost:9000&lt;&#x2F;value&gt;</span><br><span class="line">  &lt;&#x2F;property&gt;</span><br><span class="line">&lt;&#x2F;configuration&gt;</span><br></pre></td></tr></table></figure>
<table>
<thead>
<tr>
<th>参数</th>
<th>属性值</th>
<th>解释</th>
</tr>
</thead>
<tbody><tr>
<td>fs.defaultFS</td>
<td>hdfs://localhost:9000</td>
<td>hdfs调用端口</td>
</tr>
</tbody></table>
<p>hdfs-site.xml</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.replication&lt;&#x2F;name&gt;</span><br><span class="line">    &lt;value&gt;1&lt;&#x2F;value&gt;</span><br><span class="line">  &lt;&#x2F;property&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.permissions&lt;&#x2F;name&gt;</span><br><span class="line">    &lt;value&gt;false&lt;&#x2F;value&gt;</span><br><span class="line">  &lt;&#x2F;property&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.namenode.name.dir&lt;&#x2F;name&gt;</span><br><span class="line">    &lt;value&gt;file:&#x2F;D:&#x2F;Programs&#x2F;hadoop-3.0.3&#x2F;data&#x2F;namenode&lt;&#x2F;value&gt;</span><br><span class="line">  &lt;&#x2F;property&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.datanode.data.dir&lt;&#x2F;name&gt;</span><br><span class="line">    &lt;value&gt;file:&#x2F;D:&#x2F;Programs&#x2F;hadoop-3.0.3&#x2F;data&#x2F;datanode&lt;&#x2F;value&gt;</span><br><span class="line">  &lt;&#x2F;property&gt;</span><br><span class="line">&lt;&#x2F;configuration&gt;</span><br></pre></td></tr></table></figure>
<table>
<thead>
<tr>
<th>参数</th>
<th>属性值</th>
<th>解释</th>
</tr>
</thead>
<tbody><tr>
<td>dfs.replication</td>
<td>1</td>
<td>分片数量，伪分布式将其配置成1即可</td>
</tr>
<tr>
<td>dfs.permissions</td>
<td>false</td>
<td>是否打开权限检查系统</td>
</tr>
<tr>
<td>dfs.namenode.name.dir</td>
<td>file:/D:/Programs/hadoop-3.0.3/data/namenode</td>
<td>命名空间和事务在本地文件系统永久存储的路径</td>
</tr>
<tr>
<td>dfs.datanode.data.dir</td>
<td>file:/D:/Programs/hadoop-3.0.3/data/datanode</td>
<td>DataNode在本地文件系统中存放块的路径</td>
</tr>
</tbody></table>
<p>yarn-site.xml</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.nodemanager.aux-services&lt;&#x2F;name&gt;</span><br><span class="line">    &lt;value&gt;mapreduce_shuffle&lt;&#x2F;value&gt;</span><br><span class="line">  &lt;&#x2F;property&gt;</span><br><span class="line">&lt;&#x2F;configuration&gt;</span><br></pre></td></tr></table></figure>
<table>
<thead>
<tr>
<th>参数</th>
<th>属性值</th>
<th>解释</th>
</tr>
</thead>
<tbody><tr>
<td>yarn.nodemanager.aux-services</td>
<td>mapreduce_shuffle</td>
<td>NodeManager上运行的附属服务。需配置成mapreduce_shuffle，才可运行MapReduce程序</td>
</tr>
<tr>
<td>yarn.nodemanager.auxservices.mapreduce.shuffle.class</td>
<td>org.apache.hadoop.mapred.ShuffleHandler</td>
<td>是否打开权限检查系统</td>
</tr>
<tr>
<td>yarn.resourcemanager.address</td>
<td>${yarn.resourcemanager.hostname}:8032</td>
<td>ResourceManager 对客户端暴露的地址。客户端通过该地址向RM提交应用程序，杀死应用程序等</td>
</tr>
<tr>
<td>yarn.resourcemanager.scheduler.address</td>
<td>${yarn.resourcemanager.hostname}:8030</td>
<td>ResourceManager对ApplicationMaster暴露的访问地址。ApplicationMaster通过该地址向RM申请资源、释放资源等。</td>
</tr>
<tr>
<td>yarn.resourcemanager.resource-tracker.address</td>
<td>${yarn.resourcemanager.hostname}:8031</td>
<td>ResourceManager 对NodeManager暴露的地址.。NodeManager通过该地址向RM汇报心跳，领取任务等</td>
</tr>
<tr>
<td>yarn.resourcemanager.admin.address</td>
<td>${yarn.resourcemanager.hostname}:8033</td>
<td>ResourceManager 对管理员暴露的访问地址。管理员通过该地址向RM发送管理命令等</td>
</tr>
<tr>
<td>yarn.resourcemanager.webapp.address</td>
<td>${yarn.resourcemanager.hostname}:8088</td>
<td>ResourceManager对外web ui地址。用户可通过该地址在浏览器中查看集群各类信息</td>
</tr>
<tr>
<td>yarn.resourcemanager.scheduler.class</td>
<td>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler</td>
<td>启用的资源调度器主类。目前可用的有FIFO、Capacity Scheduler和Fair Scheduler</td>
</tr>
<tr>
<td>yarn.resourcemanager.resource-tracker.client.thread-count</td>
<td>50</td>
<td>处理来自NodeManager的RPC请求的Handler数目</td>
</tr>
<tr>
<td>yarn.resourcemanager.scheduler.client.thread-count</td>
<td>50</td>
<td>处理来自ApplicationMaster的RPC请求的Handler数目</td>
</tr>
<tr>
<td>yarn.scheduler.minimum-allocation-mb/yarn.scheduler.maximum-allocation-mb</td>
<td>1024/8192</td>
<td>单个可申请的最小/最大内存资源量。比如设置为1024和3072，则运行MapRedce作业时，每个Task最少可申请1024MB内存，最多可申请3072MB内存</td>
</tr>
<tr>
<td>yarn.scheduler.minimum-allocation-vcores/yarn.scheduler.maximum-allocation-vcores</td>
<td>1/32</td>
<td>单个可申请的最小/最大虚拟CPU个数。比如设置为1和4，则运行MapRedce作业时，每个Task最少可申请1个虚拟CPU，最多可申请4个虚拟CPU</td>
</tr>
<tr>
<td>yarn.resourcemanager.nodes.include-path/yarn.resourcemanager.nodes.exclude-path</td>
<td></td>
<td>NodeManager黑白名单。如果发现若干个NodeManager存在问题，比如故障率很高，任务运行失败率高，则可以将之加入黑名单中。注意，这两个配置参数可以动态生效</td>
</tr>
<tr>
<td>yarn.resourcemanager.nodemanagers.heartbeat-interval-ms</td>
<td>1000</td>
<td>NodeManager心跳间隔</td>
</tr>
</tbody></table>
<h2 id="HDFS初始化"><a href="#HDFS初始化" class="headerlink" title="HDFS初始化"></a>HDFS初始化</h2><p>首先需要根据hdfs-site.xml的配置路径，创建文件夹</p>
<p>然后使用下面的命令初始化hdfs</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hdfs namenode -format</span><br></pre></td></tr></table></figure>

<p><img data-src="windows-spark/04.jpg" alt="HDFS format"></p>
<p>格式化完毕后，如图所示，则表示初始化成功</p>
<h2 id="启动Hadoop"><a href="#启动Hadoop" class="headerlink" title="启动Hadoop"></a>启动Hadoop</h2><p>初始化完毕后，我们就可以使用下面的命令启动hadoop了</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">start-dfs</span><br><span class="line">start-yarn</span><br></pre></td></tr></table></figure>

<p><img data-src="windows-spark/05.jpg" alt="hadoop运行图"></p>
<p>如图所示，启动hadoop后会弹出4个窗口</p>
<p><img data-src="windows-spark/06.jpg" alt="hadoop运行图"></p>
<p>可以访问 <span class="exturl" data-url="aHR0cDovL2xvY2FsaG9zdDo4MDg4Lw==">http://localhost:8088<i class="fa fa-external-link-alt"></i></span> 查看所有任务的运行情况</p>
<p><img data-src="windows-spark/07.jpg" alt="hadoop运行图"></p>
<p>可以访问 <span class="exturl" data-url="aHR0cDovL2xvY2FsaG9zdDo5ODcwLw==">http://localhost:9870<i class="fa fa-external-link-alt"></i></span> 查看Hadoop集群(虽然只有一个节点)运行情况</p>
<p>至此整个hadoop就搭建好了</p>
<h2 id="测试Hadoop例子"><a href="#测试Hadoop例子" class="headerlink" title="测试Hadoop例子"></a>测试Hadoop例子</h2><p>我们可以使用一个简单的例子来测试一下hadoop是否能够正常运行</p>
<p>我们从hadoop安装文件夹，启动一个终端，使用下面的命令，计算pi值</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hadoop jar .\share\hadoop\mapreduce\hadoop-mapreduce-examples-3.0.3.jar pi 10 10</span><br></pre></td></tr></table></figure>
<p><img data-src="windows-spark/08.jpg" alt="hadoop pi值计算"></p>
<p>如图所示，我们计算量比较少导致不够精确，但是已经可以成功运算出pi值了</p>
<h1 id="Spark"><a href="#Spark" class="headerlink" title="Spark"></a>Spark</h1><h2 id="下载-1"><a href="#下载-1" class="headerlink" title="下载"></a>下载</h2><p>首先<span class="exturl" data-url="aHR0cDovL3NwYXJrLmFwYWNoZS5vcmcvZG93bmxvYWRzLmh0bWw=">点击这里<i class="fa fa-external-link-alt"></i></span>，进入Spark官网下载页面。</p>
<p><img data-src="windows-spark/09.jpg" alt="Spark下载页面"></p>
<p>选择下载版本，以及Hadoop版本，然后点击tgz地址进行下载</p>
<p><img data-src="windows-spark/10.jpg" alt="Spark镜像选择页面"></p>
<p>选中官方推荐的地址即可下载，其他地址也可用（建议采用迅雷等下载工具下载，速度比较会快很多）</p>
<h2 id="配置-1"><a href="#配置-1" class="headerlink" title="配置"></a>配置</h2><p><img data-src="windows-spark/11.jpg" alt="Spark放置目录"></p>
<p>将Spark解压到常用软件的目录下，比如我就保存在<code>D:\Programs\spark-2.4.0</code>这里，并修改了文件名，方便查看</p>
<p>接下来需要进行环境变量配置，变量如下：</p>
<table>
<thead>
<tr>
<th>变量名</th>
<th>变量值</th>
</tr>
</thead>
<tbody><tr>
<td>SPARK_HOME</td>
<td>D:\Programs\spark-2.4.0</td>
</tr>
<tr>
<td>Path</td>
<td>%SPARK_HOME%\bin</td>
</tr>
</tbody></table>
<blockquote>
<p>注意：path进行添加，而不是新建</p>
</blockquote>
<p>下面我们来验证一下看spark是否能正常启动</p>
<p>在控制台输入<code>spark-shell</code></p>
<p><img data-src="windows-spark/12.jpg" alt="spark-shell"></p>
<p>情况如图表示，则说明我们已经将spark安装配置完毕了</p>
]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>Spark</tag>
        <tag>Windows</tag>
      </tags>
  </entry>
  <entry>
    <title>WIN10 WSL VIM颜色调整</title>
    <url>//posts/wsl-terminal-color.html</url>
    <content><![CDATA[<h1 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h1><p>在win10上装了bash on ubuntu，自配的颜色真是看不清，看到知乎上推荐的molokai配色挺不错的，我们来记录一下解决的过程</p>
<h1 id="教程"><a href="#教程" class="headerlink" title="教程"></a>教程</h1><p>打开bash on ubuntu，运行下面的命令，进入vim的配置文件夹</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd &#x2F;etc&#x2F;vim</span><br></pre></td></tr></table></figure>

<p>从github上clone下molokai的配色方案</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git clone https:&#x2F;&#x2F;github.com&#x2F;tomasr&#x2F;molokai.git</span><br></pre></td></tr></table></figure>

<p>clone完毕后会得到一个molokai，然后运行下面的命令，将colors文件夹拷贝出来，然后就可以删除molokai文件夹了</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cp -rf molokai&#x2F;colors&#x2F; .&#x2F;colors</span><br><span class="line">rm -rf molokai</span><br></pre></td></tr></table></figure>

<p>之后通过编辑vimrc文件</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">vi vimrc</span><br></pre></td></tr></table></figure>

<p>添加</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">colorscheme molokai</span><br></pre></td></tr></table></figure>

<p>然后保存退出就可以了</p>
<h1 id="附件"><a href="#附件" class="headerlink" title="附件"></a>附件</h1><p>相关链接</p>
<ul>
<li><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3p5Y2RzZy9hcnRpY2xlL2RldGFpbHMvNzkwNTc2OTg=">https://blog.csdn.net/zycdsg/article/details/79057698<i class="fa fa-external-link-alt"></i></span></li>
</ul>
]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>Windows</tag>
        <tag>WSL</tag>
      </tags>
  </entry>
  <entry>
    <title>Spark的设计与运行原理</title>
    <url>//posts/spark-learning-1.html</url>
    <content><![CDATA[<h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><h2 id="Spark简介"><a href="#Spark简介" class="headerlink" title="Spark简介"></a>Spark简介</h2><ul>
<li><p>Spark最初由美国加州大学伯克利分校（UC Berkeley）的AMP实验室于2009年开发，是基于内存计算的大数据并行计算框架，可用于构建大型的、低延迟的数据分析应用程序</p>
</li>
<li><p>2013年Spark加入Apache孵化器项目后发展迅猛，如今已成为Apache软件基金会最重要的三大分布式计算系统开源项目之一（Hadoop、Spark、Storm）</p>
</li>
<li><p>Spark在2014年打破了Hadoop保持的基准排序纪录</p>
<ul>
<li>Spark/206个节点/23分钟/100TB数据</li>
<li>Hadoop/2000个节点/72分钟/100TB数据</li>
<li>Spark用十分之一的计算资源，获得了比Hadoop快3倍的速度</li>
</ul>
</li>
</ul>
<p>Spark具有如下几个主要特点：</p>
<ul>
<li>运行速度快：使用DAG执行引擎以支持循环数据流与内存计算</li>
<li>容易使用：支持使用Scala、Java、Python和R语言进行编程，可以通过Spark Shell进行交互式编程 </li>
<li>通用性：Spark提供了完整而强大的技术栈，包括SQL查询、流式计算、机器学习和图算法组件</li>
<li>运行模式多样：可运行于独立的集群模式中，可运行于Hadoop中，也可运行于Amazon EC2等云环境中，并且可以访问HDFS、Cassandra、HBase、Hive等多种数据源 </li>
</ul>
<p>Spark如今已吸引了国内外各大公司的注意，如腾讯、淘宝、百度、亚马逊等公司均不同程度地使用了Spark来构建大数据分析应用，并应用到实际的生产环境中</p>
<p><img data-src="spark-learning-1/image-20191216115039486.png" alt="谷歌趋势：Spark与Hadoop对比"></p>
<h2 id="Scala简介"><a href="#Scala简介" class="headerlink" title="Scala简介"></a>Scala简介</h2><p>Scala是一门现代的多范式编程语言，运行于Java平台（JVM，Java 虚拟机），并兼容现有的Java程序</p>
<p>Scala的特性：</p>
<ul>
<li>Scala具备强大的并发性，支持函数式编程，可以更好地支持分布式系统</li>
<li>Scala语法简洁，能提供优雅的API</li>
</ul>
<p>Scala兼容Java，运行速度快，且能融合到Hadoop生态圈中 </p>
<p>Scala是Spark的主要编程语言，但Spark还支持Java、Python、R作为编程语言</p>
<p>Scala的优势是提供了REPL（Read-Eval-Print Loop，交互式解释器），提高程序开发效率</p>
<p>开发Spark应用程序时，可以采用Scala、Python、Java和R等语言，首选语言是Scala，因为Spark这个软件本身就是使用Scala语言开发的，采用Scala语言编写Spark应用程序，可以获得最好的性能。关于采用哪种语言编写Spark应用程序，这里强调两点：</p>
<p>（1）Java代码太繁琐。在大数据应用场景中，不太适合使用Java，因为，完成同样的任务，Scala只需要一行代码，而Java则可能需要10行代码；而且，Scala语言可以支持交互式编程，大大提高了程序开发效率，而Java则不支持交互式执行，必须编译以后运行。</p>
<p>（2）Python语言并发性能不好。在并发性能方面，Scala要明显优于Python，而且，Scala是静态类型，可以在编译阶段就抛出错误，便于开发大型大数据项目，此外，Scala兼容Java，运行在JVM上，可以直接使用Java中的Hadoop API来和Hadoop进行交互，但是，Python与Hadoop之间的交互非常糟糕，通常都需要第三方库（比如hadoopy）。</p>
<h2 id="Spark与Hadoop的对比"><a href="#Spark与Hadoop的对比" class="headerlink" title="Spark与Hadoop的对比"></a>Spark与Hadoop的对比</h2><p>Hadoop存在如下一些缺点：</p>
<ul>
<li>表达能力有限</li>
<li>磁盘IO开销大</li>
<li>延迟高<ul>
<li>任务之间的衔接涉及IO开销</li>
<li>在前一个任务执行完成之前，其他任务就无法开始，难以胜任复杂、多阶段的计算任务 </li>
</ul>
</li>
</ul>
<p>Spark在借鉴Hadoop MapReduce优点的同时，很好地解决了MapReduce所面临的问题</p>
<p>相比于Hadoop MapReduce，Spark主要具有如下优点：</p>
<ul>
<li>Spark的计算模式也属于MapReduce，但不局限于Map和Reduce操作，还提供了多种数据集操作类型，编程模型比Hadoop MapReduce更灵活</li>
<li>Spark提供了内存计算，可将中间结果放到内存中，对于迭代运算效率更高</li>
</ul>
<p>Spark基于DAG的任务调度执行机制，要优于Hadoop MapReduce的迭代执行机制 </p>
<p><img data-src="spark-learning-1/image-20191216115223578.png" alt="Hadoop与Spark的执行流程对比"></p>
<ul>
<li>使用Hadoop进行迭代计算非常耗资源</li>
<li>Spark将数据载入内存后，之后的迭代计算都可以直接使用内存中的中间结果作运算，避免了从磁盘中频繁读取数据</li>
</ul>
<p><img data-src="spark-learning-1/image-20191216115247761.png" alt="Hadoop与Spark执行逻辑回归的时间对比"></p>
<h1 id="Spark生态系统"><a href="#Spark生态系统" class="headerlink" title="Spark生态系统"></a>Spark生态系统</h1><p>在实际应用中，大数据处理主要包括以下三个类型</p>
<ul>
<li>复杂的批量数据处理：通常时间跨度在数十分钟到数小时之间</li>
<li>基于历史数据的交互式查询：通常时间跨度在数十秒到数分钟之间</li>
<li>基于实时数据流的数据处理：通常时间跨度在数百毫秒到数秒之间</li>
</ul>
<p>当同时存在以上三种场景时，就需要同时部署三种不同的软件</p>
<ul>
<li>比如: MapReduce / Impala / Storm</li>
</ul>
<p>这样做难免会带来一些问题： </p>
<ul>
<li>不同场景之间输入输出数据无法做到无缝共享，通常需要进行数据格式的转换</li>
<li>不同的软件需要不同的开发和维护团队，带来了较高的使用成本</li>
<li>比较难以对同一个集群中的各个系统进行统一的资源协调和分配</li>
</ul>
<ul>
<li>Spark的设计遵循“一个软件栈满足不同应用场景”的理念，逐渐形成了一套完整的生态系统</li>
<li>既能够提供内存计算框架，也可以支持SQL即席查询、实时流式计算、机器学习和图计算等</li>
<li>Spark可以部署在资源管理器YARN之上，提供一站式的大数据解决方案</li>
<li>因此，Spark所提供的生态系统足以应对上述三种场景，即同时支持批处理、交互式查询和流数据处理</li>
</ul>
<p>Spark生态系统已经成为伯克利数据分析软件栈BDAS（Berkeley Data Analytics Stack）的重要组成部分</p>
<p><img data-src="spark-learning-1/image-20191216130245106.png" alt="BDAS架构"></p>
<p>Spark的生态系统主要包含了Spark Core、Spark SQL、Spark Streaming（ Structured Streaming ）、MLLib和GraphX 等组件</p>
<p><img data-src="spark-learning-1/image-20191216130306973.png" alt="Spark生态系统组件的应用场景"></p>
<h1 id="Spark运行架构"><a href="#Spark运行架构" class="headerlink" title="Spark运行架构"></a>Spark运行架构</h1><h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><ul>
<li>RDD：是Resillient Distributed Dataset（弹性分布式数据集）的简称，是分布式内存的一个抽象概念，提供了一种高度受限的共享内存模型</li>
<li>DAG：是Directed Acyclic Graph（有向无环图）的简称，反映RDD之间的依赖关系</li>
<li>Executor：是运行在工作节点（WorkerNode）的一个进程，负责运行Task</li>
<li>应用（Application）：用户编写的Spark应用程序</li>
<li>任务（ Task ）：运行在Executor上的工作单元 </li>
<li>作业（ Job ）：一个作业包含多个RDD及作用于相应RDD上的各种操作</li>
<li>阶段（ Stage ）：是作业的基本调度单位，一个作业会分为多组任务，每组任务被称为阶段，或者也被称为任务集合，代表了一组关联的、相互之间没有Shuffle依赖关系的任务组成的任务集</li>
</ul>
<h2 id="架构设计"><a href="#架构设计" class="headerlink" title="架构设计"></a>架构设计</h2><ul>
<li>Spark运行架构包括集群资源管理器（Cluster Manager）、运行作业任务的工作节点（Worker Node）、每个应用的任务控制节点（Driver）和每个工作节点上负责具体任务的执行进程（Executor）</li>
<li>资源管理器可以自带或Mesos或YARN</li>
</ul>
<p><img data-src="spark-learning-1/image-20191216130651534.png" alt="Spark运行架构"></p>
<ul>
<li>一个应用由一个Driver和若干个作业构成，一个作业由多个阶段构成，一个阶段由多个没有Shuffle关系的任务组成</li>
<li>当执行一个应用时，Driver会向集群管理器申请资源，启动Executor，并向Executor发送应用程序代码和文件，然后在Executor上执行任务，运行结束后，执行结果会返回给Driver，或者写到HDFS或者其他数据库中</li>
</ul>
<p><img data-src="spark-learning-1/image-20191216130723668.png" alt="Spark中各种概念之间的相互关系"></p>
<h2 id="Spark运行基本流程"><a href="#Spark运行基本流程" class="headerlink" title="Spark运行基本流程"></a>Spark运行基本流程</h2><p><img data-src="spark-learning-1/image-20191216130742375.png" alt="Spark运行基本流程图"></p>
<p>SparkContext对象代表了和一个集群的连接</p>
<ol>
<li>首先为应用构建起基本的运行环境，即由Driver创建一个SparkContext，进行资源的申请、任务的分配和监控</li>
<li>资源管理器为Executor分配资源，并启动Executor进程</li>
<li>SparkContext根据RDD的依赖关系构建DAG图，DAG图提交给DAGScheduler解析成Stage，然后把一个个TaskSet提交给底层调度器TaskScheduler处理；Executor向SparkContext申请Task，Task Scheduler将Task发放给Executor运行，并提供应用程序代码</li>
<li>Task在Executor上运行，把执行结果反馈给TaskScheduler，然后反馈给DAGScheduler，运行完毕后写入数据并释放所有资源 </li>
</ol>
<h2 id="RDD运行原理"><a href="#RDD运行原理" class="headerlink" title="RDD运行原理"></a>RDD运行原理</h2><h3 id="RDD设计背景"><a href="#RDD设计背景" class="headerlink" title="RDD设计背景"></a>RDD设计背景</h3><ul>
<li>许多迭代式算法（比如机器学习、图算法等）和交互式数据挖掘工具，共同之处是，不同计算阶段之间会重用中间结果</li>
<li>目前的MapReduce框架都是把中间结果写入到稳定存储（比如磁盘）中，带来了大量的数据复制、磁盘IO和序列化开销</li>
<li>RDD就是为了满足这种需求而出现的，它提供了一个抽象的数据架构，我们不必担心底层数据的分布式特性，只需将具体的应用逻辑表达为一系列转换处理，不同RDD之间的转换操作形成依赖关系，可以实现管道化，避免中间数据存储</li>
</ul>
<p>无论是工业界还是学术界，都已经广泛使用高级集群编程模型来处理日益增长的数据，如MapReduce和Dryad。这些系统将分布式编程简化为自动提供位置感知性调度、容错以及负载均衡，使得大量用户能够在商用集群上分析超大数据集。</p>
<p>大多数现有的集群计算系统都是基于非循环的数据流模型。从稳定的物理存储（如分布式文件系统）中加载记录，记录被传入由一组确定性操作构成的DAG，然后写回稳定存储。DAG数据流图能够在运行时自动实现任务调度和故障恢复。</p>
<p>尽管非循环数据流是一种很强大的抽象方法，但仍然有些应用无法使用这种方式描述。我们就是针对这些不太适合非循环模型的应用，它们的特点是在多个并行操作之间重用工作数据集。这类应用包括：</p>
<ol>
<li>机器学习和图应用中常用的迭代算法（每一步对数据执行相似的函数）；</li>
<li>交互式数据挖掘工具（用户反复查询一个数据子集）。</li>
</ol>
<p>基于数据流的框架并不明确支持工作集，所以需要将数据输出到磁盘，然后在每次查询时重新加载，这带来较大的开销。</p>
<h3 id="RDD概念"><a href="#RDD概念" class="headerlink" title="RDD概念"></a>RDD概念</h3><ul>
<li>一个RDD就是一个分布式对象集合，本质上是一个只读的分区记录集合，每个RDD可分成多个分区，每个分区就是一个数据集片段，并且一个RDD的不同分区可以被保存到集群中不同的节点上，从而可以在集群中的不同节点上进行并行计算</li>
<li>RDD提供了一种高度受限的共享内存模型，即RDD是只读的记录分区的集合，不能直接修改，只能基于稳定的物理存储中的数据集创建RDD，或者通过在其他RDD上执行确定的转换操作（如map、join和group by）而创建得到新的RDD</li>
<li>RDD提供了一组丰富的操作以支持常见的数据运算，分为“动作”（Action）和“转换”（Transformation）两种类型</li>
<li>RDD提供的转换接口都非常简单，都是类似map、filter、groupBy、join等粗粒度的数据转换操作，而不是针对某个数据项的细粒度修改（不适合网页爬虫）</li>
<li>表面上RDD的功能很受限、不够强大，实际上RDD已经被实践证明可以高效地表达许多框架的编程模型（比如MapReduce、SQL、Pregel）</li>
<li>Spark用Scala语言实现了RDD的API，程序员可以通过调用API实现对RDD的各种操作</li>
</ul>
<p>RDD典型的执行过程如下：</p>
<ul>
<li><p>RDD读入外部数据源进行创建</p>
</li>
<li><p>RDD经过一系列的转换（Transformation）操作，每一次都会产生不同的RDD，供给下一个转换操作使用</p>
</li>
<li><p>最后一个RDD经过“动作”操作进行转换，并输出到外部数据源 </p>
</li>
</ul>
<p>这一系列处理称为一个Lineage（血缘关系），即DAG拓扑排序的结果</p>
<p><strong>优点：惰性调用、管道化、避免同步等待、不需要保存中间结果、每次操作变得简单</strong></p>
<p><img data-src="spark-learning-1/image-20191216131107830.png" alt="RDD执行过程的一个实例"></p>
<h3 id="RDD特性"><a href="#RDD特性" class="headerlink" title="RDD特性"></a>RDD特性</h3><p>Spark采用RDD以后能够实现高效计算的原因主要在于：</p>
<ol>
<li><p>高效的容错性</p>
<ul>
<li>现有容错机制：数据复制或者记录日志</li>
<li>RDD：血缘关系、重新计算丢失分区、无需回滚系统、重算过程在不同节点之间并行、只记录粗粒度的操作</li>
</ul>
</li>
<li><p>中间结果持久化到内存，数据在内存中的多个RDD操作之间进行传递，避免了不必要的读写磁盘开销</p>
</li>
<li><p>存放的数据可以是Java对象，避免了不必要的对象序列化和反序列化</p>
</li>
</ol>
<p>一般来说，分布式数据集的容错性有两种方式：即数据检查点和记录数据的更新。由于面向的是大规模数据分析，数据检查点操作成本很高：需要通过数据中心的网络连接在机器之间复制庞大的数据集，而网络带宽往往比内存带宽低得多，同时还需要消耗更多的存储资源（在内存中复制数据可以减少需要缓存的数据量，而存储到磁盘则会拖慢应用程序）。所以选择记录更新的方式。但是，如果更新太多，那么记录更新成本也不低。因此，RDD只支持读操作，并且只支持粗粒度转换，即在大量记录上执行的单个操作。将创建RDD的一系列转换记录下来（即Lineage），以便恢复丢失的分区。</p>
<p>虽然只支持粗粒度转换限制了编程模型，但是RDD仍然可以很好地适用于很多应用，特别是支持数据并行的批量分析应用，包括数据挖掘、机器学习、图算法等，因为这些程序通常都会在很多记录上执行相同的操作。</p>
<h3 id="RDD运行原理-1"><a href="#RDD运行原理-1" class="headerlink" title="RDD运行原理"></a>RDD运行原理</h3><h4 id="RDD之间的依赖关系"><a href="#RDD之间的依赖关系" class="headerlink" title="RDD之间的依赖关系"></a>RDD之间的依赖关系</h4><ul>
<li>Shuffle操作<ul>
<li>什么是Shuffle操作</li>
</ul>
</li>
</ul>
<p><img data-src="spark-learning-1/image-20191216131353065.png" alt="一个关于Shuffle 操作的简单实例"></p>
<ul>
<li>窄依赖和宽依赖<ul>
<li>是否包含Shuffle操作是区分窄依赖和宽依赖的根据</li>
</ul>
</li>
</ul>
<p><img data-src="spark-learning-1/image-20191216131411901.png" alt="窄依赖与宽依赖的区别"></p>
<ul>
<li>窄依赖表现为一个父RDD的分区对应于一个子RDD的分区或多个父RDD的分区对应于一个子RDD的分区</li>
<li>宽依赖则表现为存在一个父RDD的一个分区对应一个子RDD的多个分区</li>
</ul>
<h3 id="阶段的划分"><a href="#阶段的划分" class="headerlink" title="阶段的划分"></a>阶段的划分</h3><p>Spark 根据DAG 图中的RDD 依赖关系，把一个作业分成多个阶段。阶段划分的依据是窄依赖和宽依赖。对于宽依赖和窄依赖而言，窄依赖对于作业的优化很有利，宽依赖无法优化</p>
<p>逻辑上，每个RDD 操作都是一个fork/join（一种用于并行执行任务的框架），把计算fork 到每个RDD 分区，完成计算后对各个分区得到的结果进行join 操作，然后fork/join下一个RDD 操作</p>
<p><img data-src="spark-learning-1/image-20191216131447362.png" alt="image-20191216131447362"></p>
<p>fork/join的优化原理</p>
<p>举例：一个学校（含2个班级）完成从北京到厦门的长征</p>
<p><img data-src="spark-learning-1/image-20191216131720515.png" alt="image-20191216131720515"></p>
<p>窄依赖可以实现“流水线”优化</p>
<p>宽依赖无法实现“流水线”优化</p>
<p><img data-src="spark-learning-1/image-20191216131730200.png" alt="image-20191216131730200"></p>
<p><img data-src="spark-learning-1/image-20191216131735052.png" alt="image-20191216131735052"></p>
<p>Spark根据DAG图中的RDD依赖关系，把一个作业分成多个阶段。对于宽依赖和窄依赖而言，窄依赖对于作业的优化很有利。只有窄依赖可以实现流水线优化，宽依赖包含Shuffle过程，无法实现流水线方式处理。</p>
<p>Spark通过分析各个RDD的依赖关系生成了DAG，再通过分析各个RDD中的分区之间的依赖关系来决定如何划分Stage，具体划分方法是：</p>
<ul>
<li>在DAG中进行反向解析，遇到宽依赖就断开</li>
<li>遇到窄依赖就把当前的RDD加入到Stage中</li>
<li>将窄依赖尽量划分在同一个Stage中，可以实现流水线计算</li>
</ul>
<h4 id="Stage的划分"><a href="#Stage的划分" class="headerlink" title="Stage的划分"></a>Stage的划分</h4><p>被分成三个Stage，在Stage2中，从map到union都是窄依赖，这两步操作可以形成一个流水线操作</p>
<p><img data-src="spark-learning-1/image-20191216132010315.png" alt="根据RDD分区的依赖关系划分Stage"></p>
<p><strong>流水线操作实例</strong></p>
<p>分区7通过map操作生成的分区9，可以不用等待分区8到分区10这个map操作的计算结束，而是继续进行union操作，得到分区13，这样流水线执行大大提高了计算的效率</p>
<h3 id="RDD运行过程"><a href="#RDD运行过程" class="headerlink" title="RDD运行过程"></a>RDD运行过程</h3><p>通过上述对RDD概念、依赖关系和Stage划分的介绍，结合之前介绍的Spark运行基本流程，再总结一下RDD在Spark架构中的运行过程：</p>
<ol>
<li>创建RDD对象；</li>
<li>SparkContext负责计算RDD之间的依赖关系，构建DAG；</li>
<li>DAGScheduler负责把DAG图分解成多个Stage，每个Stage中包含了多个Task，每个Task会被TaskScheduler分发给各个WorkerNode上的Executor去执行。</li>
</ol>
<p><img data-src="spark-learning-1/image-20191216132111870.png" alt="RDD在Spark中的运行过程"></p>
<h1 id="Spark的部署方式"><a href="#Spark的部署方式" class="headerlink" title="Spark的部署方式"></a>Spark的部署方式</h1><p>Spark支持三种不同类型的部署方式，包括：</p>
<ul>
<li>Standalone（类似于MapReduce1.0，slot为资源分配单位）</li>
<li>Spark on Mesos（和Spark有血缘关系，更好支持Mesos）</li>
<li>Spark on YARN</li>
</ul>
<p><img data-src="spark-learning-1/image-20191216132143723.png" alt="Spark on Yarn架构"></p>
<ul>
<li>虽然Spark很快，但现在在生产环境中仍然不尽人意，无论扩展性、稳定性、管理性等方面都需要进一步增强</li>
<li>同时，Spark在流处理领域能力有限，如果要实现亚秒级或大容量的数据获取或处理需要其他流处理产品。Cloudera宣布旨在让Spark流数据技术适用于80%的使用场合，就考虑到了这一缺陷。我们确实看到实时分析（而非简单数据过滤或分发）场景中，很多以前使用S4或Storm等流式处理引擎的实现已经逐渐被Kafka+Spark Streaming代替</li>
<li>Spark的流行将逐渐让MapReduce、Tez走进博物馆</li>
<li>Hadoop现在分三块HDFS/MR/YARN，Spark比Hadoop性能好，只是Spark作为一个计算引擎，比MR的性能要好。但它的存储和调度框架还是依赖于HDFS/YARN，Spark也有自己的调度框架，但仍然非常不成熟，基本不可商用</li>
</ul>
]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>Spark</tag>
      </tags>
  </entry>
  <entry>
    <title>使用Tensorflow进行物品预测</title>
    <url>//posts/tensorflow-object-detection.html</url>
    <content><![CDATA[<h1 id="序"><a href="#序" class="headerlink" title="序"></a>序</h1><p>这套流程主要是为了记录我在学习以及模型训练的过程，以及其中遇见的相关问题</p>
<h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><ul>
<li>CPU: Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz</li>
<li>MEM: 384GB 2400 DDR4</li>
<li>GPU: Matrox Electronics Systems Ltd. G200eR2</li>
<li>DISK: 1.1 TB</li>
<li>System: Ubuntu 18.04 LTS</li>
<li>Python: 3.6.7</li>
<li>TensorFlow: 1.12.0</li>
</ul>
<p>因为GPU并不是NVIDIA，所以不支持CUDA加速，目前只能使用CPU进行Tensorflow学习，在10月20日，Python版本升级到了3.7，然而到现在(11月28日)，Tensorflow还只支持3.6，故Python版本我们选择了3.6.7，也就是Python 3.6的最后一个版本</p>
<h2 id="流程"><a href="#流程" class="headerlink" title="流程"></a>流程</h2><p>1.安装Python<br>2.编译并安装Tensorflow以及相关依赖<br>3.安装Tensorflow Model<br>4.使用labelImg进行图片标注<br>5.修改Model代码，生成trainval.txt，将图片及标注文件转换成TFRecord<br>6.下载一套COCO数据集，并更改pipeline.config<br>7.进行40000次的模型训练，生成ckpt文件<br>8.将ckpt转换成GRAPH的pb冻结图<br>9.使用pb冻结图进行物品图片预测  </p>
<h1 id="Miniconda"><a href="#Miniconda" class="headerlink" title="Miniconda"></a>Miniconda</h1><p>conda和virtualenv一样，可用于Python项目做多版本环境创建与切换的，也就是在同一个环境中，可以存在几个不同python版本或者不同requirement的虚拟环境，在安装依赖更新包都十分方便，anaconda太大了，我也不需要那么多的包，所以我这里使用的是Miniconda</p>
<h2 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h2><p>首先我们需要下载Miniconda，可以<span class="exturl" data-url="aHR0cHM6Ly9jb25kYS5pby9taW5pY29uZGEuaHRtbA==">点击这里<i class="fa fa-external-link-alt"></i></span>，进入Miniconda的官网</p>
<p><img data-src="tensorflow-object-detection/01.jpg" alt="Miniconda的官网"></p>
<p>右键复制他的下载地址，通过wget进行下载</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">wget https:&#x2F;&#x2F;repo.anaconda.com&#x2F;miniconda&#x2F;Miniconda3-latest-Linux-x86_64.sh</span><br></pre></td></tr></table></figure>

<p>等待进度条走完后完成下载</p>
<p><img data-src="tensorflow-object-detection/02.jpg" alt="Miniconda下载"></p>
<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>现在完毕后我们使用bash命令运行这个sh文件</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">bash Miniconda3-latest-Linux-x86_64.sh</span><br></pre></td></tr></table></figure>

<p>按下回车，查看Licenses，并输入yes进行下一步安装</p>
<p><img data-src="tensorflow-object-detection/03.jpg" alt="Miniconda安装"></p>
<p>下一步输入安装路径，我这里是安装到了<code>/opt/miniconda3</code>这个目录下</p>
<p><img data-src="tensorflow-object-detection/04.jpg" alt="Miniconda环境变量"></p>
<p>经过解包后，会提示你是否添加环境变量，这里我们选择yes，进行添加环境变量</p>
<p>最后完成环境Miniconda的安装</p>
<p><img data-src="tensorflow-object-detection/05.jpg" alt="Miniconda环境变量查看"></p>
<p>我们可以通过下面的命令查看环境变量是否添加</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">tail .bashrc</span><br></pre></td></tr></table></figure>

<p>添加完环境变量后，我们需要用<code>source</code>更新一下，才能使环境变量生效</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">source .bashrc</span><br></pre></td></tr></table></figure>

<h2 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h2><h3 id="降级"><a href="#降级" class="headerlink" title="降级"></a>降级</h3><p>因为Tensorflow现在只支持3.6版本的Python，然而我们下载的是最新版本的Miniconda，里面预装的是3.7最新版本的，所有我们需要进行降级，将python切换到3.6.7</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">conda install python&#x3D;3.6.7</span><br></pre></td></tr></table></figure>

<p><img data-src="tensorflow-object-detection/06.jpg" alt="Python降级确认"></p>
<p>经过解析环境后<code>Solving environment</code>后，我们选择yes，进行降级操作</p>
<p><img data-src="tensorflow-object-detection/07.jpg" alt="Python降级"></p>
<p>经过一段时间的等待，我们就成功的将Python版本降到了3.6.7</p>
<p>之后运行下面的命令 安装必要的包</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">conda install numpy keras-preprocessing </span><br></pre></td></tr></table></figure>

<h3 id="更新"><a href="#更新" class="headerlink" title="更新"></a>更新</h3><p>可以使用下面的命令进行conda升级</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">conda update conda</span><br></pre></td></tr></table></figure>

<p>可以使用下面的命令进行当前所有包进行升级</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">conda update --all</span><br></pre></td></tr></table></figure>

<h3 id="清理"><a href="#清理" class="headerlink" title="清理"></a>清理</h3><p>conda长时间使用后，体积会很大，可以使用下面命令将已经下载包进行清理</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">conda clean -a -y</span><br></pre></td></tr></table></figure>

<h2 id="卸载"><a href="#卸载" class="headerlink" title="卸载"></a>卸载</h2><p>如果需要需要卸载conda，可以用下面的命令将相应位置的Miniconda目录直接删除</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">rm -rf &#x2F;opt&#x2F;miniconda3&#x2F;</span><br></pre></td></tr></table></figure>

<p>然后使用下面的命令，编辑环境变量</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">vi ~&#x2F;.bashrc</span><br></pre></td></tr></table></figure>

<p><img data-src="tensorflow-object-detection/08.jpg" alt="Miniconda环境变量"></p>
<p>将环境变量中的关于conda的内容直接删除即可</p>
<h1 id="Tensorflow"><a href="#Tensorflow" class="headerlink" title="Tensorflow"></a>Tensorflow</h1><p>Tensorflow目前分2个安装方法</p>
<ul>
<li>CPU版</li>
<li>GPU版</li>
</ul>
<p>除了通常的算术和逻辑，现代CPU提供了许多低级指令，称为扩展，例如， SSE2，SSE4，AVX等来自维基百科：</p>
<blockquote>
<p>高级矢量扩展（AVX）是英特尔在2008年3月提出的英特尔和AMD微处理器的x86指令集体系结构的扩展，英特尔首先通过Sandy Bridge处理器在2011年第一季度推出，随后由AMD推出Bulldozer处理器在2011年第三季度.AVX提供了新功能，新指令和新编码方案。<br>特别是，AVX引入了融合乘法累加（FMA）操作，加速了线性代数计算，即点积，矩阵乘法，卷积等。几乎所有机器学习训练都涉及大量这些操作，因此将会支持AVX和FMA的CPU（最高达300％）更快。该警告指出您的CPU确实支持AVX（hooray！）。</p>
</blockquote>
<p>在此强调一下：</p>
<blockquote>
<p>这只限于CPU。如果你有一个GPU，你不应该关心AVX的支持，因为大多数昂贵的操作将被分派到一个GPU设备上（除非明确地设置）。在这种情况下，您可以简单地忽略此警告。</p>
</blockquote>
<p>那为什么会出现这种警告呢？</p>
<blockquote>
<p>由于tensorflow默认分布是在没有CPU扩展的情况下构建的，例如SSE4.1，SSE4.2，AVX，AVX2，FMA等。默认版本（来自pip install tensorflow的版本）旨在与尽可能多的CPU兼容。另一个观点是，即使使用这些扩展名，CPU的速度也要比GPU慢很多，并且期望在GPU上执行中型和大型机器学习培训。</p>
</blockquote>
<p>我们机器没有GPU能够使用，为了尽可能多地利用CPU，且我们的CPU支持AVX，AVX2，为了更好效率，我们使用Bazel重新构建Tensorflow，不仅在以后的使用中，消除AVX等警报，还可以改善Tensorflow的性能</p>
<p>可以根据个人需求选择是否编译，也可以直接安装发行版本的Tensorflow</p>
<h2 id="JDK"><a href="#JDK" class="headerlink" title="JDK"></a>JDK</h2><p>安装Bazel，需要Java JDK1.8或更高版本的支持，所以我们的第一项工作就是安装JDK</p>
<p>关于JDK的安装教程，可以<a href="/posts/jdk-install.html">点击这里</a>查看。</p>
<h2 id="Bazel"><a href="#Bazel" class="headerlink" title="Bazel"></a>Bazel</h2><h3 id="依赖"><a href="#依赖" class="headerlink" title="依赖"></a>依赖</h3><p>首先运行下面的代码，安装Bazel相关依赖，因为我们已经安装过python就不需要安装了</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apt-get install pkg-config zip g++ zlib1g-dev unzip</span><br></pre></td></tr></table></figure>

<h3 id="安装-1"><a href="#安装-1" class="headerlink" title="安装"></a>安装</h3><p><img data-src="tensorflow-object-detection/09.jpg" alt="Bazel Releases下载"></p>
<p>请<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2JhemVsYnVpbGQvYmF6ZWwvcmVsZWFzZXM=">点击这里<i class="fa fa-external-link-alt"></i></span>打开Bazel Releases下载页面，选择相应版本进行下载</p>
<p>然后运行下面的命令，给sh文件加权限并运行</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">chmod +x bazel-0.19.2-installer-linux-x86_64.sh</span><br><span class="line">.&#x2F;bazel-0.19.2-installer-linux-x86_64.sh</span><br></pre></td></tr></table></figure>

<p><img data-src="tensorflow-object-detection/10.jpg" alt="Bazel安装成功"></p>
<p>加载完毕后，看到Bazel is now installed!标明Bazel已安装成功</p>
<h2 id="编译Tensorflow"><a href="#编译Tensorflow" class="headerlink" title="编译Tensorflow"></a>编译Tensorflow</h2><p>首先我们先用git把Tensorflow的源码下载下来</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git clone https:&#x2F;&#x2F;github.com&#x2F;tensorflow&#x2F;tensorflow.git</span><br></pre></td></tr></table></figure>

<p>现在完毕后，我们需要运行configure,做一些必要的配置</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd tensorflow</span><br><span class="line">.&#x2F;configure</span><br></pre></td></tr></table></figure>

<p><img data-src="tensorflow-object-detection/11.jpg" alt="Tensorflow configure"></p>
<p>接下来，配置系统会给出各种询问，以确认编译时的配置参数，请根据个人情况配置参数，我这里全部选择的n，其他的为默认选项</p>
<p>在配置完Bazel的编译选项之后，接下来就可以使用如下指令编译TensorFlow的源代码</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">bazel build --config&#x3D;opt &#x2F;&#x2F;tensorflow&#x2F;tools&#x2F;pip_package:build_pip_package</span><br></pre></td></tr></table></figure>

<p><img data-src="tensorflow-object-detection/12.jpg" alt="Tensorflow编译"></p>
<p>这个时候，我们就可以去喝喝水，休息一会，等待编译完毕即可</p>
<p><img data-src="tensorflow-object-detection/13.jpg" alt="Tensorflow编译成功"></p>
<p>半个小时后，当我们看到这个提示，就标明tensorflow已经编译成功，在临时文件夹中生成了一堆binary，当前目录下也有软连接，可以直接运行下面的命令，生成whl文件，</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">bazel-bin&#x2F;tensorflow&#x2F;tools&#x2F;pip_package&#x2F;build_pip_package &#x2F;tmp&#x2F;tensorflow_pkg</span><br></pre></td></tr></table></figure>

<p><img data-src="tensorflow-object-detection/14.jpg" alt="生成whl"></p>
<p>成功生成whl文件</p>
<h2 id="安装Tensorflow"><a href="#安装Tensorflow" class="headerlink" title="安装Tensorflow"></a>安装Tensorflow</h2><p>接下来运行下面的命令，直接安装生成的whl</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pip install &#x2F;tmp&#x2F;tensorflow_pkg&#x2F;tensorflow-1.12.0rc0-cp36-cp36m-linux_x86_64.whl</span><br></pre></td></tr></table></figure>

<p><img data-src="tensorflow-object-detection/15.jpg" alt="生成whl"></p>
<p>在经过相关依赖安装之后，提示安装成功</p>
<p>接下来我们可以跑一个例子</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd ~</span><br><span class="line">python</span><br><span class="line">import tensorflow as tf</span><br><span class="line">a &#x3D; tf.constant(2)</span><br><span class="line">b &#x3D; tf.constant(3)</span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">    print(&quot;Addition with constants: %i&quot; % sess.run(a+b))</span><br></pre></td></tr></table></figure>

<p><img data-src="tensorflow-object-detection/16.jpg" alt="Tensorflow例子"></p>
<p>如图所示，可以得到结果，则说明Tensorflow已成功安装了</p>
<h1 id="Tensorflow-Object-Detection-API"><a href="#Tensorflow-Object-Detection-API" class="headerlink" title="Tensorflow Object Detection API"></a>Tensorflow Object Detection API</h1><p>Tensorflow Object Detection API可实现基于给定模型检测图像中的特定目标，是典型的深度学习在计算机视觉中的应用</p>
<p>包含在Tensorflow Model中</p>
<p>Tensorflow旧版本自带model，然而新版本已经没有了，就需要我们自己单独下载</p>
<h2 id="下载-1"><a href="#下载-1" class="headerlink" title="下载"></a>下载</h2><p>首先运行下面的命令，安装Tensorflow Object Detection API的依赖</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">conda install Cython contextlib2 pillow lxml jupyter matplotlib</span><br></pre></td></tr></table></figure>
<p>虽然都在本次教程中，都不会全用上，但是以后总会用找到了</p>
<p>使用下面的命令，从Tensorflow models下载最新的文件</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git clone https:&#x2F;&#x2F;github.com&#x2F;tensorflow&#x2F;models.git</span><br></pre></td></tr></table></figure>
<p>如果网络不太好，就多clone几次，总会成功的</p>
<h2 id="COCO-API-installation"><a href="#COCO-API-installation" class="headerlink" title="COCO API installation"></a>COCO API installation</h2><p>我们需要使用COCO预处理数据集，需要下载cocoapi，使用下面命令完成COCO API的安装</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git clone https:&#x2F;&#x2F;github.com&#x2F;cocodataset&#x2F;cocoapi.git</span><br><span class="line">cd cocoapi&#x2F;PythonAPI</span><br><span class="line">make</span><br><span class="line">cp -r pycocotools &lt;path_to_tensorflow&gt;&#x2F;models&#x2F;research&#x2F;</span><br></pre></td></tr></table></figure>

<h2 id="Protobuf编译器安装和使用"><a href="#Protobuf编译器安装和使用" class="headerlink" title="Protobuf编译器安装和使用"></a>Protobuf编译器安装和使用</h2><p>Tensorflow对象检测API使用Protobufs配置模型和训练参数。</p>
<p>在使用框架之前，必须编译Protobuf库。</p>
<p><img data-src="tensorflow-object-detection/17.jpg" alt="Protobuf Releases下载"></p>
<p>首先<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL3Byb3RvY29sYnVmZmVycy9wcm90b2J1Zi9yZWxlYXNlcw==">点击这里<i class="fa fa-external-link-alt"></i></span>Protobuf Releases下载页面，选择相应版本进行下载</p>
<p>然后使用下面的命令解压zip的包到存储的目录下</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">unzip -d &#x2F;opt&#x2F;protoc protoc-3.6.1-linux-x86_64.zip</span><br></pre></td></tr></table></figure>

<p>并将下面的信息添加至环境变量到.bashrc</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">export PATH&#x3D;&quot;&#x2F;opt&#x2F;protoc&#x2F;bin:$PATH&quot;</span><br></pre></td></tr></table></figure>

<p>添加完毕并source更新环境变量后，运行以下命令来编译Protobuf库</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd &#x2F;opt&#x2F;models&#x2F;research&#x2F;</span><br><span class="line">protoc object_detection&#x2F;protos&#x2F;*.proto --python_out&#x3D;.</span><br></pre></td></tr></table></figure>

<h2 id="将库添加到PYTHONPATH"><a href="#将库添加到PYTHONPATH" class="headerlink" title="将库添加到PYTHONPATH"></a>将库添加到PYTHONPATH</h2><p>在本地运行时，models/research/和slim目录应该附加到PYTHONPATH。这可以通过从tensorflow/models/research/运行以下命令来完成：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">export PYTHONPATH&#x3D;$PYTHONPATH:&#96;pwd&#96;:&#96;pwd&#96;&#x2F;slim</span><br></pre></td></tr></table></figure>
<blockquote>
<p>此命令需要从您启动的每个新终端运行。如果您希望避免手动运行，可以将其作为新行添加到~/.bashrc文件的末尾，将<code>pwd</code>替换为系统上tensorflow/models/research的绝对路径。</p>
</blockquote>
<p>如果你要添加环境变量，可以将下面的内容添加至环境变量并用source更新</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">export PATH&#x3D;&quot;&#x2F;opt&#x2F;models&#x2F;research:&#x2F;opt&#x2F;models&#x2F;research&#x2F;slim:$PATH&quot;</span><br></pre></td></tr></table></figure>

<h2 id="测试安装"><a href="#测试安装" class="headerlink" title="测试安装"></a>测试安装</h2><p>您可以测试是否已正确安装Tensorflow对象检测</p>
<p>通过运行以下命令API：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">python object_detection&#x2F;builders&#x2F;model_builder_test.py</span><br></pre></td></tr></table></figure>

<p><img data-src="tensorflow-object-detection/18.jpg" alt="model_builder_test"></p>
<p>运行结果如图所示，表明Tensorflow Object Detection API已配置完毕</p>
<h1 id="LabelImg"><a href="#LabelImg" class="headerlink" title="LabelImg"></a>LabelImg</h1><p>首先需要先要标注图像相应标签，这里可以使用labelImg工具。</p>
<h2 id="下载-2"><a href="#下载-2" class="headerlink" title="下载"></a>下载</h2><p><img data-src="tensorflow-object-detection/19.jpg" alt="LabelImg Download list"></p>
<p>请<span class="exturl" data-url="aHR0cHM6Ly90enV0YWxpbi5naXRodWIuaW8vbGFiZWxJbWcv">点击这里<i class="fa fa-external-link-alt"></i></span>打开LabelImg Download list页面，下载合适版本的图片</p>
<h2 id="使用-1"><a href="#使用-1" class="headerlink" title="使用"></a>使用</h2><p><img data-src="tensorflow-object-detection/20.jpg" alt="labelImg.exe"></p>
<p>解压后，直接双击<code>labelImg.exe</code>文件运行</p>
<p><img data-src="tensorflow-object-detection/21.jpg" alt="标注"></p>
<p>对对象物体画框，并记录相应对象的名称，save完成保存xml文件完成标注</p>
<p>每标注一张样本，即生成一个xml的标注文件</p>
<p><img data-src="tensorflow-object-detection/22.jpg" alt="单类别图片标注预览图"></p>
<p>并分类别保存，记得保持图片名称及XML标注文件名称一致，最后同一类别文件夹效果如图所示</p>
<p><img data-src="tensorflow-object-detection/23.jpg" alt="多类别图片标注预览图"></p>
<p>一次完成，每个类别保证有200张左右的样本，多个类别下的图片再统一放到一个目录下，效果如图所示</p>
<h1 id="填写pbtxt文件"><a href="#填写pbtxt文件" class="headerlink" title="填写pbtxt文件"></a>填写pbtxt文件</h1><p><img data-src="tensorflow-object-detection/24.jpg" alt="pbtxt文件"></p>
<p>在图片预测的时候，并不会直接把对象名字反馈回来，所以我们需要一个映射文件pbtxt，进行标签名和数字的转换，格式如图所示</p>
<p>将自己标记的图片中对象及自己编号按照格式放到一个pbtxt文本中，之后会用得到</p>
<h1 id="trainval-txt文件生成"><a href="#trainval-txt文件生成" class="headerlink" title="trainval.txt文件生成"></a>trainval.txt文件生成</h1><p>接下来就要进行TFRecord格式文件转换了，使用官方版的Api就可以生成trainval.txt，但是为了方便多个类别的使用，我对代码进行了一些更改，对类别下的样本进行随机，并按4:1的比率生成train.txt和val.txt，以保证总体样本上的随机，以提高数据的准确性</p>
<p><img data-src="tensorflow-object-detection/25.jpg" alt="trainval生成代码"></p>
<p>关键代码如图所示</p>
<p><img data-src="tensorflow-object-detection/26.jpg" alt="trainval"></p>
<p>最后会生成2个文件内容如图所示</p>
<h1 id="TFRecord文件生成"><a href="#TFRecord文件生成" class="headerlink" title="TFRecord文件生成"></a>TFRecord文件生成</h1><p>在生成TFRecord的时候，会根据train.txt和val.txt的内容，逐条生成产生train.record和val.record</p>
<p>我是用的是object_detection/dataset_tools/create_pet_tf_record.py，并进行了一定的更改，对tainval分别处理，进行图片格式转换，都转换成JPEG格式，对mask去除，并将输出record保存为一个</p>
<p><img data-src="tensorflow-object-detection/27.jpg" alt="图片格式转换"></p>
<p>图片格式转换代码如图所示</p>
<p><img data-src="tensorflow-object-detection/28.jpg" alt="record"></p>
<p>最后生成2个文件，以便进行下一步训练</p>
<h1 id="预训练模型下载"><a href="#预训练模型下载" class="headerlink" title="预训练模型下载"></a>预训练模型下载</h1><p><img data-src="tensorflow-object-detection/29.jpg" alt="detection_model_zoo"></p>
<p>Tensorflow Object Detection API提供了很多模型进行下载，可以<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL3RlbnNvcmZsb3cvbW9kZWxzL2Jsb2IvbWFzdGVyL3Jlc2VhcmNoL29iamVjdF9kZXRlY3Rpb24vZzNkb2MvZGV0ZWN0aW9uX21vZGVsX3pvby5tZA==">点击这里<i class="fa fa-external-link-alt"></i></span>打开Tensorflow detection model zoo页面，选择想要的模型进行下载</p>
<p>我选择的是<code>ssd_inception_v2_coco</code>模型下载，下载后将<code>object_detection/samples/configs/ssd_inception_v2_coco.config</code>这里的文件放到解压后的模型下，并修改参数</p>
<p><img data-src="tensorflow-object-detection/30.jpg" alt="pipeline.config"></p>
<p>主要是5个地址进行修改，更换成刚刚生成好的tfreord文件地址，和模型下的ckpt地址</p>
<p>num_examples是val.txt中测试样本的数目</p>
<p>num_steps是训练步数</p>
<h1 id="train训练"><a href="#train训练" class="headerlink" title="train训练"></a>train训练</h1><p><img data-src="tensorflow-object-detection/31.jpg" alt="目录结构"></p>
<p>首先说明我的目录结构如图所示，我直接将<code>object_detection</code>和<code>slim</code>到工程文件夹下了，使用起来更方便</p>
<p>修改完毕后，我们就可以进行样本训练了</p>
<p>在早期的版本Tensorflow中，使用<code>train.py</code>进行训练，在<code>object_detection</code>目录下，现在已经搬到<code>object_detection\legacy</code>目录下了，现在还可以使用，使用命令如下</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">object_detection\legacy\train.py \</span><br><span class="line">    --logtostderr \</span><br><span class="line">    --pipeline_config_path&#x3D;&#x2F;root&#x2F;&lt;name_to_project&gt;&#x2F;ssd_inception_v2&#x2F;pipeline.config \</span><br><span class="line">    --train_dir&#x3D;&#x2F;root&#x2F;&lt;name_to_project&gt;&#x2F;data&#x2F;model</span><br></pre></td></tr></table></figure>

<p>在新版本的Tensorflow中，都是使用<code>model_main.py</code>进行训练，在<code>object_detection</code>目录下，使用命令如下</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">object_detection\model_main.py \</span><br><span class="line">    --model_dir&#x3D;&#x2F;root&#x2F;&lt;name_to_project&gt;&#x2F;data&#x2F;model \</span><br><span class="line">    --pipeline_config_path&#x3D;&#x2F;root&#x2F;&lt;name_to_project&gt;&#x2F;ssd_inception_v2&#x2F;pipeline.config \</span><br><span class="line">    --num_train_steps&#x3D;40000</span><br></pre></td></tr></table></figure>

<blockquote>
<p><code>&lt;name_to_project&gt;</code>是我的项目名称</p>
</blockquote>
<p><img data-src="tensorflow-object-detection/32.jpg" alt="log"></p>
<p>在经过漫长的等待(2天)后，日志终于结束打印</p>
<p><img data-src="tensorflow-object-detection/33.jpg" alt="model"></p>
<p>我们也可以在输出文件夹<code>data/model</code>中看到相应步数的检查点</p>
<h1 id="导出推理图"><a href="#导出推理图" class="headerlink" title="导出推理图"></a>导出推理图</h1><p>要在代码中使用模型，需要将检查点文件（model.ckpt-STEP_NUMBER.*）转换为推理图。</p>
<p>你可以运行下面的代码，将检查点的ckpt文件转换成推理图</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">python object_detection\export_inference_graph.py \</span><br><span class="line">    --input_type image_tensor \</span><br><span class="line">    --pipeline_config_path &#x2F;root&#x2F;&lt;name_to_project&gt;&#x2F;ssd_inception_v2&#x2F;pipeline.config \</span><br><span class="line">    --trained_checkpoint_prefix &#x2F;root&#x2F;&lt;name_to_project&gt;&#x2F;data&#x2F;model-bak&#x2F;model.ckpt-20000 \</span><br><span class="line">    --output_directory &#x2F;root&#x2F;&lt;name_to_project&gt;&#x2F;data&#x2F;graph</span><br></pre></td></tr></table></figure>

<p><img data-src="tensorflow-object-detection/34.jpg" alt="graph"></p>
<p>导出后的文件如图所示，我们使用的就是<code>frozen_inference_graph.pb</code>文件</p>
<h1 id="测试模型"><a href="#测试模型" class="headerlink" title="测试模型"></a>测试模型</h1><p>如何使用模型呢，我们可以<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL3RlbnNvcmZsb3cvbW9kZWxzL2Jsb2IvbWFzdGVyL3Jlc2VhcmNoL29iamVjdF9kZXRlY3Rpb24vb2JqZWN0X2RldGVjdGlvbl90dXRvcmlhbC5pcHluYg==">点击这里<i class="fa fa-external-link-alt"></i></span>，这是Jupyter的运行文件，我们可以将运行代码拷贝到新建的一个python文件中，或者查找相应的转换工具使用</p>
<p>将<code>PATH_TO_TEST_IMAGES_DIR</code>参数改为自己要测试的图片<br>将<code>PATH_TO_FROZEN_GRAPH</code>参数改为<code>frozen_inference_graph.pb</code>的路径<br>将<code>PATH_TO_LABELS</code>参数改为<code>xxx.pbtxt</code>的路径</p>
<p><img data-src="tensorflow-object-detection/35.jpg" alt="test"></p>
<p>然后运行这个python，稍等片刻，我们就看到的预测结果</p>
<h1 id="附件"><a href="#附件" class="headerlink" title="附件"></a>附件</h1><p>相关链接：</p>
<ul>
<li><span class="exturl" data-url="aHR0cHM6Ly93d3cudGVuc29yZmxvdy5vcmcv">Tensorflow官网<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL3RlbnNvcmZsb3cvbW9kZWxzL2Jsb2IvbWFzdGVyL3Jlc2VhcmNoL29iamVjdF9kZXRlY3Rpb24vZzNkb2MvaW5zdGFsbGF0aW9uLm1k">Tensorflow models installation<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2hxODY5MzczNzUvYXJ0aWNsZS9kZXRhaWxzLzc5Njk2MDIz">警告：Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cDovL3d3dy5oYW5rY3MuY29tL21sL2NvbXBpbGUtYW5kLWluc3RhbGwtdGVuc29yZmxvdy1mcm9tLXNvdXJjZS5odG1s">从源码编译安装TensorFlow<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2F3ZWRjdmcvYXJ0aWNsZS9kZXRhaWxzLzc4MTU4MDQ0">TensorFlow安装以及models示例验证<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3h1bmFuMDAzL2FydGljbGUvZGV0YWlscy83ODcyMDE4OQ==">目标检测标注工具labelImg使用方法<i class="fa fa-external-link-alt"></i></span></li>
</ul>
]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Tensorflow</tag>
        <tag>Conda</tag>
      </tags>
  </entry>
  <entry>
    <title>【深度学习】手把手教你用卷积神经网络做垃圾分类</title>
    <url>//posts/trash-classification.html</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>目前我国垃圾分类存在的主要问题有三点：</p>
<p>1，垃圾分类正确率不高。</p>
<p>2，居民缺乏垃圾分类的意识和相关知识。</p>
<p>3，没有真正意义上的高效的垃圾分类系统。</p>
<p>基于以上，我们用深度学习的方法做垃圾分类。从技术上旨在通过深度学习，实现垃圾的高精确度分类。</p>
<h2 id="神经网络"><a href="#神经网络" class="headerlink" title="神经网络"></a>神经网络</h2><h3 id="神经网络简介"><a href="#神经网络简介" class="headerlink" title="神经网络简介"></a>神经网络简介</h3><p>人工神经网络（ Artificial Neural Network， 简写为ANN）也简称为神经网络（NN），是一种模仿生物神经网络结构和功能的计算模型。经典的神经网络结构包含三个层次的神经网络。分别为输入层，输出层以及隐藏层。</p>
<p><img data-src="trash-classification/%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84.png"></p>
<p>其中每层的圆圈代表一个神经元，隐藏层和输出层的神经元有输入的数据计算后输出，输入层的神经元只是输入。</p>
<ul>
<li>神经网络的特点<ul>
<li>每个连接都有个权值</li>
<li>同一层神经元之间没有连接</li>
<li>最后的输出结果对应的层也称之为<strong>全连接层</strong></li>
</ul>
</li>
</ul>
<p>神经网络是深度学习的重要算法，在图像（如图像的分类、检测）和自然语言处理（如文本分类、聊天等）有很多应用。</p>
<h3 id="神经网络原理"><a href="#神经网络原理" class="headerlink" title="神经网络原理"></a>神经网络原理</h3><p>神经网络分类的原理是怎么样的？我们还是围绕着损失、优化这两块去说。神经网络输出结果如何分类？</p>
<p><img data-src="trash-classification/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%A6%82%E4%BD%95%E5%88%86%E7%B1%BB.png"></p>
<p><strong>神经网络解决多分类问题最常用的方法是设置n个输出节点，其中n为类别的个数。</strong></p>
<p>任意事件发生的概率都在0和1之间，且总有某一个事件发生（概率的和为1）。如果将分类问题中“一个样例属于某一个类别”看成一个概率事件，那么训练数据的正确答案就符合一个概率分布。如何将神经网络前向传播得到的结果也变成概率分布呢？Softmax回归就是一个非常常用的方法。</p>
<h4 id="softmax回归"><a href="#softmax回归" class="headerlink" title="softmax回归"></a>softmax回归</h4><p>Softmax回归将神经网络输出转换成概率结果</p>
<p>$$softmax(y_i) = \frac{e^{y_i}}{\sum_{j=1}^{n}e^{y_i}}$$<br><img data-src="trash-classification/softmax%E5%9B%9E%E5%BD%92.png"></p>
<p><img data-src="trash-classification/softmax%E5%B1%95%E5%BC%80.png"></p>
<p>如何理解这个公式的作用呢？看一下计算案例</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">假设输出结果为：<span class="number">2.3</span>, <span class="number">4.1</span>, <span class="number">5.6</span></span><br><span class="line">softmax的计算输出结果为：</span><br><span class="line">y1_p = e^<span class="number">2.3</span>/(e^<span class="number">2.3</span>+e^<span class="number">4.1</span>+e^<span class="number">5.6</span>)</span><br><span class="line">y2_p = e^<span class="number">4.1</span>/(e^<span class="number">2.3</span>+e^<span class="number">4.1</span>+e^<span class="number">5.6</span>)</span><br><span class="line">y3_p = e^<span class="number">5.6</span>/(e^<span class="number">2.3</span>+e^<span class="number">4.1</span>+e^<span class="number">5.6</span>)</span><br></pre></td></tr></table></figure>

<p><strong>这样就把神经网络的输出变成了概率输出</strong><br>那么如何去衡量神经网络预测的概率分布和真实答案的概率分布之间的距离？</p>
<h4 id="交叉熵损失"><a href="#交叉熵损失" class="headerlink" title="交叉熵损失"></a>交叉熵损失</h4><p>公式：</p>
<p>$$H_{y^{‘}}(y)= - \sum_{i}y_{i}^{‘} log(y_i)$$</p>
<p>为了能够衡量距离，目标值需要进行one-hot编码，能与概率值一一对应，如下图</p>
<p><img data-src="trash-classification/%E4%BA%A4%E5%8F%89%E6%8D%9F%E5%A4%B1%E7%90%86%E8%A7%A3.png"></p>
<p>损失值如何计算？</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">-(<span class="number">0l</span>og(<span class="number">0.10</span>)+<span class="number">0l</span>og(<span class="number">0.05</span>)+<span class="number">0l</span>og(<span class="number">0.15</span>)+<span class="number">0l</span>og(<span class="number">0.10</span>)+<span class="number">0l</span>og(<span class="number">0.05</span>)+<span class="number">0l</span>og(<span class="number">0.20</span>)</span><br><span class="line">    +<span class="number">1l</span>og(<span class="number">0.10</span>)+<span class="number">0l</span>og(<span class="number">0.05</span>)+<span class="number">0l</span>og(<span class="number">0.10</span>)+<span class="number">0l</span>og(<span class="number">0.10</span>))</span><br></pre></td></tr></table></figure>
<p>上述的结果为-1log(0.10)，那么为了减少这一个样本的损失。神经网络应该怎么做？所以会提高对应目标值为1的位置输出概率大小，下面是log函数，log函数取正号之后单调递增的，取负号之后就单调递减。所以在减小损失值时相应的就会增大对应的概率值，同时根据softmax公式，其他类别的概率必定会减少。所以这里会提高对应目标值为1的位置输出概率大小。</p>
<img data-src="trash-classification/image-20190818150116295.png" align='center' width='500'>



<p>那么神经网络是怎么来减少损失值或者是找到最小的损失值呢？</p>
<h4 id="梯度下降算法"><a href="#梯度下降算法" class="headerlink" title="梯度下降算法"></a>梯度下降算法</h4><p>目的：使损失函数的值找到最小值</p>
<p>函数的<strong>梯度（gradient）</strong>指出了函数的最陡增长方向。<strong>沿着梯度的方向走，函数增长得就越快。那么按梯度的负方向走，函数值自然就降低得最快了</strong>。模型的训练目标即是寻找合适的$w$与$b$以最小化损失函数值。假设**$w$与$b$都是一维实数**，那么可以得到如下的$J$关于$w$与$b$的图：</p>
<p><img data-src="trash-classification/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E5%9B%BE.png"></p>
<p>可以看到，此损失函数$J$是一个<strong>凸函数</strong></p>
<p>参数w和b的更新公式为：<br>$$w := w - \alpha\frac{dJ(w, b)}{dw}$$</p>
<p>$$b := b - \alpha\frac{dJ(w, b)}{db}$$</p>
<blockquote>
<p>注：其中 α 表示学习速率，即每次更新的 w 的步伐长度。当 w 大于最优解 w′ 时，导数大于 0，那么 w 就会向更小的方向更新。反之当 w 小于最优解 w′ 时，导数小于 0，那么 w 就会向更大的方向更新。迭代直到收敛。</p>
</blockquote>
<p>通过平面来理解梯度下降过程：</p>
<p><img data-src="trash-classification/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E7%90%86%E8%A7%A3.png"></p>
<h4 id="反向传播算法"><a href="#反向传播算法" class="headerlink" title="反向传播算法"></a>反向传播算法</h4><p>反向传播算法实际就是：<strong>我们使用链式求导法则，反向层层推进，计算出每一层神经节点的偏导数，然后使用梯度下降，不断调整每一个节点的权重，从而达到求得全局最小值的目的。</strong></p>
<h2 id="案例：Mnist手写数字识别"><a href="#案例：Mnist手写数字识别" class="headerlink" title="案例：Mnist手写数字识别"></a>案例：Mnist手写数字识别</h2><h3 id="数据集介绍"><a href="#数据集介绍" class="headerlink" title="数据集介绍"></a>数据集介绍</h3><p><img data-src="trash-classification/%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97.png"></p>
<p>文件说明：</p>
<ul>
<li>train-images-idx3-ubyte.gz: training set images (9912422 bytes)</li>
<li>train-labels-idx1-ubyte.gz: training set labels (28881 bytes)</li>
<li>t10k-images-idx3-ubyte.gz: test set images (1648877 bytes)</li>
<li>t10k-labels-idx1-ubyte.gz: test set labels (4542 bytes)</li>
</ul>
<blockquote>
<p>网址：<span class="exturl" data-url="aHR0cDovL3lhbm4ubGVjdW4uY29tL2V4ZGIvbW5pc3Qv">http://yann.lecun.com/exdb/mnist/<i class="fa fa-external-link-alt"></i></span></p>
</blockquote>
<p>Mnist数据集可以从官网下载，网址： <strong><span class="exturl" data-url="aHR0cDovL3lhbm4ubGVjdW4uY29tL2V4ZGIvbW5pc3Qv">http://yann.lecun.com/exdb/mnist/<i class="fa fa-external-link-alt"></i></span></strong> 下载下来的数据集被分成两部分：55000行的训练数据集（mnist.train）和10000行的测试数据集（mnist.test）。每一个MNIST数据单元有两部分组成：一张包含手写数字的图片和一个对应的标签。我们把这些图片设为“xs”，把这些标签设为“ys”。训练数据集和测试数据集都包含xs和ys，比如训练数据集的图片是 mnist.train.images ，训练数据集的标签是 mnist.train.labels。</p>
<p><img data-src="trash-classification/%E6%95%B0%E5%AD%97.png"><br>我们可以知道图片是黑白图片，每一张图片包含28像素X28像素。我们把这个数组展开成一个向量，长度是 28x28 = 784。因此，在MNIST训练数据集中，mnist.train.images 是一个形状为 [60000, 784] 的张量。</p>
<p><img data-src="trash-classification/%E6%95%B0%E5%AD%97%E5%BC%A0%E9%87%8F.png"></p>
<p>MNIST中的每个图像都具有相应的标签，0到9之间的数字表示图像中绘制的数字。用的是one-hot编码</p>
<p><img data-src="trash-classification/%E6%95%B0%E5%AD%97label.png"></p>
<h3 id="Mnist数据获取API"><a href="#Mnist数据获取API" class="headerlink" title="Mnist数据获取API"></a>Mnist数据获取API</h3><p>TensorFlow框架自带了读取这个数据集的接口：</p>
<ul>
<li>from tensorflow.examples.tutorials.mnist import input_data<ul>
<li>mnist = input_data.read_data_sets(path, one_hot=True)<ul>
<li>mnist.train.next_batch(100)(提供批量获取功能)</li>
<li>mnist.train.images、labels</li>
<li>mnist.test.images、labels</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="流程分析"><a href="#流程分析" class="headerlink" title="流程分析"></a>流程分析</h3><h4 id="网络设计"><a href="#网络设计" class="headerlink" title="网络设计"></a>网络设计</h4><p>我们采用只有一层，即最后一个输出层的神经网络，也称之为全连接层神经网络。</p>
<p><img data-src="trash-classification/%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E7%BD%91%E7%BB%9C%E8%AE%BE%E8%AE%A1.png"></p>
<h4 id="相关计算"><a href="#相关计算" class="headerlink" title="相关计算"></a>相关计算</h4><ul>
<li>tf.matmul(a, b, name=None)+bias<ul>
<li>return:全连接结果，供交叉损失运算</li>
</ul>
</li>
<li>tf.train.GradientDescentOptimizer(learning_rate)<ul>
<li>梯度下降</li>
<li>learning_rate:学习率</li>
<li>method:<ul>
<li>minimize(loss):最小优化损失</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="具体流程"><a href="#具体流程" class="headerlink" title="具体流程"></a>具体流程</h4><ul>
<li>获取数据</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">from tensorflow.examples.tutorials.mnist import input_data</span><br><span class="line">mnist &#x3D; input_data.read_data_sets(&quot;.&#x2F;mnist_data&#x2F;&quot;, one_hot&#x3D;True)</span><br></pre></td></tr></table></figure>

<ul>
<li>定义数据占位符，Mnist数据实时提供给placeholder</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 1、准备数据</span></span><br><span class="line"><span class="comment"># x [None, 784] y_true [None. 10]</span></span><br><span class="line"><span class="keyword">with</span> tf.variable_scope(<span class="string">&quot;mnist_data&quot;</span>):</span><br><span class="line">    x = tf.placeholder(tf.float32, [<span class="literal">None</span>, <span class="number">784</span>])</span><br><span class="line">    y_true = tf.placeholder(tf.int32, [<span class="literal">None</span>, <span class="number">10</span>])</span><br></pre></td></tr></table></figure>

<ul>
<li>全连接结果计算</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 2、全连接层神经网络计算</span></span><br><span class="line"><span class="comment"># 类别：10个类别  全连接层：10个神经元</span></span><br><span class="line"><span class="comment"># 参数w: [784, 10]   b:[10]</span></span><br><span class="line"><span class="comment"># 全连接层神经网络的计算公式：[None, 784] * [784, 10] + [10] = [None, 10]</span></span><br><span class="line"><span class="comment"># 随机初始化权重偏置参数，这些是优化的参数，必须使用变量op去定义</span></span><br><span class="line"><span class="keyword">with</span> tf.variable_scope(<span class="string">&quot;fc_model&quot;</span>):</span><br><span class="line">    weights = tf.Variable(tf.random_normal([<span class="number">784</span>, <span class="number">10</span>], mean=<span class="number">0.0</span>, stddev=<span class="number">1.0</span>), name=<span class="string">&quot;w&quot;</span>)</span><br><span class="line">    bias = tf.Variable(tf.random_normal([<span class="number">10</span>], mean=<span class="number">0.0</span>, stddev=<span class="number">1.0</span>), name=<span class="string">&quot;b&quot;</span>)</span><br><span class="line">    <span class="comment"># fc层的计算</span></span><br><span class="line">    <span class="comment"># y_predict [None, 10]输出结果，提供给softmax使用</span></span><br><span class="line">    y_predict = tf.matmul(x, weights) + bias</span><br></pre></td></tr></table></figure>

<ul>
<li>损失计算与优化</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 3、softmax回归以及交叉熵损失计算</span></span><br><span class="line"><span class="keyword">with</span> tf.variable_scope(<span class="string">&quot;loss&quot;</span>):</span><br><span class="line">    <span class="comment"># labels:真实值 [None, 10]  one_hot</span></span><br><span class="line">    <span class="comment"># logits:全脸层的输出[None,10]</span></span><br><span class="line">    <span class="comment"># 返回每个样本的损失组成的列表</span></span><br><span class="line">    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_true,</span><br><span class="line">                                                                  logits=y_predict))</span><br><span class="line"><span class="comment"># 4、梯度下降损失优化</span></span><br><span class="line"><span class="keyword">with</span> tf.variable_scope(<span class="string">&quot;optimizer&quot;</span>):</span><br><span class="line">    <span class="comment"># 学习率</span></span><br><span class="line">    optimizer = tf.train.GradientDescentOptimizer(<span class="number">0.1</span>).minimize(loss)</span><br></pre></td></tr></table></figure>

<ul>
<li>模型训练</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 开启会话去训练</span></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    <span class="comment"># 初始化变量</span></span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br><span class="line">    <span class="keyword">if</span> FLAGS.is_train == <span class="number">1</span>:</span><br><span class="line">        <span class="comment"># 循环步数去训练</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1000</span>):</span><br><span class="line">            <span class="comment"># 获取数据，实时提供</span></span><br><span class="line">            <span class="comment"># 每步提供50个样本训练          </span></span><br><span class="line">                mnist_x, mnist_y = mnist.train.next_batch(<span class="number">100</span>)</span><br><span class="line">                _, loss_value = sess.run([optimizer, loss], feed_dict=&#123;x:mnist_x, y:mnist_y&#125;)</span><br><span class="line">                print(<span class="string">&#x27;第%d次训练, 损失值%.4f&#x27;</span> %(i+<span class="number">1</span>, loss_value))</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="完善模型功能"><a href="#完善模型功能" class="headerlink" title="完善模型功能"></a>完善模型功能</h4><ul>
<li><p>如何计算准确率</p>
<ul>
<li><p>equal_list = tf.equal(tf.argmax(y, 1), tf.argmax(y_label, 1))</p>
</li>
<li><p>accuracy = tf.reduce_mean(tf.cast(equal_list, tf.float32))</p>
<p><img data-src="trash-classification/%E5%87%86%E7%A1%AE%E7%8E%87%E8%AE%A1%E7%AE%97.png"></p>
</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 5、得出每次训练的准确率（通过真实值和预测值进行位置比较，每个样本都比较）</span></span><br><span class="line"><span class="keyword">with</span> tf.variable_scope(<span class="string">&quot;accuracy&quot;</span>):</span><br><span class="line">    equal_list = tf.equal(tf.argmax(y_true, <span class="number">1</span>), tf.argmax(y_predict, <span class="number">1</span>))</span><br><span class="line">    accuracy = tf.reduce_mean(tf.cast(equal_list, tf.float32))</span><br></pre></td></tr></table></figure>
<ul>
<li>使用测试集评估模型</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 6、定义一个flag判断是否是训练模式</span></span><br><span class="line">tf.app.flags.DEFINE_integer(<span class="string">&quot;is_train&quot;</span>, <span class="number">1</span>, <span class="string">&quot;指定是否是训练模型，还是拿数据去预测&quot;</span>)</span><br><span class="line">FLAGS = tf.app.flags.FLAGS</span><br><span class="line">...</span><br><span class="line"><span class="comment"># 每次拿十个样本预测</span></span><br><span class="line">mnist_x, mnist_y = mnist.test.next_batch(<span class="number">10</span>)</span><br></pre></td></tr></table></figure>

<h2 id="卷积神经网络"><a href="#卷积神经网络" class="headerlink" title="卷积神经网络"></a>卷积神经网络</h2><h3 id="卷积神经网络简介"><a href="#卷积神经网络简介" class="headerlink" title="卷积神经网络简介"></a>卷积神经网络简介</h3><ul>
<li>传统意义上的多层神经网络是只有输入层、隐藏层、输出层。其中隐藏层的层数根据需要而定，没有明确的理论推导来说明到底多少层合适</li>
<li>卷积神经网络CNN，在原来多层神经网络的基础上，加入了更加有效的特征学习部分，具体操作就是在原来的全连接层前面加入了卷积层与池化层。<strong>卷积神经网络出现，使得神经网络层数得以加深，“深度”学习由此而来。</strong></li>
</ul>
<blockquote>
<p>通常所说的深度学习，<strong>一般指的是这些CNN等新的结构以及一些新的方法（比如新的激活函数Relu等）</strong>，解决了传统多层神经网络的一些难以解决的问题</p>
</blockquote>
<h3 id="卷积神经网络原理"><a href="#卷积神经网络原理" class="headerlink" title="卷积神经网络原理"></a>卷积神经网络原理</h3><p>先来看一个示意图：</p>
<p><img data-src="trash-classification/%E5%8D%B7%E7%A7%AF%E7%BB%93%E6%9E%84%E6%A6%82%E8%BF%B0.png"></p>
<h4 id="卷积神经网络三个结构"><a href="#卷积神经网络三个结构" class="headerlink" title="卷积神经网络三个结构"></a>卷积神经网络三个结构</h4><p>神经网络(neural networks)的基本组成包括输入层、隐藏层、输出层。而卷积神经网络的特点在于隐藏层分为卷积层和池化层(pooling layer，又叫下采样层)以及激活层。每一层的作用</p>
<ul>
<li>卷积层：通过在原始图像上平移来提取特征</li>
<li>激活层：增加非线性分割能力</li>
<li>池化层：减少学习的参数，降低网络的复杂度（最大池化和平均池化）</li>
</ul>
<p>为了能够达到分类效果，还会有一个全连接层(Full Connection)也就是最后的输出层，进行损失计算并输出分类结果。</p>
<h4 id="卷积层"><a href="#卷积层" class="headerlink" title="卷积层"></a>卷积层</h4><p><img data-src="trash-classification/%E5%8D%B7%E7%A7%AF%E5%B1%82.png" alt="卷积层"></p>
<p><strong>参数及结构</strong></p>
<p>四个超参数控制输出体积的大小：过滤器大小，深度，步幅和零填充。得到的每一个深度也叫一个Feature Map。</p>
<p><strong>卷积层的处理</strong>，在卷积层有一个重要的就是过滤器大小（需要自己指定），若输入值是一个[32x32x3]的大小（例如RGB CIFAR-10彩色图像）。如果每个过滤器（Filter）的大小为5×5，则CNN层中的每个Filter将具有对输入体积中的[5x5x3]区域的权重，总共5 <em>5</em> 3 = 75个权重（和+1偏置参数），输入图像的3个深度分别与Filter的3个深度进行运算。请注意，沿着深度轴的连接程度必须为3，因为这是输入值的深度，并且也要记住这只是一个Filter。</p>
<ul>
<li>假设输入卷的大小为[16x16x20]。然后使用3x3的示例接收字段大小，CNN中的每个神经元现在将具有总共3 <em>3</em> 20 = 180个连接到输入层的连接。</li>
</ul>
<p><strong>卷积层的输出深度</strong>，那么一个卷积层的输出深度是可以指定的，输出深度是由你本次卷积中Filter的个数决定。加入上面我们使用了64个Filter，也就是[5,5,3,64]，这样就得到了64个Feature Map，这样这64个Feature Map可以作为下一次操作的输入值</p>
<p><strong>卷积层的输出宽度</strong>，输出宽度可以通过特定算数公式进行得出，后面会列出公式。</p>
<h5 id="卷积输出值的计算"><a href="#卷积输出值的计算" class="headerlink" title="卷积输出值的计算"></a>卷积输出值的计算</h5><p>我们用一个简单的例子来讲述如何计算卷积，然后，我们抽象出卷积层的一些重要概念和计算方法。</p>
<p>假设有一个5<em>5的图像，使用一个3</em>3的filter进行卷积，得到了到一个3<em>3的Feature Map，至于得到3</em>3大小，可以自己去计算一下。如下所示：</p>
<p><img data-src="trash-classification/%E8%AE%A1%E7%AE%97%E5%9B%BE1.png" alt="计算图1"></p>
<p>我们看下它的计算过程，首先计算公式如下：</p>
<p><img data-src="trash-classification/%E8%AE%A1%E7%AE%97%E5%85%AC%E5%BC%8F.png" alt="计算公式"></p>
<p>根据计算的例子，第一次：</p>
<p><img data-src="trash-classification/%E8%AE%A1%E7%AE%97%E5%9B%BE2.png" alt="计算图2"></p>
<p>第二次：</p>
<p><img data-src="trash-classification/%E8%AE%A1%E7%AE%97%E5%9B%BE3.png" alt="计算图3"></p>
<p>通过这样我们可以依次计算出Feature Map中所有元素的值。下面的动画显示了整个Feature Map的计算过程：</p>
<p><img data-src="trash-classification/%E8%AE%A1%E7%AE%97%E5%8A%A8%E5%9B%BE.gif" alt="计算动图"></p>
<p><strong>步长</strong></p>
<p>那么在卷积神经网络中有一个概念叫步长，也就是Filter移动的间隔大小。上面的计算过程中，步幅(stride)为1。步幅可以设为大于1的数。例如，当步幅为2时，我们可以看到得出2*2大小的Feature Map，发现这也跟步长有关。Feature Map计算如下：</p>
<p><img data-src="trash-classification/%E6%AD%A5%E9%95%BF%E4%B8%BA2.1.png" alt="步长为2.1"></p>
<p><img data-src="trash-classification/%E6%AD%A5%E9%95%BF%E4%B8%BA2.2.png" alt="步长为2.2"></p>
<p><img data-src="trash-classification/%E6%AD%A5%E9%95%BF%E4%B8%BA2.3.png" alt="步长为2.3"></p>
<p><img data-src="trash-classification/%E6%AD%A5%E9%95%BF%E4%B8%BA2.4.png" alt="步长为2.4"></p>
<h5 id="填充和多Filter"><a href="#填充和多Filter" class="headerlink" title="填充和多Filter"></a>填充和多Filter</h5><p>我们前面还曾提到，每个卷积层可以有多个filter。每个filter和原始图像进行卷积后，都可以得到一个Feature Map。因此，卷积后Feature Map的深度(个数)和卷积层的filter个数是相同的。</p>
<p>如果我们的步长移动与filter的大小不适合，导致不能正好移动到边缘怎么办？</p>
<p><img data-src="trash-classification/%E5%A4%9A%E4%B8%AAFilter.gif" alt="多个Filter"></p>
<p>以上就是卷积层的计算方法。这里面体现了局部连接和权值共享：每层神经元只和上一层部分神经元相连(卷积计算规则)，且filter的权值对于上一层所有神经元都是一样的。</p>
<p><strong>总结输出大小</strong></p>
<ul>
<li>输入体积大小$H_1<em>W_1</em>D_1$</li>
<li>四个超参数：<ul>
<li>Filter数量<em>K</em></li>
<li>Filter大小<em>F</em></li>
<li>步长<em>S</em></li>
<li>零填充大小<em>P</em></li>
</ul>
</li>
<li>输出体积大小$H_2<em>W_2</em>D_2$<ul>
<li>$H_2 = (H_1 - F + 2P)/S + 1$</li>
<li>$W_2 = (W_1 - F + 2P)/S + 1$</li>
<li>$D_2 = K$</li>
</ul>
</li>
</ul>
<h4 id="激活函数-Relu"><a href="#激活函数-Relu" class="headerlink" title="激活函数-Relu"></a>激活函数-Relu</h4><p>一般在进行卷积之后就会提供给激活函数得到一个输出值。我们不使用$sigmoid$，$softmax$，而使用$Relu$。该激活函数的定义是：</p>
<p>$f(u)= max(0,u)$</p>
<p>Relu函数如下：</p>
<p><img data-src="trash-classification/Relu.png" alt="Relu"></p>
<p><strong>特点</strong></p>
<ul>
<li>速度快：与sigmoid函数需要计算指数和倒数相比，relu函数其实就是一个max(0,u)，计算代价小很多</li>
<li>稀疏性： 因为relu函数在输入小于0时是完全不激活的，因此可以获得一个更低的激活率。</li>
</ul>
<h4 id="池化计算"><a href="#池化计算" class="headerlink" title="池化计算"></a>池化计算</h4><p>池化层主要的作用是下采样，通过去掉Feature Map中不重要的样本，进一步减少参数数量。池化的方法很多，最常用的是Max Pooling。Max Pooling实际上就是在$n$个样本中取最大值，作为采样后的样本值。下图是max pooling：</p>
<p><img data-src="trash-classification/Pooling.png" alt="Pooling"></p>
<p>除了Max Pooing之外，常用的还有Mean Pooling——取各样本的平均值。对于深度为D的Feature Map，各层独立做Pooling，因此Pooling后的深度仍然为D。</p>
<h4 id="全连接层"><a href="#全连接层" class="headerlink" title="全连接层"></a>全连接层</h4><p>前面的卷积和池化相当于做特征工程，后面的全连接相当于做特征加权，最后的全连接层在整个卷积神经网络中起到“分类器”的作用。</p>
<h3 id="实例探究"><a href="#实例探究" class="headerlink" title="实例探究"></a>实例探究</h3><p>卷积网络领域有几种架构，名称。最常见的是：</p>
<ul>
<li>LeNet：卷积网络的第一个成功应用是由Yann LeCun于1990年代开发的。其中最著名的是LeNet架构，用于读取邮政编码，数字等。</li>
<li>AlexNet：卷积网络在计算机视觉中的第一个应用是AlexNet，由亚历克斯·克里维斯基，伊利亚·萨茨基弗和吉奥夫·欣顿发展。AlexNet在2012年被提交给ImageNet ILSVRC挑战，明显优于第二名。该网络与LeNet具有非常相似的体系结构，但是使用更多层数，更大和更具特色的卷积层。</li>
<li>ZFNet。ILSVRC 2013获奖者是Matthew Zeiler和Rob Fergus的卷积网络。它被称为ZFNet（Zeiler＆Fergus Net的缩写）。通过调整架构超参数，特别是通过扩展中间卷积层的大小，使第一层的步幅和过滤器尺寸更小，对AlexNet的改进。</li>
<li>GoogleNet。ILSVRC 2014获奖者是Szegedy等人的卷积网络。来自Google。其主要贡献是开发一个初始模块，大大减少了网络中的参数数量（4M，与AlexNet的60M相比）。GoogLeNet还有几个后续版本，最近的是Inception-v4。</li>
<li>VGGNet。2011年ILSVRC的亚军是来自Karen Simonyan和Andrew Zisserman的网络，被称为VGGNet。它的主要贡献在于表明网络的深度是良好性能的关键组成部分。他们最终的网络包含16个CONV / FC层，并且具有非常均匀的架构，从始至终只能执行3x3卷积和2x2池化。VGGNet的缺点是使用更多的内存和参数更多。</li>
<li>ResNet。Kaiming He等人开发的残差网络 是ILSVRC 2015的获胜者。它大量使用特殊的跳过连接和批量归一化。该架构在网络末端也没有使用全连接层。ResNets目前是迄今为止最先进的卷积神经网络模型。</li>
</ul>
<p>下面就是VGGNet的结构：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">INPUT: [224x224x3]        memory:  224*224*3&#x3D;150K   weights: 0</span><br><span class="line">CONV3-64: [224x224x64]  memory:  224*224*64&#x3D;3.2M   weights: (3*3*3)*64 &#x3D; 1,728</span><br><span class="line">CONV3-64: [224x224x64]  memory:  224*224*64&#x3D;3.2M   weights: (3*3*64)*64 &#x3D; 36,864</span><br><span class="line">POOL2: [112x112x64]  memory:  112*112*64&#x3D;800K   weights: 0</span><br><span class="line">CONV3-128: [112x112x128]  memory:  112*112*128&#x3D;1.6M   weights: (3*3*64)*128 &#x3D; 73,728</span><br><span class="line">CONV3-128: [112x112x128]  memory:  112*112*128&#x3D;1.6M   weights: (3*3*128)*128 &#x3D; 147,456</span><br><span class="line">POOL2: [56x56x128]  memory:  56*56*128&#x3D;400K   weights: 0</span><br><span class="line">CONV3-256: [56x56x256]  memory:  56*56*256&#x3D;800K   weights: (3*3*128)*256 &#x3D; 294,912</span><br><span class="line">CONV3-256: [56x56x256]  memory:  56*56*256&#x3D;800K   weights: (3*3*256)*256 &#x3D; 589,824</span><br><span class="line">CONV3-256: [56x56x256]  memory:  56*56*256&#x3D;800K   weights: (3*3*256)*256 &#x3D; 589,824</span><br><span class="line">POOL2: [28x28x256]  memory:  28*28*256&#x3D;200K   weights: 0</span><br><span class="line">CONV3-512: [28x28x512]  memory:  28*28*512&#x3D;400K   weights: (3*3*256)*512 &#x3D; 1,179,648</span><br><span class="line">CONV3-512: [28x28x512]  memory:  28*28*512&#x3D;400K   weights: (3*3*512)*512 &#x3D; 2,359,296</span><br><span class="line">CONV3-512: [28x28x512]  memory:  28*28*512&#x3D;400K   weights: (3*3*512)*512 &#x3D; 2,359,296</span><br><span class="line">POOL2: [14x14x512]  memory:  14*14*512&#x3D;100K   weights: 0</span><br><span class="line">CONV3-512: [14x14x512]  memory:  14*14*512&#x3D;100K   weights: (3*3*512)*512 &#x3D; 2,359,296</span><br><span class="line">CONV3-512: [14x14x512]  memory:  14*14*512&#x3D;100K   weights: (3*3*512)*512 &#x3D; 2,359,296</span><br><span class="line">CONV3-512: [14x14x512]  memory:  14*14*512&#x3D;100K   weights: (3*3*512)*512 &#x3D; 2,359,296</span><br><span class="line">POOL2: [7x7x512]  memory:  7*7*512&#x3D;25K  weights: 0</span><br><span class="line">FC: [1x1x4096]  memory:  4096  weights: 7*7*512*4096 &#x3D; 102,760,448</span><br><span class="line">FC: [1x1x4096]  memory:  4096  weights: 4096*4096 &#x3D; 16,777,216</span><br><span class="line">FC: [1x1x1000]  memory:  1000 weights: 4096*1000 &#x3D; 4,096,000</span><br><span class="line"></span><br><span class="line">TOTAL memory: 24M * 4 bytes ~&#x3D; 93MB &#x2F; image (only forward! ~*2 for bwd)</span><br><span class="line">TOTAL params: 138M parameters</span><br></pre></td></tr></table></figure>



<h2 id="Inception-ResNet-v2介绍"><a href="#Inception-ResNet-v2介绍" class="headerlink" title="Inception-ResNet-v2介绍"></a>Inception-ResNet-v2介绍</h2><h3 id="Inception"><a href="#Inception" class="headerlink" title="Inception"></a>Inception</h3><p><strong>问题：</strong></p>
<ul>
<li>图像中突出部分的大小差别很大。例如，狗的图像可以是以下任意情况。每张图像中狗所占区域都是不同的。</li>
</ul>
<p><img data-src="trash-classification/1527656989598.png" alt="img"></p>
<p><em>从左到右：狗占据图像的区域依次减小</em></p>
<ul>
<li>由于信息位置的巨大差异，为卷积操作选择合适的卷积核大小就比较困难。信息分布更全局性的图像偏好较大的卷积核，信息分布比较局部的图像偏好较小的卷积核。</li>
<li>非常深的网络更容易过拟合。将梯度更新传输到整个网络是很困难的。</li>
<li>简单地堆叠较大的卷积层非常消耗计算资源。</li>
</ul>
<p><strong>解决方案：</strong></p>
<p>为什么不在同一层级上运行具备多个尺寸的滤波器呢？网络本质上会变得稍微「宽一些」，而不是「更深」。作者因此设计了 Inception 模块。</p>
<p>下图是「原始」Inception 模块。它使用 3 个不同大小的滤波器（1x1、3x3、5x5）对输入执行卷积操作，此外它还会执行最大池化。所有子层的输出最后会被级联起来，并传送至下一个 Inception 模块。</p>
<p><img data-src="trash-classification/1527656989203.png" alt="img"></p>
<p><em>原始 Inception 模块。</em></p>
<h3 id="ResNet"><a href="#ResNet" class="headerlink" title="ResNet"></a>ResNet</h3><p>随着网络的加深，出现了训练集准确率下降的现象，因为梯度反向传播到前面的层，重复相乘可能使梯度无穷小。结果就是，随着网络的层数更深，其性能趋于饱和，甚至开始迅速下降。所以作者针对这个问题提出了一种全新的网络，叫深度残差网络（ResNet）其核心思想是引入一个所谓的「恒等快捷连接」（identity shortcut connection），直接跳过一个或多个层，如下图所示：</p>
<p> <img data-src="trash-classification/ResNet.png" alt="img"></p>
<h3 id="Inception-ResNet-v2"><a href="#Inception-ResNet-v2" class="headerlink" title="Inception-ResNet-v2"></a>Inception-ResNet-v2</h3><p>Google团队发布**Inception-ResNet-v2，它在ILSVRC图像分类基准测试中实现了当下最好的成绩。Inception-ResNet-v2是早期Inception V3模型变化而来，从微软的残差网络（ResNet）论文中得到了一些灵感。</p>
<p><img data-src="trash-classification/90.jpeg"></p>
<h2 id="使用Inception-ResNet-v2进行垃圾分类"><a href="#使用Inception-ResNet-v2进行垃圾分类" class="headerlink" title="使用Inception-ResNet-v2进行垃圾分类"></a>使用Inception-ResNet-v2进行垃圾分类</h2><h3 id="数据集介绍-1"><a href="#数据集介绍-1" class="headerlink" title="数据集介绍"></a>数据集介绍</h3><p>下载链接<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2dhcnl0aHVuZy90cmFzaG5ldC9ibG9iL21hc3Rlci9kYXRhL2RhdGFzZXQtcmVzaXplZC56aXA=">https://github.com/garythung/trashnet/blob/master/data/dataset-resized.zip<i class="fa fa-external-link-alt"></i></span></p>
<p>数据集一共分了六个类别，分别是：cardboard glass metal paper plastic trash，一共2527个样本</p>
<p><img data-src="trash-classification/glass108.jpg" alt="glass108"></p>
<p><em>glass样本示例</em></p>
<h3 id="处理流程"><a href="#处理流程" class="headerlink" title="处理流程"></a>处理流程</h3><h4 id="数据预处理："><a href="#数据预处理：" class="headerlink" title="数据预处理："></a>数据预处理：</h4><ul>
<li><p>设置数据类别</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">class_names_to_ids = &#123;<span class="string">&#x27;cardboard&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;glass&#x27;</span>: <span class="number">1</span>, <span class="string">&#x27;metal&#x27;</span>: <span class="number">2</span>, <span class="string">&#x27;paper&#x27;</span>:<span class="number">3</span>, <span class="string">&#x27;plastic&#x27;</span>:<span class="number">4</span>, <span class="string">&#x27;trash&#x27;</span>:<span class="number">5</span>&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>把文件名及类别写入文件</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line">data_dir = <span class="string">&#x27;dataset/&#x27;</span></span><br><span class="line">output_path = <span class="string">&#x27;list.txt&#x27;</span></span><br><span class="line">fd = open(output_path, <span class="string">&#x27;w&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> class_name <span class="keyword">in</span> class_names_to_ids.keys():</span><br><span class="line">    images_list = os.listdir(data_dir + class_name)</span><br><span class="line">    <span class="keyword">for</span> image_name <span class="keyword">in</span> images_list:</span><br><span class="line">        fd.write(<span class="string">&#x27;&#123;&#125;/&#123;&#125; &#123;&#125;\n&#x27;</span>.format(class_name, image_name, class_names_to_ids[class_name]))</span><br><span class="line">fd.close()</span><br></pre></td></tr></table></figure>

<ul>
<li>划分训练集合测试集</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 随机选取样本做训练集和测试集</span></span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line">_NUM_VALIDATION = <span class="number">505</span></span><br><span class="line">_RANDOM_SEED = <span class="number">0</span></span><br><span class="line">list_path = <span class="string">&#x27;list.txt&#x27;</span></span><br><span class="line">train_list_path = <span class="string">&#x27;list_train.txt&#x27;</span></span><br><span class="line">val_list_path = <span class="string">&#x27;list_val.txt&#x27;</span></span><br><span class="line">fd = open(list_path)</span><br><span class="line">lines = fd.readlines()</span><br><span class="line">fd.close()</span><br><span class="line">random.seed(_RANDOM_SEED)</span><br><span class="line">random.shuffle(lines)</span><br><span class="line">fd = open(train_list_path, <span class="string">&#x27;w&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> lines[_NUM_VALIDATION:]:</span><br><span class="line">    fd.write(line)</span><br><span class="line">fd.close()</span><br><span class="line">fd = open(val_list_path, <span class="string">&#x27;w&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> lines[:_NUM_VALIDATION]:</span><br><span class="line">    fd.write(line)</span><br><span class="line">fd.close()</span><br></pre></td></tr></table></figure>

<ul>
<li><p>加载数据</p>
<ul>
<li>解析训练集测试集文件名</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_train_test_data</span>(<span class="params">list_file</span>):</span></span><br><span class="line">    list_train = open(list_file)</span><br><span class="line">    x_train = []</span><br><span class="line">    y_train = []</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> list_train.readlines():</span><br><span class="line">        x_train.append(line.strip()[:<span class="number">-2</span>])</span><br><span class="line">        y_train.append(int(line.strip()[<span class="number">-1</span>]))</span><br><span class="line">        <span class="comment">#print(line.strip())</span></span><br><span class="line">    <span class="keyword">return</span> x_train, y_train</span><br><span class="line">x_train, y_train = get_train_test_data(<span class="string">&#x27;list_train.txt&#x27;</span>)</span><br><span class="line">x_test, y_test = get_train_test_data(<span class="string">&#x27;list_val.txt&#x27;</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li>加载并预处理数据</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">process_train_test_data</span>(<span class="params">x_path</span>):</span></span><br><span class="line">    images = []</span><br><span class="line">    <span class="keyword">for</span> image_path <span class="keyword">in</span> x_path:</span><br><span class="line">        img_load = load_img(<span class="string">&#x27;dataset/&#x27;</span>+image_path)</span><br><span class="line">        img = image.img_to_array(img_load)</span><br><span class="line">        img = preprocess_input(img)</span><br><span class="line">        images.append(img)</span><br><span class="line">    <span class="keyword">return</span> images</span><br><span class="line">train_images = process_train_test_data(x_train)</span><br><span class="line">test_images = process_train_test_data(x_test)</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h4 id="构造模型"><a href="#构造模型" class="headerlink" title="构造模型"></a>构造模型</h4><p>这里使用预先keras中已经训练好的InceptionResNetV2模型，模型的最后一层全连接层加载模型时不加载，按照我们需要分类的类别数进行设置。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.applications.inception_resnet_v2 <span class="keyword">import</span> InceptionResNetV2</span><br><span class="line">base_model = InceptionResNetV2(include_top=<span class="literal">False</span>, pooling=<span class="string">&#x27;avg&#x27;</span>)</span><br><span class="line">outputs = Dense(<span class="number">6</span>, activation=<span class="string">&#x27;softmax&#x27;</span>)(base_model.output)</span><br><span class="line">model = Model(base_model.inputs, outputs)</span><br></pre></td></tr></table></figure>

<h4 id="模型训练与保存"><a href="#模型训练与保存" class="headerlink" title="模型训练与保存"></a>模型训练与保存</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 设置ModelCheckpoint，按照验证集的准确率进行保存</span></span><br><span class="line">save_dir=<span class="string">&#x27;train_model&#x27;</span></span><br><span class="line">filepath=<span class="string">&quot;model_&#123;epoch:02d&#125;-&#123;val_acc:.2f&#125;.hdf5&quot;</span></span><br><span class="line">checkpoint = ModelCheckpoint(os.path.join(save_dir, filepath), monitor=<span class="string">&#x27;val_acc&#x27;</span>,verbose=<span class="number">1</span>, </span><br><span class="line">                            save_best_only=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># 模型设置</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">acc_top3</span>(<span class="params">y_true, y_pred</span>):</span></span><br><span class="line">    <span class="keyword">return</span> top_k_categorical_accuracy(y_true, y_pred, k=<span class="number">3</span>)</span><br><span class="line">  </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">acc_top5</span>(<span class="params">y_true, y_pred</span>):</span></span><br><span class="line">    <span class="keyword">return</span> top_k_categorical_accuracy(y_true, y_pred, k=<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">model.compile(optimizer=<span class="string">&#x27;adam&#x27;</span>,</span><br><span class="line">              loss=<span class="string">&#x27;categorical_crossentropy&#x27;</span>,</span><br><span class="line">              metrics=[<span class="string">&#x27;accuracy&#x27;</span>, acc_top3, acc_top5])</span><br><span class="line"><span class="comment"># 模型训练</span></span><br><span class="line">model.fit(np.array(train_images), to_categorical(y_train),</span><br><span class="line">          batch_size=<span class="number">8</span>,</span><br><span class="line">          epochs=<span class="number">5</span>,</span><br><span class="line">          shuffle=<span class="literal">True</span>,</span><br><span class="line">          validation_data=(np.array(test_images), to_categorical(y_test)),</span><br><span class="line">          callbacks=[checkpoint])</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 训练结果输出示例</span></span><br><span class="line">Train on 2022 samples, validate on 505 samples</span><br><span class="line">Epoch 1/5</span><br><span class="line">2022/2022 [==============================] - 238s 118ms/step - loss: 0.1213 - acc: 0.9629 - acc_top3: 0.9970 - acc_top5: 0.9990 - val_loss: 0.6070 - val_acc: 0.8653 - val_acc_top3: 0.9644 - val_acc_top5: 0.9921</span><br><span class="line">Epoch 00001: val_acc improved from 0.86139 to 0.86535, saving model to train_model/model_01-0.87.hdf5</span><br></pre></td></tr></table></figure>

<h4 id="模型加载与预测"><a href="#模型加载与预测" class="headerlink" title="模型加载与预测"></a>模型加载与预测</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 加载指定模型</span></span><br><span class="line">model.load_weights(<span class="string">&#x27;train_model/model_01-0.87.hdf5&#x27;</span>)</span><br><span class="line"><span class="comment"># 直接使用predict方法进行预测</span></span><br><span class="line">y_pred = model.predict(np.array(test_images))</span><br></pre></td></tr></table></figure>

<h3 id="结果分析"><a href="#结果分析" class="headerlink" title="结果分析"></a>结果分析</h3><p>可以看到在验证集上的top1准确率是86.53%，top3的准确率是96.44%，相比于Inception-ResNet-v2模型本身的准确率有一些提升，也说明我们在Inception-ResNet-v2微调之后的这个垃圾分类模型充分利用了原模型已经学习到的规律，并对我们这个特定数据集有很好的预测能力。</p>
<h2 id="附件"><a href="#附件" class="headerlink" title="附件"></a>附件</h2><p>相关链接：</p>
<ul>
<li><span class="exturl" data-url="aHR0cHM6Ly93d3cuYmlsaWJpbGkuY29tL3ZpZGVvL2F2NjU2OTc0NjA=">https://www.bilibili.com/video/av65697460<i class="fa fa-external-link-alt"></i></span></li>
</ul>
]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>Tensorflow</tag>
        <tag>Keras</tag>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>如何在Ubuntu上安装配置Hadoop</title>
    <url>//posts/ubuntu-hadoop.html</url>
    <content><![CDATA[<h1 id="版本"><a href="#版本" class="headerlink" title="版本"></a>版本</h1><ul>
<li>JDK: 8u221</li>
<li>Hadoop: 3.1.2</li>
</ul>
<h1 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h1><p>首先<span class="exturl" data-url="aHR0cHM6Ly9oYWRvb3AuYXBhY2hlLm9yZy9yZWxlYXNlcy5odG1s">点击这里<i class="fa fa-external-link-alt"></i></span>，进入Hadoop官网下载页面。</p>
<p><img data-src="ubuntu-hadoop/01.png" alt="Hadoop下载页面"></p>
<p>选择3.0.3版本进行下载，然后点击binary地址进行下载</p>
<p><img data-src="ubuntu-hadoop/02.png" alt="Hadoop镜像选择页面"></p>
<p>选中官方推荐的地址即可下载，其他地址也可用（建议采用迅雷等下载工具下载，速度比较会快很多，上传至UBUNTU系统）</p>
<p>或者使用<code>wget</code>命令进行下载</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">wget http:&#x2F;&#x2F;mirror.bit.edu.cn&#x2F;apache&#x2F;hadoop&#x2F;common&#x2F;hadoop-3.1.2&#x2F;hadoop-3.1.2.tar.gz</span><br></pre></td></tr></table></figure>

<h1 id="HOSTS"><a href="#HOSTS" class="headerlink" title="HOSTS"></a>HOSTS</h1><p>Hosts是一个没有扩展名的系统文件，可以用记事本等工具打开，其作用就是将一些常用的网址域名与其对应的IP地址建立一个关联“数据库”，当用户在浏览器中输入一个需要登录的网址时，系统会首先自动从Hosts文件中寻找对应的IP地址，一旦找到，系统会立即打开对应网页，如果没有找到，则系统会再将网址提交DNS域名解析服务器进行IP地址的解析。</p>
<p>为了机器能够快速识别自己以及其他机器，我们可以做一下域名和IP的hosts映射，这样在之后的操作中，我们就可以直接用域名来代替IP地址</p>
<h2 id="伪分布模式"><a href="#伪分布模式" class="headerlink" title="伪分布模式"></a>伪分布模式</h2><p>使用<code>vi /etc/hosts</code>命令添加master映射，并修改localhost</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">本机IP localhost</span><br><span class="line">本机IP master</span><br></pre></td></tr></table></figure>

<h2 id="全分布模式"><a href="#全分布模式" class="headerlink" title="全分布模式"></a>全分布模式</h2><p>全分布模式下，需要你在每一台机器都设置好hosts，例如我有三台机器，IP分别为<code>192.168.0.1</code> <code>192.168.0.2</code> <code>192.168.0.3</code>，那么master主节点机器的hosts内容就如下进行设置</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">192.168.0.1 localhost</span><br><span class="line"></span><br><span class="line">192.168.0.1 master</span><br><span class="line">192.168.0.2 slave1</span><br><span class="line">192.168.0.3 slave1</span><br></pre></td></tr></table></figure>

<p>方便计算机互相连接</p>
<h1 id="SSH"><a href="#SSH" class="headerlink" title="SSH"></a>SSH</h1><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>SSH 为 Secure Shell 的缩写，由 IETF 的网络小组（Network Working Group）所制定；SSH 为建立在应用层基础上的安全协议。SSH 是目前较可靠，专为远程登录会话和其他网络服务提供安全性的协议。</p>
<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>Ubuntu中一般默认安装了ssh，如果没有安装，可以使用下面的命令进行安装</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo apt-get install openssh-server</span><br></pre></td></tr></table></figure>

<p><img data-src="ubuntu-hadoop/03.png" alt="SSH安装"></p>
<p>由于我的Ubuntu服务器已经安装好了SSH，所以提示我无需安装。安装好后，我们需要启动一下SSH服务。</p>
<h2 id="查看并启动SSH"><a href="#查看并启动SSH" class="headerlink" title="查看并启动SSH"></a>查看并启动SSH</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo ps -e | grep ssh</span><br></pre></td></tr></table></figure>

<p>其中<code>ps -e</code>表示查看当前的进程，-e表示显示全部，效果同-A<br><code>grep ssh</code>即<code>grep match_pattern</code>，是正则表达式，它会获取包含<strong>match_pattern</strong>的文本段</p>
<p><img data-src="ubuntu-hadoop%5C04.png" alt="查看ssh服务"></p>
<p>当有类似如上结果显示时，表示服务器的SSH服务正在运行中。如果没有则需要<strong>启动SSH</strong>服务，可以运行下面的命令：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">service ssh start</span><br></pre></td></tr></table></figure>

<p>或者</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">service ssh restart</span><br></pre></td></tr></table></figure>

<h2 id="查看并修改SSH设置"><a href="#查看并修改SSH设置" class="headerlink" title="查看并修改SSH设置"></a>查看并修改SSH设置</h2><p>SSH的配置文件一般在<code>/etc/ssh/sshd_config</code>中</p>
<p>可以使用下面的命令编辑，或者使用<code>gedit</code>编辑</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">vi &#x2F;etc&#x2F;ssh&#x2F;sshd_config</span><br></pre></td></tr></table></figure>

<p>老版本的话，可能需要做如下修改才行。如果有<code>PermitRootLogin without-password</code>,加一个”#”号，注释掉该行，并增加一句<code>PermitRootLogin yes</code></p>
<h2 id="生成密钥对"><a href="#生成密钥对" class="headerlink" title="生成密钥对"></a>生成密钥对</h2><p>使用下面的命令</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ssh-keygen  -t rsa</span><br></pre></td></tr></table></figure>

<p>该命令将在~/.ssh目录下面产生一个密钥id_rsa和一个公钥id_rsa.pub<br>将你的计算机(A)中的公钥传给别的计算机(B)，你才能免密码登录到计算机B</p>
<h2 id="免密登录本机"><a href="#免密登录本机" class="headerlink" title="免密登录本机"></a>免密登录本机</h2><p>首先使用下面的命令，将公钥发放给自己</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cp ~&#x2F;.ssh&#x2F;id_rsa.pub ~&#x2F;.ssh&#x2F;authorized_keys</span><br></pre></td></tr></table></figure>

<p>你可以进入<code>~/.ssh/</code>路径下，更方便的进行操作</p>
<p>需要查看<code>authorized_keys</code>文件的权限，需要保证是600,</p>
<p>如果权限不正确，请使用下面的命令</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">chmod 600 authorized_keys</span><br></pre></td></tr></table></figure>

<p>然后使用下面的命令，免密连接本机</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ssh localhost</span><br></pre></td></tr></table></figure>

<p><img data-src="ubuntu-hadoop%5C05.png" alt="ssh免密登录"></p>
<p>当有类似结果如上图所示，表示你已经可以成功免密登录了</p>
<h2 id="全分布模式-免密登录到别的计算机）"><a href="#全分布模式-免密登录到别的计算机）" class="headerlink" title="全分布模式(免密登录到别的计算机）"></a>全分布模式(免密登录到别的计算机）</h2><p>如果你需要登录到别的计算机，你需要将<code>id_rsa.pub</code>发送给别的电脑同样的路径，保存到<code>authorized_keys</code>文件中，如果对方计算机也要免密登录到你的计算机，也需要将它的<code>id_rsa.pub</code>发送到你的电脑同样的路径，保存到<code>authorized_keys</code>文件中</p>
<p>如果是多个计算机，比如三个（master slave1 slave2）,最方便的方法就是，每台计算机先运行<code>ssh-keygen  -t rsa</code>生成<code>id_rsa.pub</code>文件，然后创建一个记事本，将3个<code>id_rsa.pub</code>文件中的内容都保存起来，然后重命名为<code>authorized_keys</code>，然后使用下面<code>scp</code>命令，直接发放给每台计算机，发放时需要输入每天计算机密码，设置完毕后，再进行传输就不需要了</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">scp ~&#x2F;.ssh&#x2F;authorized_keys slave1:~&#x2F;.ssh&#x2F;authorized_keys</span><br><span class="line">scp ~&#x2F;.ssh&#x2F;authorized_keys slave2:~&#x2F;.ssh&#x2F;authorized_keys</span><br></pre></td></tr></table></figure>

<p><strong>记得检查权限</strong></p>
<h1 id="环境配置"><a href="#环境配置" class="headerlink" title="环境配置"></a>环境配置</h1><p>下载完毕后，使用下面的命令，将hadoop解压出来，并移动到合适的位置，我解压到了<code>/opt</code>目录下</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">tar -zxvf .&#x2F;hadoop-3.1.2.tar.gz -C &#x2F;opt</span><br></pre></td></tr></table></figure>

<p>之后，需要配置以下的环境变量</p>
<p>使用vi命令编辑<code>vi /etc/profile</code>，添加下面的环境变量</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># HADOOP</span><br><span class="line">export HADOOP_HOME&#x3D;&#x2F;opt&#x2F;hadoop-3.1.2</span><br><span class="line">export HADOOP_CONF_DIR&#x3D;$&#123;HADOOP_HOME&#125;&#x2F;etc&#x2F;hadoop</span><br><span class="line">export PATH&#x3D;$&#123;HADOOP_HOME&#125;&#x2F;bin:$&#123;HADOOP_HOME&#125;&#x2F;sbin:$PATH</span><br></pre></td></tr></table></figure>

<p>添加完毕保存后，使用<code>source /etc/profile</code>更新环境变量</p>
<p>更新环境变量后，可以命令<code>hdfs</code>来检查环境变量是否配置成功</p>
<p><img data-src="ubuntu-hadoop%5C06.png" alt="hdfs检查"></p>
<p>当有类似的命令提示如上图所示，表示你已经成功配置好环境变量了</p>
<h1 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h1><p>hadoop的部署分为3种模式，分别为<strong>单机模式</strong> <strong>伪分布模式(单节点)</strong> <strong>全分布模式</strong>三种</p>
<p>无论部署哪种模式，我们都需要先配置环境变量，我们选择配置系统变量，无论是否是当前路径都可以使用</p>
<h2 id="单机模式"><a href="#单机模式" class="headerlink" title="单机模式"></a>单机模式</h2><p>如果你只是进行单节点运行，那么你现在已经完成安装了，不需要启动，可以直接进入测试环节</p>
<h2 id="伪分布模式-1"><a href="#伪分布模式-1" class="headerlink" title="伪分布模式"></a>伪分布模式</h2><p>首先打开<code>/opt/hadoop-3.2.0/etc/hadoop</code>这个目录，分别编辑下面几个文件，根据个人需求更改参数：</p>
<h3 id="core-site-xml"><a href="#core-site-xml" class="headerlink" title="core-site.xml"></a>core-site.xml</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">  # 配置hdfs的namenode的地址，使用的是hdfs协议</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;fs.defaultFS&lt;&#x2F;name&gt;</span><br><span class="line">    &lt;value&gt;hdfs:&#x2F;&#x2F;master:9000&lt;&#x2F;value&gt;</span><br><span class="line">  &lt;&#x2F;property&gt;</span><br><span class="line">  # 配置hadoop运行时产生数据的存储目录，不是临时目录</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;hadoop.tmp.dir&lt;&#x2F;name&gt;</span><br><span class="line">    &lt;value&gt;&#x2F;opt&#x2F;tmp&lt;&#x2F;value&gt;</span><br><span class="line">  &lt;&#x2F;property&gt;</span><br><span class="line">&lt;&#x2F;configuration&gt;</span><br></pre></td></tr></table></figure>

<p>master在hosts文件中做了映射，可以替换成本机IP</p>
<p>hadoop有时候并不能自己创建namenode和datanode文件夹，可以运行下面的命令手动创建这2个文件夹</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mkdir -p &#x2F;opt&#x2F;data&#x2F;namenode</span><br><span class="line">mkdir -p &#x2F;opt&#x2F;data&#x2F;datanode</span><br><span class="line">mkdir -p &#x2F;opt&#x2F;tmp</span><br></pre></td></tr></table></figure>

<h3 id="hdfs-site-xml"><a href="#hdfs-site-xml" class="headerlink" title="hdfs-site.xml"></a>hdfs-site.xml</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">  # 配置在hdfs中，一份文件存几份，默认是3份，一台机器只能存一份，伪分布设置为1</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.replication&lt;&#x2F;name&gt;</span><br><span class="line">    &lt;value&gt;1&lt;&#x2F;value&gt;</span><br><span class="line">  &lt;&#x2F;property&gt;</span><br><span class="line">  # 是否打开权限检查系统</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.permissions&lt;&#x2F;name&gt;</span><br><span class="line">    &lt;value&gt;false&lt;&#x2F;value&gt;</span><br><span class="line">  &lt;&#x2F;property&gt;</span><br><span class="line">  # 命名空间和事务在本地文件系统永久存储的路径</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.namenode.name.dir&lt;&#x2F;name&gt;</span><br><span class="line">    &lt;value&gt;&#x2F;opt&#x2F;data&#x2F;namenode&lt;&#x2F;value&gt;</span><br><span class="line">  &lt;&#x2F;property&gt;</span><br><span class="line">  # DataNode在本地文件系统中存放块的路径</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.datanode.data.dir&lt;&#x2F;name&gt;</span><br><span class="line">    &lt;value&gt;&#x2F;opt&#x2F;data&#x2F;datanode&lt;&#x2F;value&gt;</span><br><span class="line">  &lt;&#x2F;property&gt;</span><br><span class="line">&lt;&#x2F;configuration&gt;</span><br></pre></td></tr></table></figure>

<h3 id="yarn-site-xml"><a href="#yarn-site-xml" class="headerlink" title="yarn-site.xml"></a>yarn-site.xml</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">  # 指定yarn的resourcemanager的地址（该地址是resourcemanager的主机地址，即主机名或该主机的ip地址）</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.resourcemanager.hostname&lt;&#x2F;name&gt;</span><br><span class="line">    &lt;value&gt;master&lt;&#x2F;value&gt;</span><br><span class="line">  &lt;&#x2F;property&gt;</span><br><span class="line">  # 指定mapreduce执行shuffle时获取数据的方式</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.nodemanager.aux-services&lt;&#x2F;name&gt;</span><br><span class="line">    &lt;value&gt;mapreduce_shuffle&lt;&#x2F;value&gt;</span><br><span class="line">  &lt;&#x2F;property&gt;</span><br><span class="line">&lt;&#x2F;configuration&gt;</span><br></pre></td></tr></table></figure>

<h3 id="mapred-site-xml"><a href="#mapred-site-xml" class="headerlink" title="mapred-site.xml"></a>mapred-site.xml</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">  # 指定mapreduce运行在yarn上</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;mapreduce.framework.name&lt;&#x2F;name&gt;</span><br><span class="line">    &lt;value&gt;yarn&lt;&#x2F;value&gt;</span><br><span class="line">  &lt;&#x2F;property&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.app.mapreduce.am.env&lt;&#x2F;name&gt;</span><br><span class="line">    &lt;value&gt;HADOOP_MAPRED_HOME&#x3D;&#x2F;opt&#x2F;hadoop-3.1.2&lt;&#x2F;value&gt;</span><br><span class="line">  &lt;&#x2F;property&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;mapreduce.map.env&lt;&#x2F;name&gt;</span><br><span class="line">    &lt;value&gt;HADOOP_MAPRED_HOME&#x3D;&#x2F;opt&#x2F;hadoop-3.1.2&lt;&#x2F;value&gt;</span><br><span class="line">  &lt;&#x2F;property&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;mapreduce.reduce.env&lt;&#x2F;name&gt;</span><br><span class="line">    &lt;value&gt;HADOOP_MAPRED_HOME&#x3D;&#x2F;opt&#x2F;hadoop-3.1.2&lt;&#x2F;value&gt;</span><br><span class="line">  &lt;&#x2F;property&gt;</span><br><span class="line">&lt;&#x2F;configuration&gt;</span><br></pre></td></tr></table></figure>

<h3 id="hadoop-env-sh"><a href="#hadoop-env-sh" class="headerlink" title="hadoop-env.sh"></a>hadoop-env.sh</h3><p>在任意地方添加JAVA_HOME</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">export JAVA_HOME&#x3D;你的JDK安装地址</span><br></pre></td></tr></table></figure>

<p>所有配置文件修改完毕后，进入hadoop初始化步骤</p>
<h2 id="全分布模式-1"><a href="#全分布模式-1" class="headerlink" title="全分布模式"></a>全分布模式</h2><p>首先打开<code>/opt/hadoop-3.2.0/etc/hadoop</code>这个目录，分别编辑下面几个文件，根据个人需求更改参数：</p>
<h3 id="core-site-xml-1"><a href="#core-site-xml-1" class="headerlink" title="core-site.xml"></a>core-site.xml</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">  # 配置hdfs的namenode的地址，使用的是hdfs协议</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;fs.defaultFS&lt;&#x2F;name&gt;</span><br><span class="line">    &lt;value&gt;hdfs:&#x2F;&#x2F;master:9000&lt;&#x2F;value&gt;</span><br><span class="line">  &lt;&#x2F;property&gt;</span><br><span class="line">  # 配置hadoop运行时产生数据的存储目录，不是临时目录</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;hadoop.tmp.dir&lt;&#x2F;name&gt;</span><br><span class="line">    &lt;value&gt;&#x2F;opt&#x2F;tmp&lt;&#x2F;value&gt;</span><br><span class="line">  &lt;&#x2F;property&gt;</span><br><span class="line">&lt;&#x2F;configuration&gt;</span><br></pre></td></tr></table></figure>

<p>master在hosts文件中做了映射，可以替换成本机IP</p>
<p>hadoop有时候并不能自己创建namenode和datanode文件夹，可以运行下面的命令手动创建这2个文件夹</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mkdir -p &#x2F;opt&#x2F;data&#x2F;namenode</span><br><span class="line">mkdir -p &#x2F;opt&#x2F;data&#x2F;datanode</span><br><span class="line">mkdir -p &#x2F;opt&#x2F;tmp</span><br></pre></td></tr></table></figure>

<h3 id="hdfs-site-xml-1"><a href="#hdfs-site-xml-1" class="headerlink" title="hdfs-site.xml"></a>hdfs-site.xml</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">  # 配置在hdfs中，一份文件存几份，默认是3份，一台机器只能存一份，小于datanode数量</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.replication&lt;&#x2F;name&gt;</span><br><span class="line">    &lt;value&gt;3&lt;&#x2F;value&gt;</span><br><span class="line">  &lt;&#x2F;property&gt;</span><br><span class="line">  # 是否打开权限检查系统</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.permissions&lt;&#x2F;name&gt;</span><br><span class="line">    &lt;value&gt;false&lt;&#x2F;value&gt;</span><br><span class="line">  &lt;&#x2F;property&gt;</span><br><span class="line">  # 命名空间和事务在本地文件系统永久存储的路径</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.namenode.name.dir&lt;&#x2F;name&gt;</span><br><span class="line">    &lt;value&gt;&#x2F;opt&#x2F;data&#x2F;namenode&lt;&#x2F;value&gt;</span><br><span class="line">  &lt;&#x2F;property&gt;</span><br><span class="line">  # DataNode在本地文件系统中存放块的路径</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.datanode.data.dir&lt;&#x2F;name&gt;</span><br><span class="line">    &lt;value&gt;&#x2F;opt&#x2F;data&#x2F;datanode&lt;&#x2F;value&gt;</span><br><span class="line">  &lt;&#x2F;property&gt;</span><br><span class="line">&lt;&#x2F;configuration&gt;</span><br></pre></td></tr></table></figure>

<p>如果你只有3个datanode，但是你却指定副本数为4，是不会生效的，因为每个datanode上只能存放一个副本。</p>
<h3 id="yarn-site-xml-1"><a href="#yarn-site-xml-1" class="headerlink" title="yarn-site.xml"></a>yarn-site.xml</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">  # 指定yarn的resourcemanager的地址（该地址是resourcemanager的主机地址，即主机名或该主机的ip地址）</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.resourcemanager.hostname&lt;&#x2F;name&gt;</span><br><span class="line">    &lt;value&gt;master&lt;&#x2F;value&gt;</span><br><span class="line">  &lt;&#x2F;property&gt;</span><br><span class="line">  # 指定mapreduce执行shuffle时获取数据的方式</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.nodemanager.aux-services&lt;&#x2F;name&gt;</span><br><span class="line">    &lt;value&gt;mapreduce_shuffle&lt;&#x2F;value&gt;</span><br><span class="line">  &lt;&#x2F;property&gt;</span><br><span class="line">&lt;&#x2F;configuration&gt;</span><br></pre></td></tr></table></figure>

<h3 id="mapred-site-xml-1"><a href="#mapred-site-xml-1" class="headerlink" title="mapred-site.xml"></a>mapred-site.xml</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">  # 指定mapreduce运行在yarn上</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;mapreduce.framework.name&lt;&#x2F;name&gt;</span><br><span class="line">    &lt;value&gt;yarn&lt;&#x2F;value&gt;</span><br><span class="line">  &lt;&#x2F;property&gt;</span><br><span class="line">&lt;&#x2F;configuration&gt;</span><br></pre></td></tr></table></figure>

<h3 id="workers"><a href="#workers" class="headerlink" title="workers"></a>workers</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">master</span><br><span class="line">slave1</span><br><span class="line">slave2</span><br></pre></td></tr></table></figure>

<p>老版本文件名为slaves，配置的是所有的从节点，用IP也可以，所有配置文件修改完毕后，进入hadoop初始化步骤</p>
<h1 id="Hadoop初始化"><a href="#Hadoop初始化" class="headerlink" title="Hadoop初始化"></a>Hadoop初始化</h1><h2 id="允许root账户运行"><a href="#允许root账户运行" class="headerlink" title="允许root账户运行"></a>允许root账户运行</h2><p>使用下面的命令进入hadoop脚本路径</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd $HADOOP_HOME&#x2F;sbin&#x2F;</span><br></pre></td></tr></table></figure>

<p>使用<code>vi</code>编辑<code>start-dfs.sh</code>和<code>stop-dfs.sh</code>添加</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">HDFS_DATANODE_USER&#x3D;root </span><br><span class="line">HDFS_DATANODE_SECURE_USER&#x3D;hdfs </span><br><span class="line">HDFS_NAMENODE_USER&#x3D;root </span><br><span class="line">HDFS_SECONDARYNAMENODE_USER&#x3D;root</span><br></pre></td></tr></table></figure>

<p>使用<code>vi</code>编辑<code>start-yarn.sh</code>和<code>stop-yarn.sh</code>添加</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">YARN_RESOURCEMANAGER_USER&#x3D;root</span><br><span class="line">HADOOP_SECURE_DN_USER&#x3D;yarn</span><br><span class="line">YARN_NODEMANAGER_USER&#x3D;root</span><br></pre></td></tr></table></figure>

<p>使用<code>vi</code>编辑<code>hadoop-env.sh</code></p>
<h2 id="hdfs初始化"><a href="#hdfs初始化" class="headerlink" title="hdfs初始化"></a>hdfs初始化</h2><h3 id="伪分布模式-2"><a href="#伪分布模式-2" class="headerlink" title="伪分布模式"></a>伪分布模式</h3><p>然后使用下面的命令初始化hdfs</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hdfs namenode -format</span><br></pre></td></tr></table></figure>
<p><img data-src="ubuntu-hadoop%5C07.png" alt="hdfs检查"></p>
<p>格式化完毕后，如图所示，则表示初始化成功，如果初始化失败，需要用下面的命令手动清空namenode和datanode文件夹，调整配置后，重新初始化</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">rm -rf &#x2F;opt&#x2F;data&#x2F;namenode&#x2F;*</span><br><span class="line">rm -rf &#x2F;opt&#x2F;data&#x2F;datanode&#x2F;*</span><br></pre></td></tr></table></figure>

<h3 id="全分布模式-2"><a href="#全分布模式-2" class="headerlink" title="全分布模式"></a>全分布模式</h3><p>集群模式下，不能能只在主机进行hdfs初始化，还需要到每一台机子中运行下面的命令进行hdfs初始化</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hdfs namenode -format</span><br></pre></td></tr></table></figure>

<h1 id="启动Hadoop"><a href="#启动Hadoop" class="headerlink" title="启动Hadoop"></a>启动Hadoop</h1><h2 id="伪分布模式-3"><a href="#伪分布模式-3" class="headerlink" title="伪分布模式"></a>伪分布模式</h2><p>初始化完毕后，我们就可以使用下面的命令启动hadoop了</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">start-yarn.sh &amp; start-dfs.sh</span><br></pre></td></tr></table></figure>

<p><img data-src="ubuntu-hadoop/08.png" alt="JPS"></p>
<p>启动完毕后可以使用<code>jps</code>命令查看启动的hadoop进程</p>
<p><img data-src="ubuntu-hadoop/09.png" alt="hadoop运行图"></p>
<p>可以访问 <span class="exturl" data-url="aHR0cDovL21hc3Rlcjo4MDg4Lw==">http://master:8088<i class="fa fa-external-link-alt"></i></span> 查看所有任务的运行情况</p>
<p><img data-src="ubuntu-hadoop/10.png" alt="hadoop运行图"></p>
<p>可以访问 <span class="exturl" data-url="aHR0cDovL21hc3Rlcjo5ODcwLw==">http://master:9870<i class="fa fa-external-link-alt"></i></span> 查看Hadoop集群运行情况</p>
<p>至此整个hadoop就搭建好了</p>
<h2 id="全分部模式"><a href="#全分部模式" class="headerlink" title="全分部模式"></a>全分部模式</h2><h3 id="Namenode"><a href="#Namenode" class="headerlink" title="Namenode"></a>Namenode</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hdfs --daemon start namenode</span><br><span class="line">hdfs --daemon stop namenode</span><br><span class="line">hdfs --daemon restart namenode</span><br></pre></td></tr></table></figure>

<h3 id="Datanode"><a href="#Datanode" class="headerlink" title="Datanode"></a>Datanode</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hdfs --daemon start datanode</span><br><span class="line">hdfs --daemon stop datanode</span><br><span class="line">hdfs --daemon restart datanode</span><br></pre></td></tr></table></figure>

<p>你可以使用上面的命令挨个启动namenode和datanode，如果已配置好workers和ssh免密登录，你可以使用下面的命令调用脚本直接启动所有hdfs进程</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">start-dfs.sh</span><br></pre></td></tr></table></figure>

<h3 id="ResourceManager"><a href="#ResourceManager" class="headerlink" title="ResourceManager"></a>ResourceManager</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">yarn --daemon start resourcemanager</span><br><span class="line">yarn --daemon stop resourcemanager</span><br><span class="line">yarn --daemon restart resourcemanager</span><br></pre></td></tr></table></figure>

<h3 id="NodeManager"><a href="#NodeManager" class="headerlink" title="NodeManager"></a>NodeManager</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">yarn --daemon start nodemanager</span><br><span class="line">yarn --daemon stop nodemanager</span><br><span class="line">yarn --daemon restart nodemanager</span><br></pre></td></tr></table></figure>

<p>你可以使用上面的命令挨个启动resourcemanager和nodemanager，如果已配置好workers和ssh免密登录，你可以使用下面的命令调用脚本直接启动所有yarn进程</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">start-yarn.sh</span><br></pre></td></tr></table></figure>

<h1 id="案例测试"><a href="#案例测试" class="headerlink" title="案例测试"></a>案例测试</h1><h2 id="词频统计"><a href="#词频统计" class="headerlink" title="词频统计"></a>词频统计</h2><p>可以使用下面的命令进行一个wordcount的测试程序(命令已进行版本兼容，不需要修改直接运行即可)</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mkdir input</span><br><span class="line">cp $HADOOP_HOME&#x2F;*.txt input</span><br><span class="line">hadoop jar $HADOOP_HOME&#x2F;share&#x2F;hadoop&#x2F;mapreduce&#x2F;hadoop-mapreduce-examples-*.jar wordcount input output</span><br></pre></td></tr></table></figure>

<p>之后通过<code>ls</code>查看当前目录下的文件</p>
<p><img data-src="ubuntu-hadoop%5C11.png" alt="单机模式测试结果"></p>
<p>使用下面的命令可查看词频统计的结果</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat output&#x2F;part-r-00000</span><br></pre></td></tr></table></figure>

<p><img data-src="ubuntu-hadoop%5C12.png" alt="单机模式词频统计结果"></p>
<p>当有类似的结果如上图所示，表示你已经成功搭建好了hadoop单机模式，并测试成功</p>
<h2 id="PI值计算"><a href="#PI值计算" class="headerlink" title="PI值计算"></a>PI值计算</h2><p>我们可以使用一个简单的例子来测试一下hadoop是否能够正常运行</p>
<p>我们从hadoop安装文件夹，启动一个终端，使用下面的命令，计算pi值</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hadoop jar $HADOOP_HOME&#x2F;share&#x2F;hadoop&#x2F;mapreduce&#x2F;hadoop-mapreduce-examples-*.jar pi 10 10</span><br></pre></td></tr></table></figure>
<p><img data-src="ubuntu-hadoop/13.png" alt="hadoop pi值计算"></p>
<p>如图所示，我们计算量比较少导致不够精确，但是已经可以成功运算出pi值了</p>
<h1 id="附件"><a href="#附件" class="headerlink" title="附件"></a>附件</h1><p>各配置文件参数描述</p>
<h2 id="core-site-xml-2"><a href="#core-site-xml-2" class="headerlink" title="core-site.xml"></a>core-site.xml</h2><table>
<thead>
<tr>
<th>参数</th>
<th align="center">属性值</th>
<th>解释</th>
</tr>
</thead>
<tbody><tr>
<td>fs.defaultFS</td>
<td align="center">hdfs://localhost:9000</td>
<td>配置hdfs的namenode的地址，使用的是hdfs协议</td>
</tr>
<tr>
<td>hadoop.tmp.dir</td>
<td align="center"></td>
<td>配置hadoop运行时产生数据的存储目录</td>
</tr>
<tr>
<td>io.file.buffer.size</td>
<td align="center">65536</td>
<td>配置读/写缓存区的大小，以byte为单位，默认值是4KB</td>
</tr>
<tr>
<td>一般情况下，可以设置为64KB（65536byte）</td>
<td align="center"></td>
<td></td>
</tr>
</tbody></table>
<h2 id="hdfs-site-xml-2"><a href="#hdfs-site-xml-2" class="headerlink" title="hdfs-site.xml"></a>hdfs-site.xml</h2><table>
<thead>
<tr>
<th>参数</th>
<th>属性值</th>
<th>解释</th>
</tr>
</thead>
<tbody><tr>
<td>dfs.replication</td>
<td>1</td>
<td>分片数量，伪分布式将其配置成1即可</td>
</tr>
<tr>
<td>dfs.permissions</td>
<td>false</td>
<td>是否打开权限检查系统</td>
</tr>
<tr>
<td>dfs.namenode.name.dir</td>
<td>/opt/data/namenode</td>
<td>命名空间和事务在本地文件系统永久存储的路径</td>
</tr>
<tr>
<td>dfs.datanode.data.dir</td>
<td>/opt/data/datanode</td>
<td>DataNode在本地文件系统中存放块的路径</td>
</tr>
</tbody></table>
<h2 id="yarn-site-xml-2"><a href="#yarn-site-xml-2" class="headerlink" title="yarn-site.xml"></a>yarn-site.xml</h2><table>
<thead>
<tr>
<th>参数</th>
<th>属性值</th>
<th>解释</th>
</tr>
</thead>
<tbody><tr>
<td>yarn.nodemanager.aux-services</td>
<td>mapreduce_shuffle</td>
<td>NodeManager上运行的附属服务。需配置成mapreduce_shuffle，才可运行MapReduce程序</td>
</tr>
<tr>
<td>yarn.nodemanager.auxservices.mapreduce.shuffle.class</td>
<td>org.apache.hadoop.mapred.ShuffleHandler</td>
<td>是否打开权限检查系统</td>
</tr>
<tr>
<td>yarn.resourcemanager.address</td>
<td>${yarn.resourcemanager.hostname}:8032</td>
<td>ResourceManager 对客户端暴露的地址。客户端通过该地址向RM提交应用程序，杀死应用程序等</td>
</tr>
<tr>
<td>yarn.resourcemanager.scheduler.address</td>
<td>${yarn.resourcemanager.hostname}:8030</td>
<td>ResourceManager对ApplicationMaster暴露的访问地址。ApplicationMaster通过该地址向RM申请资源、释放资源等。</td>
</tr>
<tr>
<td>yarn.resourcemanager.resource-tracker.address</td>
<td>${yarn.resourcemanager.hostname}:8031</td>
<td>ResourceManager 对NodeManager暴露的地址.。NodeManager通过该地址向RM汇报心跳，领取任务等</td>
</tr>
<tr>
<td>yarn.resourcemanager.admin.address</td>
<td>${yarn.resourcemanager.hostname}:8033</td>
<td>ResourceManager 对管理员暴露的访问地址。管理员通过该地址向RM发送管理命令等</td>
</tr>
<tr>
<td>yarn.resourcemanager.webapp.address</td>
<td>${yarn.resourcemanager.hostname}:8088</td>
<td>ResourceManager对外web ui地址。用户可通过该地址在浏览器中查看集群各类信息</td>
</tr>
<tr>
<td>yarn.resourcemanager.scheduler.class</td>
<td>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler</td>
<td>启用的资源调度器主类。目前可用的有FIFO、Capacity Scheduler和Fair Scheduler</td>
</tr>
<tr>
<td>yarn.resourcemanager.resource-tracker.client.thread-count</td>
<td>50</td>
<td>处理来自NodeManager的RPC请求的Handler数目</td>
</tr>
<tr>
<td>yarn.resourcemanager.scheduler.client.thread-count</td>
<td>50</td>
<td>处理来自ApplicationMaster的RPC请求的Handler数目</td>
</tr>
<tr>
<td>yarn.scheduler.minimum-allocation-mb/yarn.scheduler.maximum-allocation-mb</td>
<td>1024/8192</td>
<td>单个可申请的最小/最大内存资源量。比如设置为1024和3072，则运行MapRedce作业时，每个Task最少可申请1024MB内存，最多可申请3072MB内存</td>
</tr>
<tr>
<td>yarn.scheduler.minimum-allocation-vcores/yarn.scheduler.maximum-allocation-vcores</td>
<td>1/32</td>
<td>单个可申请的最小/最大虚拟CPU个数。比如设置为1和4，则运行MapRedce作业时，每个Task最少可申请1个虚拟CPU，最多可申请4个虚拟CPU</td>
</tr>
<tr>
<td>yarn.resourcemanager.nodes.include-path/yarn.resourcemanager.nodes.exclude-path</td>
<td></td>
<td>NodeManager黑白名单。如果发现若干个NodeManager存在问题，比如故障率很高，任务运行失败率高，则可以将之加入黑名单中。注意，这两个配置参数可以动态生效</td>
</tr>
<tr>
<td>yarn.resourcemanager.nodemanagers.heartbeat-interval-ms</td>
<td>1000</td>
<td>NodeManager心跳间隔</td>
</tr>
</tbody></table>
]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
        <tag>Spark</tag>
      </tags>
  </entry>
  <entry>
    <title>Scala学习指南</title>
    <url>//posts/scala-learning.html</url>
    <content><![CDATA[<h1 id="Scala简介"><a href="#Scala简介" class="headerlink" title="Scala简介"></a>Scala简介</h1><p>Scala是一门类Java的多范式语言，它整合了面向对象编程和函数式编程的最佳特性。具体来讲：</p>
<ul>
<li>Scala运行于Java虚拟机（JVM）之上，并且兼容现有的Java程序，可以与Java类进行互操作，包括调用Java方法，创建Java对象，继承Java类和实现Java接口。</li>
<li>Scala是一门纯粹的面向对象的语言。在Scala语言中，每个值都是对象，每个操作都是方法调用。对象的数据类型以及行为由类和特质描述。类抽象机制的扩展有两种途径，一种途径是子类继承，另一种途径是灵活的混入机制，这两种途径能避免多重继承的种种问题</li>
<li>Scala也是一门函数式语言。在Scala语言中，每个函数都是一个值，并且和其他类型（如整数、字符串等）的值处于同一地位。Scala提供了轻量级的语法用以定义匿名函数，支持高阶函数，允许嵌套多层函数，并支持柯里化</li>
</ul>
<h1 id="Scala安装"><a href="#Scala安装" class="headerlink" title="Scala安装"></a>Scala安装</h1><p>Scala运行在Java虚拟机（JVM）之上，因此只要安装有相应的Java虚拟机，所有的操作系统都可以运行Scala程序，包括Window、Linux、Unix、Mac OS等。</p>
<h2 id="JDK安装"><a href="#JDK安装" class="headerlink" title="JDK安装"></a>JDK安装</h2><h3 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h3><p>首先打开JDK的<span class="exturl" data-url="aHR0cHM6Ly93d3cub3JhY2xlLmNvbS90ZWNobmV0d29yay9qYXZhL2phdmFzZS9kb3dubG9hZHMvaW5kZXguaHRtbA==">下载页面<i class="fa fa-external-link-alt"></i></span></p>
<p><img data-src="jdk-install/01.jpg" alt="JDK"></p>
<p>这里我们选择的是Java SE Development Kit 8u191进行下载使用</p>
<h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><p>下载完毕后，使用下面的命令解压到相应的目录下</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">tar -zxvf .&#x2F;jdk-8u191-linux-x64.tar.gz -C &#x2F;opt</span><br></pre></td></tr></table></figure>

<p>编辑.bashrc文件，将下面的文本添加进环境变量</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#add Java environment</span><br><span class="line">export JAVA_HOME&#x3D;&#x2F;opt&#x2F;jdk1.8.0_201</span><br><span class="line">export JRE_HOME&#x3D;$&#123;JAVA_HOME&#125;&#x2F;jre</span><br><span class="line">export CLASSPATH&#x3D;.:$&#123;JAVA_HOME&#125;&#x2F;lib:$&#123;JRE_HOME&#125;&#x2F;lib</span><br><span class="line">export PATH&#x3D;$&#123;JAVA_HOME&#125;&#x2F;bin:$PATH</span><br></pre></td></tr></table></figure>

<p><img data-src="jdk-install/02.jpg" alt="JAVA版本查看"></p>
<p>然后运行下面的命令，查看JDK是否安装成功</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">java -version</span><br></pre></td></tr></table></figure>

<h3 id="JDK没有JRE"><a href="#JDK没有JRE" class="headerlink" title="JDK没有JRE"></a>JDK没有JRE</h3><p>新版本的JDK（9,10,11,10）没有JRE，可以使用下面的命令，生成JRE模块</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">bin\jlink.exe --module-path jmods --add-modules java.desktop --output jre</span><br></pre></td></tr></table></figure>

<h2 id="Scala安装-1"><a href="#Scala安装-1" class="headerlink" title="Scala安装"></a>Scala安装</h2><h3 id="下载-1"><a href="#下载-1" class="headerlink" title="下载"></a>下载</h3><p><span class="exturl" data-url="aHR0cHM6Ly93d3cuc2NhbGEtbGFuZy5vcmcvZG93bmxvYWQvMi4xMS4xMi5odG1s">https://www.scala-lang.org/download/2.11.12.html<i class="fa fa-external-link-alt"></i></span></p>
<p>下载2.11版本的scala</p>
<h3 id="安装-1"><a href="#安装-1" class="headerlink" title="安装"></a>安装</h3><h4 id="win"><a href="#win" class="headerlink" title="win"></a>win</h4><p>双击下一步下一步下一步下一步下一步完成</p>
<h4 id="linux"><a href="#linux" class="headerlink" title="linux"></a>linux</h4><p>解压到<code>/opt</code>目录下，配置好环境变量即可</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># SCALA</span><br><span class="line">export SCALA_HOME&#x3D;&#x2F;opt&#x2F;scala-2.12.9</span><br><span class="line">export PATH&#x3D;$&#123;SCALA_HOME&#125;&#x2F;bin:$PATH</span><br></pre></td></tr></table></figure>

<h1 id="Scala基础"><a href="#Scala基础" class="headerlink" title="Scala基础"></a>Scala基础</h1><h2 id="基础数据类型和变量"><a href="#基础数据类型和变量" class="headerlink" title="基础数据类型和变量"></a>基础数据类型和变量</h2><h3 id="基础数据类型"><a href="#基础数据类型" class="headerlink" title="基础数据类型"></a>基础数据类型</h3><p>Scala的数据类型包括：Byte、Char、Short、Int、Long、Float、Double和Boolean（注意首字母大写）</p>
<p>和Java不同的是，在Scala中，这些类型都是“类”，并且都是包scala的成员，比如，Int的全名是scala.Int。对于字符串，Scala用java.lang.String类来表示字符串</p>
<table>
<thead>
<tr>
<th>值类型</th>
<th>范围</th>
</tr>
</thead>
<tbody><tr>
<td>Byte</td>
<td>8位有符号补码整数。数值区间为 -128 到 127 （-$$2^{7}$$~$$2^{7}-1$$）</td>
</tr>
<tr>
<td>Short</td>
<td>16位有符号补码整数。数值区间为 -32768 到 32767（-$$2^{15}$$~$$2^{15}-1$$）</td>
</tr>
<tr>
<td>Int</td>
<td>32位有符号补码整数。数值区间为（-$$2^{31}$$~$$2^{31}-1$$）</td>
</tr>
<tr>
<td>Long</td>
<td>64位有符号补码整数。数值区间为（-$$2^{63}$$~$$2^{63}-1$$）</td>
</tr>
<tr>
<td>Float</td>
<td>32 位, IEEE 754 标准的单精度浮点数</td>
</tr>
<tr>
<td>Double</td>
<td>64 位 IEEE 754 标准的双精度浮点数</td>
</tr>
<tr>
<td>Char</td>
<td>16位无符号Unicode字符, 区间值为 U+0000 到 U+FFFF（0~$$2^{16}-1$$）</td>
</tr>
<tr>
<td>String</td>
<td>字符序列</td>
</tr>
<tr>
<td>Boolean</td>
<td>true或false</td>
</tr>
</tbody></table>
<h3 id="字面量"><a href="#字面量" class="headerlink" title="字面量"></a>字面量</h3><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> i = <span class="number">123</span>            <span class="comment">//123就是整数字面量</span></span><br><span class="line"><span class="keyword">val</span> i = <span class="number">3.14</span>           <span class="comment">//3.14就是浮点数字面量</span></span><br><span class="line"><span class="keyword">val</span> i = <span class="literal">true</span>           <span class="comment">//true就是布尔型字面量</span></span><br><span class="line"><span class="keyword">val</span> i = &#x27;<span class="type">A</span>&#x27;            <span class="comment">//&#x27;A&#x27;就是字符字面量</span></span><br><span class="line"><span class="keyword">val</span> i = “<span class="type">Hello</span>”        <span class="comment">//“Hello”就是字符串字面量</span></span><br></pre></td></tr></table></figure>

<h3 id="操作符"><a href="#操作符" class="headerlink" title="操作符"></a>操作符</h3><p>算术运算符：加(+)、减(-) 、乘(*) 、除(/) 、余数(%)；</p>
<p>关系运算符：大于(&gt;)、小于(&lt;)、等于(==)、不等于(!=)、大于等于(&gt;=)、小于等于(&lt;=)</p>
<p>逻辑运算符：逻辑与(&amp;&amp;)、逻辑或(||)、逻辑非(!)；</p>
<p>位运算符：按位与(&amp;)、按位或(|)、按位异或(^)、按位取反(~)</p>
<p>赋值运算符：=及其与其它运算符结合的扩展赋值运算符，例如+=、%=</p>
<p>操作符优先级：算术运算符 &gt; 关系运算符 &gt; 逻辑运算符 &gt; 赋值运算符</p>
<p>在Scala中，操作符就是方法</p>
<p>例如，5 + 3和(5).+(3)是等价的</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> sum1 = <span class="number">5</span> + <span class="number">3</span>         <span class="comment">//实际上调用了 (5).+(3)</span></span><br><span class="line">sum1: <span class="type">Int</span> = <span class="number">8</span></span><br><span class="line">scala&gt; <span class="keyword">val</span> sum2 = (<span class="number">5</span>).+(<span class="number">3</span>)     <span class="comment">//可以发现，写成方法调用的形式，和上面得到相同的结果</span></span><br><span class="line">sum2: <span class="type">Int</span> = <span class="number">8</span></span><br></pre></td></tr></table></figure>

<h4 id="富包装类"><a href="#富包装类" class="headerlink" title="富包装类"></a>富包装类</h4><p>对于基本数据类型，除了以上提到的各种操作符外，Scala还提供了许多常用运算的方法，只是这些方法不是在基本类里面定义，而是被封装到一个对应的富包装类中</p>
<p>每个基本类型都有一个对应的富包装类，例如Int有一个RichInt类、String有一个RichString类，这些类位于包scala.runtime中</p>
<p>当对一个基本数据类型的对象调用其富包装类提供的方法，Scala会自动通过隐式转换将该对象转换为对应的富包装类型，然后再调用相应的方法。例如：<code>3 max 5</code></p>
<h3 id="变量"><a href="#变量" class="headerlink" title="变量"></a>变量</h3><p>Scala有两种类型的变量：</p>
<ul>
<li><p>val：是不可变的，在声明时就必须被初始化，而且初始化以后就不能再赋值</p>
</li>
<li><p>var：是可变的，声明的时候需要进行初始化，初始化以后还可以再次对其赋值</p>
</li>
</ul>
<p>基本语法：</p>
<p>val  变量名:数据类型 = 初始值</p>
<p>var  变量名:数据类型 = 初始值</p>
<p>类型推断机制（type inference）：根据初始值自动推断变量的类型，使得定义变量时可以省略具体的数据类型及其前面的冒号</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> myStr = <span class="string">&quot;Hello World!&quot;</span></span><br><span class="line">myStr: <span class="type">String</span> = <span class="type">Hello</span> <span class="type">World</span>!</span><br></pre></td></tr></table></figure>

<p>当然，我们也可以显式声明变量的类型：</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> myStr2 : <span class="type">String</span> = <span class="string">&quot;Hello World!&quot;</span></span><br><span class="line">myStr2: <span class="type">String</span> = <span class="type">Hello</span> <span class="type">World</span>!</span><br><span class="line">scala&gt; println(myStr)</span><br><span class="line"><span class="type">Hello</span> <span class="type">World</span>!</span><br></pre></td></tr></table></figure>

<p>myStr是val变量，因此，一旦初始化以后，就不能再次赋值</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">scala&gt; myStr = <span class="string">&quot;Hello Scala!&quot;</span></span><br><span class="line">&lt;console&gt;:<span class="number">27</span>: error: reassignment to <span class="keyword">val</span></span><br><span class="line">          myStr = <span class="string">&quot;Hello Scala!&quot;</span></span><br><span class="line">                ^</span><br></pre></td></tr></table></figure>

<p>var变量初始化以后，可以再次赋值</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">scala&gt; <span class="keyword">var</span> myPrice : <span class="type">Double</span> = <span class="number">9.9</span></span><br><span class="line">myPrice: <span class="type">Double</span> = <span class="number">9.9</span></span><br><span class="line"></span><br><span class="line">scala&gt; myPrice = <span class="number">10.6</span></span><br><span class="line">myPrice: <span class="type">Double</span> = <span class="number">10.6</span></span><br></pre></td></tr></table></figure>

<p>注意：在REPL环境下，可以重复使用同一个变量名来定义变量，而且变量前的修饰符和其类型都可以不一致，REPL会以最新的一个定义为准</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> a = <span class="string">&quot;Xiamen University&quot;</span></span><br><span class="line">a: <span class="type">String</span> = <span class="type">Xiamen</span> <span class="type">University</span></span><br><span class="line">scala&gt; <span class="keyword">var</span> a = <span class="number">50</span></span><br><span class="line">a: <span class="type">Int</span> = <span class="number">50</span></span><br></pre></td></tr></table></figure>

<h2 id="输入输出"><a href="#输入输出" class="headerlink" title="输入输出"></a>输入输出</h2><h3 id="控制台输入输出语句"><a href="#控制台输入输出语句" class="headerlink" title="控制台输入输出语句"></a>控制台输入输出语句</h3><p>从控制台读入数据方法：readInt、readDouble、readByte、readShort、readFloat、readLong、readChar readBoolean及readLine，分别对应9种基本数据类型，其中前8种方法没有参数，readLine可以不提供参数，也可以带一个字符串参数的提示</p>
<p>所有这些函数都属于对象scala.io.StdIn的方法，使用前必须导入，或者直接用全称进行调用</p>
<p>从控制台读入数据方法</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">scala&gt; <span class="keyword">import</span> io.<span class="type">StdIn</span>._</span><br><span class="line"><span class="keyword">import</span> io.<span class="type">StdIn</span>._</span><br><span class="line">scala&gt; <span class="keyword">var</span> i=readInt()</span><br><span class="line"><span class="number">54</span></span><br><span class="line">i: <span class="type">Int</span> = <span class="number">54</span></span><br><span class="line">scala&gt; <span class="keyword">var</span> f=readFloat</span><br><span class="line"><span class="number">1.618</span></span><br><span class="line">f: <span class="type">Float</span> = <span class="number">1.618</span></span><br><span class="line">scala&gt; <span class="keyword">var</span> b=readBoolean</span><br><span class="line"><span class="literal">true</span></span><br><span class="line">b: <span class="type">Boolean</span> = <span class="literal">true</span></span><br><span class="line">scala&gt; <span class="keyword">var</span> str=readLine(<span class="string">&quot;please input your name:&quot;</span>)</span><br><span class="line">please input your name:<span class="type">Li</span> <span class="type">Lei</span></span><br><span class="line">str: <span class="type">String</span> = <span class="type">Li</span> <span class="type">Lei</span></span><br></pre></td></tr></table></figure>

<p>向控制台输出信息方法：</p>
<ul>
<li>print()和println()，可以直接输出字符串或者其它数据类型，其中println在末尾自动换行。</li>
</ul>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> i=<span class="number">345</span></span><br><span class="line">i: <span class="type">Int</span> = <span class="number">345</span></span><br><span class="line">scala&gt; print(<span class="string">&quot;i=&quot;</span>);print(i) </span><br><span class="line"><span class="comment">//两条语句位于同一行，不能省略中间的分号</span></span><br><span class="line">i=<span class="number">345</span></span><br><span class="line">scala&gt; println(<span class="string">&quot;hello&quot;</span>);println(<span class="string">&quot;world&quot;</span>)</span><br><span class="line">hello</span><br><span class="line">world</span><br></pre></td></tr></table></figure>

<ul>
<li>C语言风格格式化字符串的printf()函数</li>
</ul>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> i = <span class="number">34</span></span><br><span class="line">i: <span class="type">Int</span> = <span class="number">34</span></span><br><span class="line">scala&gt; <span class="keyword">val</span> f=<span class="number">56.5</span></span><br><span class="line">f: <span class="type">Double</span> = <span class="number">56.5</span></span><br><span class="line">scala&gt; printf(<span class="string">&quot;I am %d years old and weight %.1f Kg.&quot;</span>,<span class="string">&quot;Li Lie&quot;</span>,i,f)</span><br><span class="line"><span class="type">I</span> am <span class="number">34</span> years old and weight <span class="number">56.5</span> <span class="type">Kg</span>.</span><br></pre></td></tr></table></figure>

<p>print()、println()和printf() 都在对象Predef中定义，该对象默认情况下被所有Scala程序引用，因此可以直接使用Predef对象提供的方法，而无需使用scala.Predef.的形式。</p>
<p>s字符串和f字符串：Scala提供的字符串插值机制，以方便在字符串字面量中直接嵌入变量的值。</p>
<p>基本语法：s “ …$变量名… “ 或 f” …$变量名%格式化字符…”</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> i=<span class="number">10</span></span><br><span class="line">i: <span class="type">Int</span> = <span class="number">10</span></span><br><span class="line">scala&gt; <span class="keyword">val</span> f=<span class="number">3.5</span></span><br><span class="line">f: <span class="type">Double</span> = <span class="number">3.5452</span></span><br><span class="line">scala&gt; <span class="keyword">val</span> s=<span class="string">&quot;hello&quot;</span></span><br><span class="line">s: <span class="type">String</span> = hello</span><br><span class="line">scala&gt; println(<span class="string">s&quot;<span class="subst">$s</span>:i=<span class="subst">$i</span>,f=<span class="subst">$f</span>&quot;</span>)    <span class="comment">//s插值字符串</span></span><br><span class="line">hello:i=<span class="number">10</span>,f=<span class="number">3.5452</span></span><br><span class="line">scala&gt; println(<span class="string">f&quot;<span class="subst">$s</span>:i=<span class="subst">$i</span>%-4d,f=<span class="subst">$f</span>%.1f&quot;</span>)   <span class="comment">//f插值字符串</span></span><br><span class="line">hello:i=<span class="number">10</span>  ,f=<span class="number">3.5</span></span><br></pre></td></tr></table></figure>

<h3 id="读写文件"><a href="#读写文件" class="headerlink" title="读写文件"></a>读写文件</h3><h4 id="写入文件"><a href="#写入文件" class="headerlink" title="写入文件"></a>写入文件</h4><p>Scala需要使用java.io.PrintWriter实现把数据写入到文件，PrintWriter类提供了print和println两个写方法</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">scala&gt; <span class="keyword">import</span> java.io.<span class="type">PrintWriter</span></span><br><span class="line">scala&gt; <span class="keyword">val</span> outputFile = <span class="keyword">new</span> <span class="type">PrintWriter</span>(<span class="string">&quot;test.txt&quot;</span>)</span><br><span class="line">scala&gt; outputFile.println(<span class="string">&quot;Hello World&quot;</span>)</span><br><span class="line">scala&gt; outputFile.print(<span class="string">&quot;Spark is good&quot;</span>)</span><br><span class="line">scala&gt; outputFile.close()</span><br></pre></td></tr></table></figure>

<p>PrintWriter里路径可以是直接路径，也可以是相对路径</p>
<h4 id="读取文件"><a href="#读取文件" class="headerlink" title="读取文件"></a>读取文件</h4><p>可以使用scala.io.Source的getLines方法实现对文件中所有行的读取</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> scala.io.<span class="type">Source</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> file = <span class="keyword">new</span> <span class="type">PrintWriter</span>(<span class="string">&quot;output.txt&quot;</span>)</span><br><span class="line"><span class="keyword">val</span> lines = file.getLines()</span><br><span class="line"><span class="keyword">for</span> (line &lt;- lines) println(line)</span><br></pre></td></tr></table></figure>

<h2 id="控制结构"><a href="#控制结构" class="headerlink" title="控制结构"></a>控制结构</h2><h3 id="if条件表达式"><a href="#if条件表达式" class="headerlink" title="if条件表达式"></a>if条件表达式</h3><p>基本语法</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (表达式) &#123;</span><br><span class="line">    语句块<span class="number">1</span></span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    语句块<span class="number">2</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">val x &#x3D; 6</span><br><span class="line">if (x &gt; 0) &#123;</span><br><span class="line">  println(&quot;This is a positive number&quot;)</span><br><span class="line">&#125; else &#123;</span><br><span class="line">  println(&quot;This is not a positive number&quot;)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> x = <span class="number">3</span></span><br><span class="line"><span class="keyword">if</span> (x &gt; <span class="number">0</span>) &#123;</span><br><span class="line">  println(<span class="string">&quot;This is a positive number&quot;</span>)</span><br><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> (x == <span class="number">0</span>) &#123;</span><br><span class="line">  println(<span class="string">&quot;This is a zero&quot;</span>)</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">  println(<span class="string">&quot;This is a negative number&quot;</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>有一点与Java不同的是，Scala中的if表达式的值可以赋值给变量</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> x = <span class="number">6</span></span><br><span class="line"><span class="keyword">val</span> a = <span class="keyword">if</span> (x &gt; <span class="number">0</span>) <span class="number">1</span> <span class="keyword">else</span> <span class="number">-1</span></span><br></pre></td></tr></table></figure>

<p>相当于c或Java里的三元操作符：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">x &gt; <span class="number">0</span> ? <span class="number">1</span>: -<span class="number">1</span></span><br></pre></td></tr></table></figure>

<h3 id="while循环"><a href="#while循环" class="headerlink" title="while循环"></a>while循环</h3><p>基本语法</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">while</span> (表达式)&#123;</span><br><span class="line">        循环体</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">do&#123;</span><br><span class="line">        循环体</span><br><span class="line">&#125;<span class="keyword">while</span> (表达式)</span><br></pre></td></tr></table></figure>

<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> i = <span class="number">9</span></span><br><span class="line"><span class="keyword">while</span> (i &gt; <span class="number">0</span>) &#123;</span><br><span class="line">  i -= <span class="number">1</span></span><br><span class="line">  printf(<span class="string">&quot;i is %d\n&quot;</span>, i)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> i = <span class="number">0</span></span><br><span class="line">do &#123;</span><br><span class="line">  i += <span class="number">1</span></span><br><span class="line">  println(i)</span><br><span class="line">&#125; <span class="keyword">while</span> (i &lt; <span class="number">5</span>)</span><br></pre></td></tr></table></figure>

<h3 id="for循环"><a href="#for循环" class="headerlink" title="for循环"></a>for循环</h3><p>基本语法 </p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> (变量 &lt;- 表达式) &#123;语句块&#125;</span><br></pre></td></tr></table></figure>

<p>其中，“变量&lt;-表达式”被称为“生成器（generator）”</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> (i &lt;- <span class="number">1</span> to <span class="number">5</span>) println(i)</span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="number">2</span></span><br><span class="line"><span class="number">3</span></span><br><span class="line"><span class="number">4</span></span><br><span class="line"><span class="number">5</span></span><br></pre></td></tr></table></figure>

<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> (i &lt;- <span class="number">1</span> to <span class="number">5</span> by <span class="number">2</span>) println(i)</span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="number">3</span></span><br><span class="line"><span class="number">5</span></span><br></pre></td></tr></table></figure>

<p>“守卫(guard)”的表达式：过滤出一些满足条件的结果。基本语法：</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> (变量 &lt;- 表达式 <span class="keyword">if</span> 条件表达式) 语句块</span><br></pre></td></tr></table></figure>

<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> (i &lt;- <span class="number">1</span> to <span class="number">5</span> <span class="keyword">if</span> i % <span class="number">2</span> == <span class="number">0</span>) println(i)</span><br><span class="line"><span class="number">2</span></span><br><span class="line"><span class="number">4</span></span><br></pre></td></tr></table></figure>

<p>Scala也支持“多个生成器”的情形，可以用分号把它们隔开，比如：</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> (i &lt;- <span class="number">1</span> to <span class="number">2</span>; j &lt;- <span class="number">1</span> to <span class="number">5</span>) println(<span class="string">f&quot;<span class="subst">$i</span>,<span class="subst">$j</span>&quot;</span>)</span><br><span class="line"><span class="number">1</span>,<span class="number">1</span></span><br><span class="line"><span class="number">1</span>,<span class="number">2</span></span><br><span class="line"><span class="number">1</span>,<span class="number">3</span></span><br><span class="line"><span class="number">1</span>,<span class="number">4</span></span><br><span class="line"><span class="number">1</span>,<span class="number">5</span></span><br><span class="line"><span class="number">2</span>,<span class="number">1</span></span><br><span class="line"><span class="number">2</span>,<span class="number">2</span></span><br><span class="line"><span class="number">2</span>,<span class="number">3</span></span><br><span class="line"><span class="number">2</span>,<span class="number">4</span></span><br><span class="line"><span class="number">2</span>,<span class="number">5</span></span><br></pre></td></tr></table></figure>

<p>for推导式：for结构可以在每次执行的时候创造一个值，然后将包含了所有产生值的集合作为for循环表达式的结果返回，集合的类型由生成器中的集合类型确定</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">for (变量 &lt;- 表达式) yield &#123;语句块&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> r=<span class="keyword">for</span> (i &lt;- <span class="type">Array</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>) <span class="keyword">if</span> i%<span class="number">2</span>==<span class="number">0</span>) <span class="keyword">yield</span> &#123; println(i); i&#125;</span><br><span class="line"><span class="number">2</span></span><br><span class="line"><span class="number">4</span></span><br><span class="line">r: <span class="type">Array</span>[<span class="type">Int</span>] = <span class="type">Array</span>(<span class="number">2</span>,<span class="number">4</span>)</span><br></pre></td></tr></table></figure>

<h3 id="异常处理"><a href="#异常处理" class="headerlink" title="异常处理"></a>异常处理</h3><p>Scala不支持Java中的“受检查异常”(checked exception)，将所有异常都当作“不受检异常”（或称为运行时异常）</p>
<p>Scala仍使用try-catch结构来捕获异常</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.<span class="type">FileReader</span> </span><br><span class="line"><span class="keyword">import</span> java.io.<span class="type">FileNotFoundException</span> </span><br><span class="line"><span class="keyword">import</span> java.io.<span class="type">IOException</span> </span><br><span class="line"><span class="keyword">try</span> &#123; </span><br><span class="line">  <span class="keyword">val</span> f = <span class="keyword">new</span> <span class="type">FileReader</span>(<span class="string">&quot;input.txt&quot;</span>) </span><br><span class="line">    <span class="comment">// 文件操作 </span></span><br><span class="line">&#125; <span class="keyword">catch</span> &#123; </span><br><span class="line">  <span class="keyword">case</span> ex: <span class="type">FileNotFoundException</span> =&gt; </span><br><span class="line">    <span class="comment">// 文件不存在时的操作 </span></span><br><span class="line">  <span class="keyword">case</span> ex: <span class="type">IOException</span> =&gt; </span><br><span class="line">   <span class="comment">// 发生I/O错误时的操作</span></span><br><span class="line">&#125; <span class="keyword">finally</span> &#123; </span><br><span class="line">  file.close() <span class="comment">// 确保关闭文件 </span></span><br><span class="line">&#125; </span><br></pre></td></tr></table></figure>

<p>受检查异常和不受检查异常的区别：<span class="exturl" data-url="aHR0cHM6Ly93d3cuY25ibG9ncy5jb20vdGp1ZHpqL3AvNzA1Mzk4MC5odG1s">https://www.cnblogs.com/tjudzj/p/7053980.html<i class="fa fa-external-link-alt"></i></span></p>
<p>异常，开发者之间一直存在着争议，毕竟两类异常都各有优缺点。受检异常的特点在于它强制要求开发人员在代码中进行显式的声明和捕获，否则就会产生编译错误。这种限制从好的方面来说，可以防止开发人员意外地忽略某些出错的情况，因为编译器不允许出现未被处理的受检异常；从不好的方面来说，受检异常对程序中的设计提出了更高的要求。不恰当地使用受检异常，会使代码中充斥着大量没有实际作用、只是为了通过编译而添加的代码。而非受检异常的特点是，如果不捕获异常，不会产生编译错误，异常会在运行时刻才被抛出。</p>
<p>非受检异常的好处是可以去掉一些不需要的异常处理代码，而不好之处是开发人员可能忽略某些应该处理的异常。一个典型的例子是把字符串转换成数字时会发生java.lang.NumberFormatException异常，忽略该异常可能导致一个错误的输入就造成整个程序退出。</p>
<p>目前的主流意见是，最好优先使用非受检异常。</p>
<h3 id="对循环的控制"><a href="#对循环的控制" class="headerlink" title="对循环的控制"></a>对循环的控制</h3><p>为了提前终止整个循环或者跳到下一个循环，Scala没有break和continue关键字</p>
<p>Scala提供了一个Breaks类（位于包scala.util.control）。Breaks类有两个方法用于对循环结构进行控制，即breakable和break</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">breakable&#123;</span><br><span class="line">...</span><br><span class="line"><span class="keyword">if</span>(...) <span class="keyword">break</span></span><br><span class="line">...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> util.control.<span class="type">Breaks</span>._ <span class="comment">//导入Breaks类的所有方法</span></span><br><span class="line"><span class="keyword">val</span> array = <span class="type">Array</span>(<span class="number">1</span>,<span class="number">3</span>,<span class="number">10</span>,<span class="number">5</span>,<span class="number">4</span>)</span><br><span class="line">breakable&#123;</span><br><span class="line"><span class="keyword">for</span>(i&lt;- array)&#123;</span><br><span class="line">       <span class="keyword">if</span>(i&gt;<span class="number">5</span>) <span class="keyword">break</span> <span class="comment">//跳出breakable，终止for循环，相当于Java中的break</span></span><br><span class="line">println(i)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 上面的for语句将输出1，3</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">for</span>(i&lt;- array)&#123;</span><br><span class="line">    breakable&#123;</span><br><span class="line">        <span class="keyword">if</span>(i&gt;<span class="number">5</span>) <span class="keyword">break</span> </span><br><span class="line">        <span class="comment">//跳出breakable，终止当次循环，相当于Java的continue        println(i)</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;<span class="comment">// 上面的for语句将输出1，3，5，4</span></span><br></pre></td></tr></table></figure>

<h2 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h2><h3 id="数组（Array）"><a href="#数组（Array）" class="headerlink" title="数组（Array）"></a>数组（Array）</h3><p>数组：一种可变的、可索引的、元素具有相同类型的数据集合</p>
<p>Scala提供了参数化类型的通用数组类Array[T]，其中T可以是任意的Scala类型，可以通过显式指定类型或者通过隐式推断来实例化一个数组</p>
<p>声明一个字符串数组</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> myStrArr = <span class="keyword">new</span> <span class="type">Array</span>[<span class="type">String</span>](<span class="number">3</span>) <span class="comment">//声明一个长度为3的字符串数组，每个数组元素初始化为null</span></span><br><span class="line"></span><br><span class="line">myStrArr(<span class="number">0</span>) = <span class="string">&quot;BigData&quot;</span></span><br><span class="line">myStrArr(<span class="number">1</span>) = <span class="string">&quot;Hadoop&quot;</span></span><br><span class="line">myStrArr(<span class="number">2</span>) = <span class="string">&quot;Spark&quot;</span></span><br><span class="line"><span class="keyword">for</span> (i &lt;- <span class="number">0</span> to <span class="number">2</span>) println(myStrArr(i))</span><br></pre></td></tr></table></figure>

<p>可以不给出数组类型，Scala会自动根据提供的初始化数据来推断出数组的类型</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> intValueArr = <span class="type">Array</span>(<span class="number">12</span>,<span class="number">45</span>,<span class="number">33</span>)</span><br><span class="line"><span class="keyword">val</span> myStrArr = <span class="type">Array</span>(<span class="string">&quot;BigData&quot;</span>,<span class="string">&quot;Hadoop&quot;</span>,<span class="string">&quot;Spark&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>多维数组的创建：调用Array的ofDim方法</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span>  myMatrix = <span class="type">Array</span>.ofDim[<span class="type">Int</span>](<span class="number">3</span>,<span class="number">4</span>)  <span class="comment">//类型实际就是Array[Array[Int]]</span></span><br><span class="line"><span class="keyword">val</span>  myCube = <span class="type">Array</span>.ofDim[<span class="type">String</span>](<span class="number">3</span>,<span class="number">2</span>,<span class="number">4</span>)  <span class="comment">//类型实际是Array[Array[Array[Int]]]</span></span><br></pre></td></tr></table></figure>

<p>可以使用多级圆括号来访问多维数组的元素，例如myMatrix(0)(1)返回第一行第二列的元素</p>
<h3 id="元组（Tuple）"><a href="#元组（Tuple）" class="headerlink" title="元组（Tuple）"></a>元组（Tuple）</h3><p>元组是对多个不同类型对象的一种简单封装。定义元组最简单的方法就是把多个元素用逗号分开并用圆括号包围起来。</p>
<p>使用下划线“_”加上从1开始的索引值，来访问元组的元素</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> tuple = (<span class="string">&quot;BigData&quot;</span>,<span class="number">1</span>,<span class="number">23.0</span>)</span><br><span class="line">scala&gt; print(tuple._1)</span><br><span class="line"><span class="string">&quot;BigData&quot;</span></span><br><span class="line">scala&gt; print(tuple._2)</span><br><span class="line"><span class="number">1</span></span><br><span class="line">scala&gt; print(tuple._3)</span><br><span class="line"><span class="number">23.0</span></span><br></pre></td></tr></table></figure>

<h3 id="容器（Collection）"><a href="#容器（Collection）" class="headerlink" title="容器（Collection）"></a>容器（Collection）</h3><p>Scala提供了一套丰富的容器（collection）库，包括序列（Sequence）、集合（Set）、映射（Map）等<br>Scala用了三个包来组织容器类，分别是scala.collection 、scala.collection.mutable和scala.collection.immutable<br>scala.collection封装了可变容器和不可变容器的超类或特质，定义了可变容器和不可变容器的一些通用操作</p>
<p><img data-src="scala-learning/01.png"></p>
<p>所有容器的根为Traverable特质，表示可遍历的，它为所有的容器类定义了抽象的foreach方法，该方法用于对容器元素进行遍历操作。混入Traverable特质的容器类必须给出foreach方法的具体实现。Traverable的下一级为Iterable特质，表示元素可一个个地依次迭代，该特质定义了一个抽象的iterator方法，混入该特质的容器必须实现iterator方法，返回一个迭代器（Iterator），另外，Iterable特质还给出了其从Traverable继承的foreach方法的一个默认实现，即通过迭代器进行遍历。</p>
<p>在Iterable下的继承层次包括三个特质，分别是序列（Seq）、映射（Map）和 集合（Set），这三种容器最大的区别是其元素的索引方式，序列是按照从0开始的整数进行索引的，映射是按照键值进行索引的，而集合是没有索引的。</p>
<h3 id="序列（Sequence）"><a href="#序列（Sequence）" class="headerlink" title="序列（Sequence）"></a>序列（Sequence）</h3><p>序列（Sequence）: 元素可以按照特定的顺序访问的容器。序列中每个元素均带有一个从0开始计数的固定索引位置</p>
<p>序列容器的根是collection.Seq特质。其具有两个子特质 LinearSeq和IndexedSeq。LinearSeq序列具有高效的 head 和 tail 操作，而IndexedSeq序列具有高效的随机存储操作</p>
<p>实现了特质LinearSeq的常用序列有列表（List）和队列（Queue）。实现了特质IndexedSeq的常用序列有可变数组（ArrayBuffer）和向量（Vector）</p>
<h4 id="列表-List"><a href="#列表-List" class="headerlink" title="列表(List)"></a>列表(List)</h4><p>列表: 一种共享相同类型的不可变的对象序列。定义在scala.collection.immutable包中</p>
<p>不同于Java的java.util.List，scala的List一旦被定义，其值就不能改变，因此声明List时必须初始化</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> strList=<span class="type">List</span>(<span class="string">&quot;BigData&quot;</span>,<span class="string">&quot;Hadoop&quot;</span>,<span class="string">&quot;Spark&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>列表有头部和尾部的概念，可以分别使用head和tail方法来获取</p>
<p>head返回的是列表第一个元素的值</p>
<p>tail返回的是除第一个元素外的其它值构成的新列表，这体现出列表具有递归的链表结构</p>
<p>strList.head将返回字符串”BigData”，strList.tail返回List (“Hadoop”,”Spark”)</p>
<p>不能用new来建立List（原型：<strong>sealed abstract class List[+A]</strong> ）</p>
<p>补充相同类型：对于包括List在内的所有容器类型，如果没有显式指定元素类型，Scala会自动选择所有初始值的最近公共类型来作为元素的类型。因为Scala的所有对象都来自共同的根Any，因此，原则上容器内可以容纳任意不同类型的成员。例如：val x=List(1,3.4,”Spark”)</p>
<p>构造列表常用的方法是通过在已有列表前端增加元素，使用的操作符为<code>::</code>，例如：</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> otherList=<span class="string">&quot;Apache&quot;</span>::strList</span><br></pre></td></tr></table></figure>

<p>执行该语句后strList保持不变，而otherList将成为一个新的列表：</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="type">List</span>(<span class="string">&quot;Apache&quot;</span>,<span class="string">&quot;BigData&quot;</span>,<span class="string">&quot;Hadoop&quot;</span>,<span class="string">&quot;Spark&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>Scala还定义了一个空列表对象Nil，借助Nil，可以将多个元素用操作符<code>::</code>串起来初始化一个列表</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> intList = <span class="number">1</span>::<span class="number">2</span>::<span class="number">3</span>::<span class="type">Nil</span></span><br></pre></td></tr></table></figure>

<p>与</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> intList = <span class="type">List</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>)</span><br></pre></td></tr></table></figure>

<p>等效</p>
<p>注意：除了head、tail操作是常数时间O(1)，其它按索引访问的操作都需要从头开始遍历，因此是线性时间复杂度O(N)。</p>
<p><code>::</code>是向右结合的（<code>:</code>结尾的操作符都是向右结合）</p>
<h4 id="向量-Vector"><a href="#向量-Vector" class="headerlink" title="向量(Vector)"></a>向量(Vector)</h4><p>Vetor可以实现所有访问操作都是常数时间。</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> vec1=<span class="type">Vector</span>(<span class="number">1</span>,<span class="number">2</span>)</span><br><span class="line">vec1: scala.collection.immutable.<span class="type">Vector</span>[<span class="type">Int</span>] = <span class="type">Vector</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line">scala&gt; <span class="keyword">val</span> vec2 = <span class="number">3</span> +: <span class="number">4</span> +: vec1</span><br><span class="line">vec2: scala.collection.immutable.<span class="type">Vector</span>[<span class="type">Int</span>] = <span class="type">Vector</span>(<span class="number">3</span>, <span class="number">4</span>, <span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">scala&gt; <span class="keyword">val</span> vec3 = vec2 :+ <span class="number">5</span></span><br><span class="line">vec3: scala.collection.immutable.<span class="type">Vector</span>[<span class="type">Int</span>] = <span class="type">Vector</span>(<span class="number">3</span>, <span class="number">4</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">5</span>)</span><br><span class="line">scala&gt; vec3(<span class="number">3</span>)</span><br><span class="line">res6: <span class="type">Int</span> = <span class="number">2</span></span><br></pre></td></tr></table></figure>

<p><code>+:</code>和<code>:+</code>是Seq的方法，执行后vector本身没变</p>
<h4 id="Range"><a href="#Range" class="headerlink" title="Range"></a>Range</h4><p>Range类：一种特殊的、带索引的不可变数字等差序列。其包含的值为从给定起点按一定步长增长(减小)到指定终点的所有数值</p>
<p>Range可以支持创建不同数据类型的数值序列，包括Int、Long、Float、Double、Char、BigInt和BigDecimal等</p>
<ul>
<li>创建一个从1到5的数值序列，包含区间终点5，步长为1</li>
</ul>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> r=<span class="keyword">new</span> <span class="type">Range</span>(<span class="number">1</span>,<span class="number">5</span>,<span class="number">1</span>)</span><br><span class="line">scala&gt; <span class="number">1</span> to <span class="number">5</span></span><br><span class="line">scala&gt; <span class="number">1.</span>to(<span class="number">5</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li>创建一个从1到5的数值序列，不包含区间终点5，步长为1</li>
</ul>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">scala&gt; <span class="number">1</span> until <span class="number">5</span></span><br></pre></td></tr></table></figure>

<ul>
<li>创建一个从1到10的数值序列，包含区间终点10，步长为2</li>
</ul>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">scala&gt; <span class="number">1</span> to <span class="number">10</span> by <span class="number">2</span></span><br></pre></td></tr></table></figure>

<ul>
<li>创建一个Float类型的数值序列，从0.5f到5.9f，步长为0.8f</li>
</ul>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">scala&gt; <span class="number">0.5</span>f to <span class="number">5.9</span>f by <span class="number">0.8</span>f</span><br></pre></td></tr></table></figure>

<p><code>1to 10 by 2</code>等效于<code>1.to(10).by(2)</code>，调用了Range的by方法</p>
<h3 id="集合（Set）"><a href="#集合（Set）" class="headerlink" title="集合（Set）"></a>集合（Set）</h3><p>集合(set)：不重复元素的容器（collection）</p>
<p>列表（List）中的元素是按照插入的先后顺序来组织的，但是，“集合”中的元素并不会记录元素的插入顺序，而是以“哈希”方法对元素的值进行组织，所以，它允许你快速地找到某个元素</p>
<p>集合包括<strong>可变集</strong>和<strong>不可变集</strong>，分别位于<code>scala.collection.mutable</code>包和<code>scala.collection.immutable</code>包，缺省情况下创建的是不可变集</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> mySet = <span class="type">Set</span>(<span class="string">&quot;Hadoop&quot;</span>,<span class="string">&quot;Spark&quot;</span>)</span><br><span class="line">mySet += <span class="string">&quot;Scala&quot;</span></span><br></pre></td></tr></table></figure>

<p>如果要声明一个可变集，则需要提前引入scala.collection.mutable.Set</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> scala.collection.mutable.<span class="type">Set</span></span><br><span class="line"><span class="keyword">val</span> myMutableSet = <span class="type">Set</span>(<span class="string">&quot;Database&quot;</span>,<span class="string">&quot;BigData&quot;</span>)</span><br><span class="line">myMutableSet += <span class="string">&quot;Cloud Computing&quot;</span> </span><br></pre></td></tr></table></figure>

<h3 id="映射（Map）"><a href="#映射（Map）" class="headerlink" title="映射（Map）"></a>映射（Map）</h3><p>映射(Map)：一系列键值对的容器。键是唯一的，但值不一定是唯一的。可以根据键来对值进行快速的检索</p>
<p>Scala 的映射包含了可变的和不可变的两种版本，分别定义在包scala.collection.mutable 和scala.collection.immutable 里。默认情况下，Scala中使用不可变的映射。如果想使用可变映射，必须明确地导入scala.collection.mutable.Map</p>
<p>其中，操作符”-&gt;”是定义二元组的简写方式，它会返回一个包含调用者和传入参数的二元组</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> university = <span class="type">Map</span>(<span class="string">&quot;XMU&quot;</span> -&gt; <span class="string">&quot;Xiamen University&quot;</span>, <span class="string">&quot;THU&quot;</span> -&gt; <span class="string">&quot;Tsinghua University&quot;</span>,<span class="string">&quot;PKU&quot;</span>-&gt;<span class="string">&quot;Peking University&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>如果要获取映射中的值，可以通过键来获取</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">println(university(<span class="string">&quot;XMU&quot;</span>))</span><br></pre></td></tr></table></figure>

<p>对于这种访问方式，如果给定的键不存在，则会抛出异常，为此，访问前可以先调用contains方法确定键是否存在</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> xmu = <span class="keyword">if</span> (university.contains(<span class="string">&quot;XMU&quot;</span>)) university(<span class="string">&quot;XMU&quot;</span>) <span class="keyword">else</span> <span class="number">0</span> println(xmu)</span><br></pre></td></tr></table></figure>

<h4 id="可变的映射"><a href="#可变的映射" class="headerlink" title="可变的映射"></a>可变的映射</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> scala.collection.mutable.<span class="type">Map</span></span><br><span class="line"><span class="keyword">val</span> university2 = <span class="type">Map</span>(<span class="string">&quot;XMU&quot;</span> -&gt; <span class="string">&quot;Xiamen University&quot;</span>, <span class="string">&quot;THU&quot;</span> -&gt; <span class="string">&quot;Tsinghua University&quot;</span>,<span class="string">&quot;PKU&quot;</span>-&gt;<span class="string">&quot;Peking University&quot;</span>)</span><br><span class="line">university2(<span class="string">&quot;XMU&quot;</span>) = <span class="string">&quot;Ximan University&quot;</span> <span class="comment">//更新已有元素的值</span></span><br><span class="line">university2(<span class="string">&quot;FZU&quot;</span>) = <span class="string">&quot;Fuzhou University&quot;</span> <span class="comment">//添加新元素</span></span><br></pre></td></tr></table></figure>

<p>也可以使用+=操作来添加新的元素</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">university2 + = (<span class="string">&quot;TJU&quot;</span>-&gt;<span class="string">&quot;Tianjin University&quot;</span>) <span class="comment">//添加一个新元素</span></span><br><span class="line">university2 + = (<span class="string">&quot;SDU&quot;</span>-&gt;<span class="string">&quot;Shandong University&quot;</span>,<span class="string">&quot;WHU&quot;</span>-&gt;<span class="string">&quot;Wuhan University&quot;</span>) <span class="comment">//同时添加两个新元素</span></span><br></pre></td></tr></table></figure>

<h3 id="迭代器（Iterator）"><a href="#迭代器（Iterator）" class="headerlink" title="迭代器（Iterator）"></a>迭代器（Iterator）</h3><p>迭代器（Iterator）不是一个容器，而是提供了按顺序访问容器元素的数据结构</p>
<p>迭代器包含两个基本操作：next和hasNext。next可以返回迭代器的下一个元素，hasNext用于检测是否还有下一个元素</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> iter = <span class="type">Iterator</span>(<span class="string">&quot;Hadoop&quot;</span>,<span class="string">&quot;Spark&quot;</span>,<span class="string">&quot;Scala&quot;</span>)</span><br><span class="line"><span class="keyword">while</span> (iter.hasNext) &#123;</span><br><span class="line">    println(iter.next())</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>建议：除next和hasnext方法外，在对一个迭代器调用了某个方法后，不要再次使用该迭代器</p>
<p>1、尽管构造一个迭代器与构造一个容器很类似，但迭代器并不是一个容器类，因为不能随机访问迭代器的元素，而只能按从前往后的顺序依次访问其元素。</p>
<p>2、实际上，迭代器的大部分方法都会改变迭代器的状态，例如，调用length方法会返回迭代器元素的个数，但是，调用结束后，迭代器已经没有元素了，再次进行相关操作会报错。</p>
<h1 id="面向对象编程基础"><a href="#面向对象编程基础" class="headerlink" title="面向对象编程基础"></a>面向对象编程基础</h1><p>作为一个运行一个JVM上的语言，Scala毫无疑问首先是面向对象的语言。尽管在具体的数据处理部分，函数式编程在Scala中已成为首选方案，但在上层的架构组织上，仍然需要采用面向对象的模型，这对于大型的应用程序尤其必不可少。</p>
<h2 id="类"><a href="#类" class="headerlink" title="类"></a>类</h2><h3 id="类的定义"><a href="#类的定义" class="headerlink" title="类的定义"></a>类的定义</h3><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Counter</span></span>&#123;</span><br><span class="line">       <span class="comment">//这里定义类的字段和方法</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>字段定义：用val或var关键字进行定义</p>
<p>方法定义：</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">方法名</span></span>(参数列表):返回结果类型=&#123;方法体&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Counter</span> </span>&#123;</span><br><span class="line">  <span class="keyword">var</span> value = <span class="number">0</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">increment</span></span>(step:<span class="type">Int</span>):<span class="type">Unit</span> = &#123; value += step&#125;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">current</span></span>():<span class="type">Int</span> = &#123;value&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>使用new关键字创建一个类的实例</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> myCounter = <span class="keyword">new</span> <span class="type">Counter</span></span><br><span class="line">myCounter.value = <span class="number">5</span> <span class="comment">//访问字段</span></span><br><span class="line">myCounter. increment(<span class="number">3</span>) <span class="comment">//调用方法</span></span><br><span class="line">println(myCounter.current) <span class="comment">//调用无参数方法时，可以省略方法名后的括号</span></span><br></pre></td></tr></table></figure>

<h3 id="类成员的可见性"><a href="#类成员的可见性" class="headerlink" title="类成员的可见性"></a>类成员的可见性</h3><p>Scala类中所有成员的默认可见性为公有，任何作用域内都能直接访问公有成员</p>
<p>除了默认的公有可见性，Scala也提供<code>private</code>和<code>protected</code>，其中，private成员只对本类型和嵌套类型可见；<code>protected</code>成员对本类型和其继承类型都可见</p>
<p>为了避免直接暴露public字段，建议将字段设置为<code>private</code>，对于<code>private</code>字段，Scala采用类似Java中的<code>getter</code>和<code>setter</code>方法，定义了两个成对的方法<code>value</code>和<code>value_=</code>进行读取和修改</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Counter</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">  <span class="keyword">var</span> privateValue = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">value</span> </span>= privateValue</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">value_=</span></span>(newValue: <span class="type">Int</span>) = &#123;</span><br><span class="line">    <span class="keyword">if</span> (newValue &gt; <span class="number">0</span>) &#123;</span><br><span class="line">      privateValue = newValue</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">increment</span></span>(step: <span class="type">Int</span>) = &#123;</span><br><span class="line">    value += step</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">current</span> </span>= value</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> myCounter = <span class="keyword">new</span> <span class="type">Counter</span></span><br><span class="line">myCounter: <span class="type">Counter</span> = <span class="type">Counter</span><span class="meta">@f</span>591271</span><br><span class="line">scala&gt; myCounter.value_=(<span class="number">3</span>) <span class="comment">//为privateValue设置新的值</span></span><br><span class="line">scala&gt; println(myCounter.value)<span class="comment">//访问privateValue的当前值</span></span><br><span class="line"><span class="number">3</span></span><br></pre></td></tr></table></figure>

<p>Scala语法中有如下规范，当编译器看到以<code>value</code>和<code>value_=</code>这种成对形式出现的方法时，它允许用户去掉下划线_，而采用类似赋值表达式的形式</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">myCounter.value= <span class="number">3</span> <span class="comment">// 等效于myCounter.value_=(3)</span></span><br></pre></td></tr></table></figure>

<p>如果class Counter{}中，使用 private var value =0，那么，使用scalac命令编译该程序，会出现myCounter.value=3变量无法访问的错误，因为是私有变量，不能从外部访问。</p>
<h3 id="方法的定义方式"><a href="#方法的定义方式" class="headerlink" title="方法的定义方式"></a>方法的定义方式</h3><p>基本语法：</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">方法名</span></span>(参数列表):返回结果类型=&#123;方法体&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>方法参数前不能加上val或var，所有的方法参数都是不可变类型</li>
<li>无参数的方法定义时可以省略括号，这时调用时也不能带有括号；如果定义时带有括号，则调用时可以带括号，也可以不带括号</li>
<li>方法名后面的圆括号()可以用大括号{}来代替</li>
<li>如果方法只有一个参数，可以省略点号（.）而采用中缀操作符调用方法</li>
<li>如果方法体只有一条语句，可以省略方法体两边的大括号</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class Counter() &#123;</span><br><span class="line">  var value &#x3D; 0</span><br><span class="line"></span><br><span class="line">  def increment(step: Int):Unit &#x3D; &#123;</span><br><span class="line">    value +&#x3D; step</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  def current:Int &#x3D; value</span><br><span class="line"></span><br><span class="line">  def getValue():Int &#x3D; value</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> c=<span class="keyword">new</span> <span class="type">Counter</span></span><br><span class="line">c: <span class="type">Counter</span> = <span class="type">Counter</span>@<span class="number">30</span>ab4b0e</span><br><span class="line">scala&gt; c increment <span class="number">5</span> <span class="comment">//中缀调用法</span></span><br><span class="line">scala&gt; c.getValue()     <span class="comment">//getValue定义中有括号，可以带括号调用</span></span><br><span class="line">res0: <span class="type">Int</span> = <span class="number">0</span></span><br><span class="line">scala&gt; c.getValue <span class="comment">// getValue定义中有括号，也可不带括号调用</span></span><br><span class="line">res1: <span class="type">Int</span> = <span class="number">0</span></span><br><span class="line">scala&gt; c.current() <span class="comment">// current定义中没有括号，不可带括号调用</span></span><br><span class="line">&lt;console&gt;:<span class="number">13</span>: error: <span class="type">Int</span> does not take parameters</span><br><span class="line">       c.current()</span><br><span class="line">                ^</span><br><span class="line">scala&gt; c.current  <span class="comment">// current定义中没有括号，只能不带括号调用</span></span><br><span class="line">res3: <span class="type">Int</span> = <span class="number">0</span></span><br></pre></td></tr></table></figure>

<ul>
<li>当方法的返回结果类型可以从最后的表达式推断出时，可以省略结果类型</li>
<li>如果方法返回类型为Unit，可以同时省略返回结果类型和等号，但不能省略大括号</li>
</ul>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Counter</span> </span>&#123;</span><br><span class="line">    <span class="keyword">var</span> value = <span class="number">0</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">increment</span></span>(step:<span class="type">Int</span>) &#123; value += step &#125;<span class="comment">//赋值表达式的值为Unit类型</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">current</span></span>()= value <span class="comment">//根据value的类型自动推断出返回类型为Int型</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="构造器"><a href="#构造器" class="headerlink" title="构造器"></a>构造器</h3><p>Scala类的定义主体就是类的构造器，称为主构造器。在类名之后用圆括号列出主构造器的参数列表</p>
<p>主构造器的参数前可以使用val或var关键字，Scala内部将自动为这些参数创建私有字段，并提供对应的访问方法</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">scala&gt; <span class="class"><span class="keyword">class</span> <span class="title">Counter</span>(<span class="params">var name:<span class="type">String</span></span>) <span class="title">//定义一个带字符串参数的简单类</span></span></span><br><span class="line"><span class="class"><span class="title">defined</span> <span class="title">class</span> <span class="title">Counter</span></span></span><br><span class="line"><span class="class"><span class="title">scala&gt;</span> <span class="title">var</span> <span class="title">mycounter</span> </span>= <span class="keyword">new</span> <span class="type">Counter</span>(<span class="string">&quot;Runner&quot;</span>)</span><br><span class="line">mycounter: <span class="type">Counter</span> = <span class="type">Counter</span>@<span class="number">17</span>fcc4f7</span><br><span class="line">scala&gt; println(mycounter.name) <span class="comment">//调用读方法</span></span><br><span class="line"><span class="type">Runner</span></span><br><span class="line">scala&gt; mycounter.name_=(<span class="string">&quot;Timer&quot;</span>) <span class="comment">//调用写方法</span></span><br><span class="line">scala&gt; mycounter.name = <span class="string">&quot;Timer&quot;</span><span class="comment">// 更直观地调用写方法，和上句等效</span></span><br><span class="line">mycounter.name: <span class="type">String</span> = <span class="type">Timer</span></span><br></pre></td></tr></table></figure>

<p> 如果不希望将构造器参数成为类的字段，只需要省略关键字var或者val</p>
<ul>
<li><p>Scala类可以包含零个或多个辅助构造器（auxiliary constructor）。辅助构造器使用this进行定义，this的返回类型为Unit</p>
</li>
<li><p>每个辅助构造器的第一个表达式必须是调用一个此前已经定义的辅助构造器或主构造器，调用的形式为“this(参数列表)”</p>
</li>
</ul>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Counter</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">var</span> value = <span class="number">0</span> </span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">var</span> name = <span class="string">&quot;&quot;</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">var</span> step = <span class="number">1</span> <span class="comment">//计算器的默认递进步长</span></span><br><span class="line">    println(<span class="string">&quot;the main constructor&quot;</span>)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">this</span></span>(name: <span class="type">String</span>)&#123; <span class="comment">//第一个辅助构造器</span></span><br><span class="line">        <span class="keyword">this</span>() <span class="comment">//调用主构造器</span></span><br><span class="line">        <span class="keyword">this</span>.name = name</span><br><span class="line">        printf(<span class="string">&quot;the first auxiliary constructor,name:%s\n&quot;</span>,name)</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">this</span> </span>(name: <span class="type">String</span>,step: <span class="type">Int</span>)&#123; <span class="comment">//第二个辅助构造器</span></span><br><span class="line">        <span class="keyword">this</span>(name) <span class="comment">//调用前一个辅助构造器</span></span><br><span class="line">        <span class="keyword">this</span>.step = step</span><br><span class="line">       printf(<span class="string">&quot;the second auxiliary constructor,name:%s,step:%d\n&quot;</span>,name,step)</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">increment</span></span>(step: <span class="type">Int</span>): <span class="type">Unit</span> = &#123; value += step&#125;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">current</span></span>(): <span class="type">Int</span> = &#123;value&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> c1=<span class="keyword">new</span> <span class="type">Counter</span></span><br><span class="line">the main constructor</span><br><span class="line">c1: <span class="type">Counter</span> = <span class="type">Counter</span>@<span class="number">319</span>c6b2</span><br><span class="line"> </span><br><span class="line">scala&gt; <span class="keyword">val</span> c2=<span class="keyword">new</span> <span class="type">Counter</span>(<span class="string">&quot;the 2nd Counter&quot;</span>)</span><br><span class="line">the main constructor</span><br><span class="line">the first auxiliary constructor,name:the <span class="number">2</span>nd <span class="type">Counter</span></span><br><span class="line">c2: <span class="type">Counter</span> = <span class="type">Counter</span>@<span class="number">4</span>ed6c602</span><br><span class="line"> </span><br><span class="line">scala&gt; <span class="keyword">val</span> c3=<span class="keyword">new</span> <span class="type">Counter</span>(<span class="string">&quot;the 3rd Counter&quot;</span>,<span class="number">2</span>)</span><br><span class="line">the main constructor</span><br><span class="line">the first auxiliary constructor,name:the <span class="number">3</span>rd <span class="type">Counter</span></span><br><span class="line">the second auxiliary constructor,name:the <span class="number">3</span>rd <span class="type">Counter</span>,step:<span class="number">2</span></span><br><span class="line">c3: <span class="type">Counter</span> = <span class="type">Counter</span>@<span class="number">64</span>fab83b</span><br></pre></td></tr></table></figure>

<h2 id="对象"><a href="#对象" class="headerlink" title="对象"></a>对象</h2><h3 id="单例对象"><a href="#单例对象" class="headerlink" title="单例对象"></a>单例对象</h3><p>Scala采用单例对象（singleton object）来实现与Java静态成员同样的功能</p>
<p>使用object 关键字定义单例对象</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Person</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">var</span> lastId = <span class="number">0</span>  <span class="comment">//一个人的身份编号</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">newPersonId</span></span>() = &#123;</span><br><span class="line">        lastId +=<span class="number">1</span></span><br><span class="line">        lastId</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>单例对象的使用与一个普通的类实例一样：</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">scala&gt; printf(<span class="string">&quot;The first person id: %d.\n&quot;</span>,<span class="type">Person</span>.newPersonId())</span><br><span class="line"><span class="type">The</span> first person id: <span class="number">1.</span></span><br><span class="line">scala&gt; printf(<span class="string">&quot;The second person id：%d.\n&quot;</span>,<span class="type">Person</span>.newPersonId())</span><br><span class="line"><span class="type">The</span> second person id：<span class="number">2.</span></span><br><span class="line">scala&gt; printf(<span class="string">&quot;The third person id: %d.\n&quot;</span>,<span class="type">Person</span>.newPersonId())</span><br><span class="line"><span class="type">The</span> third person id: <span class="number">3.</span></span><br></pre></td></tr></table></figure>

<h4 id="伴生对象和孤立对象"><a href="#伴生对象和孤立对象" class="headerlink" title="伴生对象和孤立对象"></a>伴生对象和孤立对象</h4><ul>
<li><p>当一个单例对象和它的同名类一起出现时，这时的单例对象被称为这个同名类的“伴生对象”（companion object）。相应的类被称为这个单例对象的“伴生类”</p>
</li>
<li><p>类和它的伴生对象必须存在于同一个文件中，可以相互访问私有成员</p>
</li>
<li><p>没有同名类的单例对象，被称为孤立对象（standalone object）。一般情况下，Scala程序的入口点main方法就是定义在一个孤立对象里</p>
</li>
</ul>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Person</span>(<span class="params">val name:<span class="type">String</span></span>)</span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">val</span> id = <span class="type">Person</span>.newPersonId() <span class="comment">//调用了伴生对象中的方法</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">info</span></span>() &#123;</span><br><span class="line">        printf(<span class="string">&quot;The id of %s is %d.\n&quot;</span>,name,id)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Person</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">var</span> lastId = <span class="number">0</span>  <span class="comment">//一个人的身份编号</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">newPersonId</span></span>() = &#123;</span><br><span class="line">        lastId +=<span class="number">1</span></span><br><span class="line">        lastId</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]) &#123;</span><br><span class="line">        <span class="keyword">val</span> person1 = <span class="keyword">new</span> <span class="type">Person</span>(<span class="string">&quot;Lilei&quot;</span>)</span><br><span class="line">        <span class="keyword">val</span> person2 = <span class="keyword">new</span> <span class="type">Person</span>(<span class="string">&quot;Hanmei&quot;</span>)</span><br><span class="line">        person1.info()</span><br><span class="line">        person2.info()</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="type">The</span> id of <span class="type">Lilei</span> is <span class="number">1.</span></span><br><span class="line"><span class="type">The</span> id of <span class="type">Hanmei</span> is <span class="number">2.</span></span><br></pre></td></tr></table></figure>

<h3 id="apply方法"><a href="#apply方法" class="headerlink" title="apply方法"></a>apply方法</h3><p>思考下行代码的执行过程：</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> myStrArr = <span class="type">Array</span>(<span class="string">&quot;BigData&quot;</span>,<span class="string">&quot;Hadoop&quot;</span>,<span class="string">&quot;Spark&quot;</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li>Scala自动调用Array类的伴生对象Array中的一个称为apply的方法，来创建一个Array对象myStrArr</li>
<li>apply方法调用约定：用括号传递给类实例或单例对象名一个或多个参数时，Scala 会在相应的类或对象中查找方法名为apply且参数列表与传入的参数一致的方法，并用传入的参数来调用该apply方法</li>
</ul>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TestApplyClass</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">apply</span></span>(param: <span class="type">String</span>)&#123;</span><br><span class="line">         println(<span class="string">&quot;apply method called: &quot;</span> + param)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> myObject = <span class="keyword">new</span> <span class="type">TestApplyClass</span></span><br><span class="line">myObject: <span class="type">TestApplyClass</span> = <span class="type">TestApplyClass</span>@<span class="number">11</span>b352e9</span><br><span class="line">scala&gt; myObject(<span class="string">&quot;Hello Apply&quot;</span>)<span class="comment">// 自动调用类中定义的apply方法，等同于下句</span></span><br><span class="line">apply method called: <span class="type">Hello</span> <span class="type">Apply</span></span><br><span class="line">scala&gt; myObject.apply(<span class="string">&quot;Hello Apply&quot;</span>)  <span class="comment">//手动调用apply方法</span></span><br><span class="line">apply method called: <span class="type">Hello</span> <span class="type">Apply</span></span><br></pre></td></tr></table></figure>

<p>伴生对象中的apply方法：将所有类的构造方法以apply方法的形式定义在伴生对象中，这样伴生对象就像生成类实例的工厂，而这些apply方法也被称为工厂方法</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Car</span>(<span class="params">name: <span class="type">String</span></span>) </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">info</span></span>() &#123;</span><br><span class="line">        println(<span class="string">&quot;Car name is &quot;</span>+ name)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Car</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">apply</span></span>(name: <span class="type">String</span>) = <span class="keyword">new</span> <span class="type">Car</span>(name) <span class="comment">//调用伴生类Car的构造方法</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">MyTestApply</span></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span> </span>(args: <span class="type">Array</span>[<span class="type">String</span>]) &#123;</span><br><span class="line">    <span class="keyword">val</span> mycar = <span class="type">Car</span>(<span class="string">&quot;BMW&quot;</span>) <span class="comment">//调用伴生对象中的apply方法</span></span><br><span class="line">    mycar.info() <span class="comment">//输出结果为“Car name is BMW”</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>为什么要设计apply方法？</p>
<ul>
<li><p>保持对象和函数之间使用的一致性</p>
</li>
<li><p>面向对象：“对象.方法” VS  数学：“函数(参数)”</p>
</li>
<li><p>Scala中一切都是对象，包括函数也是对象。Scala中的函数既保留括号调用样式，也可以使用点号调用形式，其对应的方法名即为apply</p>
</li>
</ul>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">scala&gt; <span class="function"><span class="keyword">def</span> <span class="title">add=</span></span>(x:<span class="type">Int</span>,y:<span class="type">Int</span>)=&gt;x+y  <span class="comment">//add是一个函数</span></span><br><span class="line">add: (<span class="type">Int</span>, <span class="type">Int</span>) =&gt; <span class="type">Int</span></span><br><span class="line">scala&gt; add(<span class="number">4</span>,<span class="number">5</span>)   <span class="comment">//采用数学界的括号调用样式</span></span><br><span class="line">res2: <span class="type">Int</span> = <span class="number">9</span></span><br><span class="line">scala&gt; add.apply(<span class="number">4</span>,<span class="number">5</span>) <span class="comment">//add也是对象，采用点号形式调用apply方法</span></span><br><span class="line">res3: <span class="type">Int</span> = <span class="number">9</span></span><br></pre></td></tr></table></figure>

<p>Scala的对象也可以看成函数，前提是该对象提供了apply方法</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Car</span>(<span class="params">name: <span class="type">String</span></span>) </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">info</span></span>() &#123;</span><br><span class="line">    println(<span class="string">&quot;Car name is &quot;</span> + name)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Car</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">apply</span></span>(name: <span class="type">String</span>) = <span class="keyword">new</span> <span class="type">Car</span>(name) <span class="comment">//调用伴生类Car的构造方法</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">MyTestApply</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]) &#123;</span><br><span class="line">    <span class="keyword">val</span> mycar = <span class="type">Car</span>(<span class="string">&quot;BMW&quot;</span>) <span class="comment">//调用伴生对象中的apply方法</span></span><br><span class="line">    mycar.info() <span class="comment">//输出结果为“Car name is BMW”</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="update方法"><a href="#update方法" class="headerlink" title="update方法"></a>update方法</h3><p>与apply方法类似的update方法也遵循相应的调用约定：当对带有括号并包括一到若干参数的对象进行赋值时，编译器将调用对象的update方法，并将括号里的参数和等号右边的值一起作为update方法的输入参数来执行调用</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">scala&gt;<span class="keyword">val</span> myStrArr = <span class="keyword">new</span> <span class="type">Array</span>[<span class="type">String</span>](<span class="number">3</span>)  <span class="comment">//声明一个长度为3的字符串数组，每个数组元素初始化为null</span></span><br><span class="line">scala&gt;myStrArr(<span class="number">0</span>) = <span class="string">&quot;BigData&quot;</span> <span class="comment">//实际上，调用了伴生类Array中的update方法，执行myStrArr.update(0,&quot;BigData&quot;)</span></span><br><span class="line">scala&gt;myStrArr(<span class="number">1</span>) = <span class="string">&quot;Hadoop&quot;</span> <span class="comment">//实际上，调用了伴生类Array中的update方法，执行myStrArr.update(1,&quot;Hadoop&quot;)</span></span><br><span class="line">scala&gt;myStrArr(<span class="number">2</span>) = <span class="string">&quot;Spark&quot;</span> <span class="comment">//实际上，调用了伴生类Array中的update方法，执行myStrArr.update(2,&quot;Spark&quot;)</span></span><br></pre></td></tr></table></figure>


<h3 id="unapply方法"><a href="#unapply方法" class="headerlink" title="unapply方法"></a>unapply方法</h3><ul>
<li><p>unapply方法用于对对象进行解构操作，与apply方法类似，该方法也会被自动调用</p>
</li>
<li><p>可以认为unapply方法是apply方法的反向操作，apply方法接受构造参数变成对象，而unapply方法接受一个对象，从中提取值</p>
</li>
</ul>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Car</span>(<span class="params">val brand: <span class="type">String</span>, val price: <span class="type">Int</span></span>) </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">info</span></span>() &#123;</span><br><span class="line">    println(<span class="string">&quot;Car brand is &quot;</span> + brand + <span class="string">&quot; and price is &quot;</span> + price)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Car</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">apply</span></span>(brand: <span class="type">String</span>, price: <span class="type">Int</span>) = &#123;</span><br><span class="line">    println(<span class="string">&quot;Debug:calling apply ... &quot;</span>)</span><br><span class="line">    <span class="keyword">new</span> <span class="type">Car</span>(brand, price)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">unapply</span></span>(c: <span class="type">Car</span>): <span class="type">Option</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = &#123;</span><br><span class="line">    println(<span class="string">&quot;Debug:calling unapply ... &quot;</span>)</span><br><span class="line">    <span class="type">Some</span>((c.brand, c.price))</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">TestUnapply</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]) &#123;</span><br><span class="line">    <span class="keyword">var</span> <span class="type">Car</span>(carbrand, carprice) = <span class="type">Car</span>(<span class="string">&quot;BMW&quot;</span>, <span class="number">800000</span>)</span><br><span class="line">    println(<span class="string">&quot;brand: &quot;</span> + carbrand + <span class="string">&quot; and carprice: &quot;</span> + carprice)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="继承"><a href="#继承" class="headerlink" title="继承"></a>继承</h2><h3 id="抽象类"><a href="#抽象类" class="headerlink" title="抽象类"></a>抽象类</h3><p>如果一个类包含没有实现的成员，则必须使用abstract关键词进行修饰，定义为抽象类</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">Car</span>(<span class="params">val name:<span class="type">String</span></span>) </span>&#123;</span><br><span class="line">    <span class="keyword">val</span> carBrand:<span class="type">String</span> <span class="comment">//字段没有初始化值，就是一个抽象字段</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">info</span></span>() <span class="comment">//抽象方法</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">greeting</span></span>() &#123;</span><br><span class="line">        println(<span class="string">&quot;Welcome to my car!&quot;</span>)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>关于上面的定义，说明几点：<br>（1）定义一个抽象类，需要使用关键字abstract<br>（2）定义一个抽象类的抽象方法，不需要关键字abstract，只要把方法体空着，不写方法体就可以<br>（3）抽象类中定义的字段，只要没有给出初始化值，就表示是一个抽象字段，但是，抽象字段必须要声明类型，否则编译会报错</p>
<h3 id="扩展类"><a href="#扩展类" class="headerlink" title="扩展类"></a>扩展类</h3><p>Scala只支持单一继承，而不支持多重继承。在类定义中使用extends关键字表示继承关系。定义子类时，需要注意：</p>
<ul>
<li><p>重载父类的抽象成员（包括字段和方法）时，override关键字是可选的；而重载父类的非抽象成员时，override关键字是必选的</p>
</li>
<li><p>只能重载val类型的字段，而不能重载var类型的字段。因为var类型本身就是可变的，所以，可以直接修改它的值，无需重载</p>
</li>
</ul>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">//抽象类的定义</span></span><br><span class="line"><span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">Animal</span> </span>&#123;</span><br><span class="line">  <span class="comment">//抽象字段，没有初始化值</span></span><br><span class="line">  <span class="keyword">var</span> name: <span class="type">String</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">//抽象方法</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">id</span></span>: <span class="type">Int</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">//具体方法</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">show</span></span>() = &#123;</span><br><span class="line">    println(<span class="string">&quot;this is animal&quot;</span>)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Cat</span> <span class="keyword">extends</span> <span class="title">Animal</span> </span>&#123;</span><br><span class="line">  <span class="keyword">var</span> name = <span class="string">&quot;cat&quot;</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">id</span></span>: <span class="type">Int</span> = &#123;</span><br><span class="line">    name.hashCode</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">show</span></span>() = &#123;</span><br><span class="line">    println(<span class="string">&quot;this is cat&quot;</span>)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">abstractTest</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">var</span> cat1 = <span class="keyword">new</span> <span class="type">Cat</span>()</span><br><span class="line">    cat1.show()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="Scala的类层次结构"><a href="#Scala的类层次结构" class="headerlink" title="Scala的类层次结构"></a>Scala的类层次结构</h3><p><img data-src="scala-learning/02.png" alt="Scala的类层次结构"></p>
<p>在字节码层面上，Scala 直接使用JVM 原生类型来表示值类型，并将它们的实例保存在栈或寄存器上。值类型没有构造器，不能使用new 关键字创建，只能通过用字面量来创建或者来自表达式运算结果。</p>
<p>之所以被称为引用类型，是因为它们的实例是分配在堆内存上，这些实例对应的变量实际是指向了堆中的相应位置</p>
<ul>
<li><p>Null是所有引用类型的子类，其唯一的实例为null，表示一个“空”对象，可以赋值给任何引用类型的变量，但不能赋值给值类型的变量</p>
</li>
<li><p>Nothing是所有其它类型的子类，包括Null。Nothing没有实例，主要用于异常处理函数的返回类型</p>
</li>
</ul>
<h3 id="Option类"><a href="#Option类" class="headerlink" title="Option类"></a>Option类</h3><ul>
<li><p>Scala提供null是为了实现在JVM与其它Java库的兼容性，但是，除非明确需要与Java库进行交互，否则，Scala建议尽量避免使用这种可能带来bug的null，而改用Option类</p>
</li>
<li><p>Option是一个抽象类，有一个具体的子类Some和一个对象None，其中，前者表示有值的情形，后者表示没有值</p>
</li>
<li><p>当方法不确定是否有对象返回时，可以让返回值类型为Option[T]，其中，T为类型参数。对于这类方法，如果确实有T类型的对象需要返回，会将该对象包装成一个Some对象并返回；如果没有值需要返回，将返回None</p>
</li>
</ul>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">scala&gt; <span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">Book</span>(<span class="params">val name:<span class="type">String</span>,val price:<span class="type">Double</span></span>)</span></span><br><span class="line"><span class="class"><span class="title">defined</span> <span class="title">class</span> <span class="title">Book</span></span></span><br><span class="line"><span class="class"><span class="title">scala&gt;</span> <span class="title">val</span> <span class="title">books=Map</span>(<span class="params">&quot;hadoop&quot;-&gt;<span class="type">Book</span>(&quot;<span class="type">Hadoop</span>&quot;,35.5</span>),</span></span><br><span class="line"><span class="class">     <span class="title">|</span> &quot;<span class="title">spark</span>&quot;<span class="title">-&gt;Book</span>(<span class="params">&quot;<span class="type">Spark</span>&quot;,55.5</span>),</span></span><br><span class="line"><span class="class">     <span class="title">|</span> &quot;<span class="title">hbase</span>&quot;<span class="title">-&gt;Book</span>(<span class="params">&quot;<span class="type">Hbase</span>&quot;,26.0</span>)) <span class="title">//定义一个书名到书对象的映射</span></span></span><br><span class="line"><span class="class"><span class="title">books</span></span>: scala.collection.immutable.<span class="type">Map</span>[<span class="type">String</span>,<span class="type">Book</span>] =… </span><br><span class="line">scala&gt; books.get(<span class="string">&quot;hadoop&quot;</span>) <span class="comment">//返回该键所对应值的Some对象</span></span><br><span class="line">res0: <span class="type">Option</span>[<span class="type">Book</span>] = <span class="type">Some</span>(<span class="type">Book</span>(<span class="type">Hadoop</span>,<span class="number">35.5</span>))</span><br><span class="line">scala&gt; books.get(<span class="string">&quot;hive&quot;</span>) <span class="comment">// 不存在该键，返回None对象</span></span><br><span class="line">res1: <span class="type">Option</span>[<span class="type">Book</span>] = <span class="type">None</span></span><br><span class="line">scala&gt; books.get(<span class="string">&quot;hadoop&quot;</span>).get <span class="comment">//Some对象的get方法返回其包装的对象</span></span><br><span class="line">res2: <span class="type">Book</span> = <span class="type">Book</span>(<span class="type">Hadoop</span>,<span class="number">35.5</span>)</span><br><span class="line">scala&gt; books.get(<span class="string">&quot;hive&quot;</span>).get <span class="comment">// None对象的get方法会抛出异常</span></span><br><span class="line">java.util.<span class="type">NoSuchElementException</span>: <span class="type">None</span>.get</span><br><span class="line">  …</span><br><span class="line">scala&gt; books.get(<span class="string">&quot;hive&quot;</span>).getOrElse(<span class="type">Book</span>(<span class="string">&quot;Unknown name&quot;</span>,<span class="number">0</span>))</span><br><span class="line">res4: <span class="type">Book</span> = <span class="type">Book</span>(<span class="type">Unknown</span> name,<span class="number">0.0</span>)</span><br></pre></td></tr></table></figure>

<h2 id="特质"><a href="#特质" class="headerlink" title="特质"></a>特质</h2><h3 id="特质概述"><a href="#特质概述" class="headerlink" title="特质概述"></a>特质概述</h3><ul>
<li><p>Java中提供了接口，允许一个类实现任意数量的接口</p>
</li>
<li><p>Scala中没有接口的概念，而是提供了“特质(trait)”，它不仅实现了接口的功能，还具备了很多其他的特性</p>
</li>
<li><p>Scala的特质是代码重用的基本单元，可以同时拥有抽象方法和具体方法</p>
</li>
<li><p>Scala中，一个类只能继承自一个超类，却可以实现多个特质，从而重用特质中的方法和字段，实现了多重继承</p>
</li>
</ul>
<h3 id="特质的定义"><a href="#特质的定义" class="headerlink" title="特质的定义"></a>特质的定义</h3><p>使用关键字trait定义特质</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">trait</span> <span class="title">Flyable</span> </span>&#123;</span><br><span class="line">    <span class="keyword">var</span> maxFlyHeight:<span class="type">Int</span>  <span class="comment">//抽象字段</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fly</span></span>() <span class="comment">//抽象方法</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">breathe</span></span>()&#123; <span class="comment">//具体的方法</span></span><br><span class="line">        println(<span class="string">&quot;I can breathe&quot;</span>)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>特质既可以包含抽象成员，也可以包含非抽象成员。包含抽象成员时，不需要abstract关键字</li>
<li>特质可以使用extends继承其它的特质</li>
</ul>
<h3 id="把特质混入类中"><a href="#把特质混入类中" class="headerlink" title="把特质混入类中"></a>把特质混入类中</h3><p>可以使用extends或with关键字把特质混入类中</p>
<p>如果特质中包含抽象成员，则该类必须为这些抽象成员提供具体实现，除非该类被定义为抽象类</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Bird</span>(<span class="params">flyHeight:<span class="type">Int</span></span>) <span class="keyword">extends</span> <span class="title">Flyable</span></span>&#123;</span><br><span class="line">    <span class="keyword">var</span> maxFlyHeight:<span class="type">Int</span> = flyHeight  <span class="comment">//重载特质的抽象字段</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fly</span></span>()&#123;</span><br><span class="line">        printf(<span class="string">&quot;I can fly at the height of %d.&quot;</span>,maxFlyHeight)</span><br><span class="line">    &#125; <span class="comment">//重载特质的抽象方法</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>把上面定义的特质Flyable和类Bird封装到一个代码文件Bird.scala中：</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">trait</span> <span class="title">Flyable</span> </span>&#123;</span><br><span class="line">    <span class="keyword">var</span> maxFlyHeight:<span class="type">Int</span>  <span class="comment">//抽象字段</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fly</span></span>() <span class="comment">//抽象方法</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">breathe</span></span>()&#123; <span class="comment">//具体的方法</span></span><br><span class="line">        println(<span class="string">&quot;I can breathe&quot;</span>)</span><br><span class="line">    &#125;</span><br><span class="line"> &#125;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Bird</span>(<span class="params">flyHeight:<span class="type">Int</span></span>) <span class="keyword">extends</span> <span class="title">Flyable</span></span>&#123;</span><br><span class="line">    <span class="keyword">var</span> maxFlyHeight:<span class="type">Int</span> = flyHeight  <span class="comment">//重载特质的抽象字段</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fly</span></span>()&#123;</span><br><span class="line">        printf(<span class="string">&quot;I can fly at the height of %d&quot;</span>,maxFlyHeight)</span><br><span class="line">    &#125; <span class="comment">//重载特质的抽象方法</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> b=<span class="keyword">new</span> <span class="type">Bird</span>(<span class="number">100</span>)</span><br><span class="line">b: <span class="type">Bird</span> = <span class="type">Bird</span>@<span class="number">43</span>a51d00</span><br><span class="line"> </span><br><span class="line">scala&gt; b.fly()</span><br><span class="line"><span class="type">I</span> can fly at the height of <span class="number">100</span></span><br><span class="line">scala&gt; b.breathe()</span><br><span class="line"><span class="type">I</span> can breathe</span><br></pre></td></tr></table></figure>

<p>如果要混入多个特质，可以连续使用多个with</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">trait</span> <span class="title">Flyable</span> </span>&#123;</span><br><span class="line">    <span class="keyword">var</span> maxFlyHeight:<span class="type">Int</span>  <span class="comment">//抽象字段</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fly</span></span>() <span class="comment">//抽象方法</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">breathe</span></span>()&#123; <span class="comment">//具体的方法</span></span><br><span class="line">        println(<span class="string">&quot;I can breathe&quot;</span>)</span><br><span class="line">    &#125;</span><br><span class="line"> &#125;</span><br><span class="line"><span class="class"><span class="keyword">trait</span> <span class="title">HasLegs</span> </span>&#123;</span><br><span class="line">    <span class="keyword">val</span> legs:<span class="type">Int</span>   <span class="comment">//抽象字段</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">move</span></span>()&#123;printf(<span class="string">&quot;I can walk with %d legs&quot;</span>,legs)&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Animal</span>(<span class="params">val category:<span class="type">String</span></span>)</span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">info</span></span>()&#123;println(<span class="string">&quot;This is a &quot;</span>+category)&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Bird</span>(<span class="params">flyHeight:<span class="type">Int</span></span>) <span class="keyword">extends</span> <span class="title">Animal</span>(<span class="params">&quot;<span class="type">Bird</span>&quot;</span>) <span class="keyword">with</span> <span class="title">Flyable</span> <span class="keyword">with</span> <span class="title">HasLegs</span></span>&#123;</span><br><span class="line">    <span class="keyword">var</span> maxFlyHeight:<span class="type">Int</span> = flyHeight <span class="comment">//重载特质的抽象字段</span></span><br><span class="line">    <span class="keyword">val</span> legs=<span class="number">2</span> <span class="comment">//重载特质的抽象字段</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fly</span></span>()&#123;</span><br><span class="line">       printf(<span class="string">&quot;I can fly at the height of %d&quot;</span>,maxFlyHeight)</span><br><span class="line">    &#125;<span class="comment">//重载特质的抽象方法</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> b=<span class="keyword">new</span> <span class="type">Bird</span>(<span class="number">108</span>)</span><br><span class="line">b: <span class="type">Bird</span> = <span class="type">Bird</span>@<span class="number">126675</span>fd</span><br><span class="line">scala&gt; b.info</span><br><span class="line"><span class="type">This</span> is a <span class="type">Bird</span></span><br><span class="line">scala&gt; b.fly</span><br><span class="line"><span class="type">I</span> can fly at the height of <span class="number">108</span></span><br><span class="line">scala&gt; b.move</span><br><span class="line"><span class="type">I</span> can walk <span class="keyword">with</span> <span class="number">2</span> legs</span><br></pre></td></tr></table></figure>

<h2 id="模式匹配"><a href="#模式匹配" class="headerlink" title="模式匹配"></a>模式匹配</h2><h3 id="match语句"><a href="#match语句" class="headerlink" title="match语句"></a>match语句</h3><p>最常见的模式匹配是match语句，match语句用在当需要从多个分支中进行选择的场景</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> scala.io.<span class="type">StdIn</span>._</span><br><span class="line"></span><br><span class="line">println(<span class="string">&quot;Please input the score:&quot;</span>)</span><br><span class="line"><span class="keyword">val</span> grade = readChar()</span><br><span class="line"></span><br><span class="line">grade <span class="keyword">match</span> &#123;</span><br><span class="line">  <span class="keyword">case</span> &#x27;<span class="type">A</span>&#x27; =&gt; println(<span class="string">&quot;85-100&quot;</span>)</span><br><span class="line">  <span class="keyword">case</span> &#x27;<span class="type">B</span>&#x27; =&gt; println(<span class="string">&quot;70-84&quot;</span>)</span><br><span class="line">  <span class="keyword">case</span> &#x27;<span class="type">C</span>&#x27; =&gt; println(<span class="string">&quot;60-69&quot;</span>)</span><br><span class="line">  <span class="keyword">case</span> &#x27;<span class="type">D</span>&#x27; =&gt; println(<span class="string">&quot;&lt;60&quot;</span>)</span><br><span class="line">  <span class="keyword">case</span> _ =&gt; println(<span class="string">&quot;error input!&quot;</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>通配符_相当于Java中的default分支</li>
</ul>
<ul>
<li>match结构中不需要break语句来跳出判断，Scala从前往后匹配到一个分支后，会自动跳出判断</li>
</ul>
<p>case后面的表达式可以是任何类型的常量，而不要求是整数类型</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> scala.io.<span class="type">StdIn</span>._</span><br><span class="line">println(<span class="string">&quot;Please input a country:&quot;</span>)</span><br><span class="line"><span class="keyword">val</span> country = readLine()</span><br><span class="line">country <span class="keyword">match</span> &#123;</span><br><span class="line">  <span class="keyword">case</span> <span class="string">&quot;China&quot;</span> =&gt; println(<span class="string">&quot;中国&quot;</span>)</span><br><span class="line">  <span class="keyword">case</span> <span class="string">&quot;America&quot;</span> =&gt; println(<span class="string">&quot;美国&quot;</span>)</span><br><span class="line">  <span class="keyword">case</span> <span class="string">&quot;Japan&quot;</span> =&gt; println(<span class="string">&quot;日本&quot;</span>)</span><br><span class="line">  <span class="keyword">case</span> _ =&gt; println(<span class="string">&quot;我不认识!&quot;</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>除了匹配特定的常量，还能匹配某种类型的所有值</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> (elem &lt;- <span class="type">List</span>(<span class="number">6</span>, <span class="number">9</span>, <span class="number">0.618</span>, <span class="string">&quot;Spark&quot;</span>, <span class="string">&quot;Hadoop&quot;</span>, <span class="symbol">&#x27;Hello</span>)) &#123;</span><br><span class="line">  <span class="keyword">val</span> str = elem <span class="keyword">match</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> i: <span class="type">Int</span> =&gt; i + <span class="string">&quot; is an int value.&quot;</span> <span class="comment">//匹配整型的值，并赋值给i</span></span><br><span class="line">    <span class="keyword">case</span> d: <span class="type">Double</span> =&gt; d + <span class="string">&quot; is a double value.&quot;</span> <span class="comment">//匹配浮点型的值</span></span><br><span class="line">    <span class="keyword">case</span> <span class="string">&quot;Spark&quot;</span> =&gt; <span class="string">&quot;Spark is found.&quot;</span> <span class="comment">//匹配特定的字符串</span></span><br><span class="line">    <span class="keyword">case</span> s: <span class="type">String</span> =&gt; s + <span class="string">&quot; is a string value.&quot;</span> <span class="comment">//匹配其它字符串</span></span><br><span class="line">    <span class="keyword">case</span> _ =&gt; <span class="string">&quot;unexpected value：&quot;</span> + elem <span class="comment">//与以上都不匹配</span></span><br><span class="line">  &#125;</span><br><span class="line">  println(str)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">6 is an int value.</span><br><span class="line">9 is an int value.</span><br><span class="line">0.618 is a double value.</span><br><span class="line">Spark is found.</span><br><span class="line">Hadoop is a string value.</span><br><span class="line">unexpected value：&#39;Hello</span><br></pre></td></tr></table></figure>

<p>可以在match表达式的case中使用守卫式（guard）添加一些过滤逻辑</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> (elem &lt;- <span class="type">List</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>))&#123;</span><br><span class="line">  elem <span class="keyword">match</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> _ <span class="keyword">if</span> (elem%<span class="number">2</span>==<span class="number">0</span>) =&gt; println(elem + <span class="string">&quot; is even.&quot;</span>)</span><br><span class="line">    <span class="keyword">case</span> _ =&gt; println(elem + <span class="string">&quot; is odd.&quot;</span>)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="case类"><a href="#case类" class="headerlink" title="case类"></a>case类</h3><ul>
<li><p>case类是一种特殊的类，它们经过优化以被用于模式匹配</p>
</li>
<li><p>当定义一个类时，如果在class关键字前加上case关键字，则该类称为case类</p>
</li>
<li><p>Scala为case类自动重载了许多实用的方法，包括toString、equals和hashcode方法</p>
</li>
<li><p>Scala为每一个case类自动生成一个伴生对象，其包括模板代码</p>
<ul>
<li>1个apply方法，因此，实例化case类的时候无需使用new关键字</li>
<li>1个unapply方法，该方法包含一个类型为伴生类的参数，返回的结果是Option类型，对应的类型参数是N元组，N是伴生类中主构造器参数的个数。Unapply方法用于对对象进行解构操作，在case类模式匹配中，该方法被自动调用，并将待匹配的对象作为参数传递给它</li>
</ul>
</li>
</ul>
<p>例如，假设有如下定义的一个case类：</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">Car</span>(<span class="params">brand: <span class="type">String</span>, price: <span class="type">Int</span></span>)</span></span><br></pre></td></tr></table></figure>

<p>则编译器自动生成的伴生对象是：</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span>  <span class="title">Car</span></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">apply</span></span>(brand:<span class="type">String</span>,price:<span class="type">Int</span>)= <span class="keyword">new</span> <span class="type">Car</span>(brand,price)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">unapply</span></span>(c:<span class="type">Car</span>):<span class="type">Option</span>[(<span class="type">String</span>,<span class="type">Int</span>)]=<span class="type">Some</span>((c.brand,c.price))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">Car</span>(<span class="params">brand: <span class="type">String</span>, price: <span class="type">Int</span></span>)</span></span><br><span class="line"><span class="class"><span class="title">val</span> <span class="title">myBYDCar</span> </span>= <span class="type">Car</span>(<span class="string">&quot;BYD&quot;</span>, <span class="number">89000</span>)</span><br><span class="line"><span class="keyword">val</span> myBMWCar = <span class="type">Car</span>(<span class="string">&quot;BMW&quot;</span>, <span class="number">1200000</span>)</span><br><span class="line"><span class="keyword">val</span> myBenzCar = <span class="type">Car</span>(<span class="string">&quot;Benz&quot;</span>, <span class="number">1500000</span>)</span><br><span class="line"><span class="keyword">for</span> (car &lt;- <span class="type">List</span>(myBYDCar, myBMWCar, myBenzCar)) &#123;</span><br><span class="line">  car <span class="keyword">match</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> <span class="type">Car</span>(<span class="string">&quot;BYD&quot;</span>, <span class="number">89000</span>) =&gt; println(<span class="string">&quot;Hello, BYD!&quot;</span>)</span><br><span class="line">    <span class="keyword">case</span> <span class="type">Car</span>(<span class="string">&quot;BMW&quot;</span>, <span class="number">1200000</span>) =&gt; println(<span class="string">&quot;Hello, BMW!&quot;</span>)</span><br><span class="line">    <span class="keyword">case</span> <span class="type">Car</span>(brand, price) =&gt; println(<span class="string">&quot;Brand:&quot;</span> + brand + <span class="string">&quot;, Price: &quot;</span> + price + <span class="string">&quot;, do you want it ? &quot;</span>)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="包"><a href="#包" class="headerlink" title="包"></a>包</h2><h3 id="包的定义"><a href="#包的定义" class="headerlink" title="包的定义"></a>包的定义</h3><ul>
<li>为了解决程序中命名冲突问题，Scala也和Java一样采用包(package)来层次化、模块化地组织程序</li>
</ul>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span>  autodepartment</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyClass</span></span></span><br></pre></td></tr></table></figure>

<ul>
<li><p>为了在任意位置访问MyClass类，需要使用autodepartment.MyClass</p>
</li>
<li><p>通过在关键字package后面加大括号，可以将程序的不同部分放在不同的包里。这样可以实现包的嵌套，相应的作用域也是嵌套的</p>
</li>
</ul>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> xmu &#123;</span><br><span class="line">    <span class="keyword">package</span> autodepartment &#123;</span><br><span class="line">        <span class="class"><span class="keyword">class</span> <span class="title">ControlCourse</span></span>&#123;</span><br><span class="line">            ...</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">package</span> csdepartment &#123;</span><br><span class="line">        <span class="class"><span class="keyword">class</span>  <span class="title">OSCourse</span></span>&#123;</span><br><span class="line">            <span class="keyword">val</span> cc = <span class="keyword">new</span> autodepartment.<span class="type">ControlCourse</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="引用包成员"><a href="#引用包成员" class="headerlink" title="引用包成员"></a>引用包成员</h3><ul>
<li>可以用import 子句来引用包成员，这样可以简化包成员的访问方式</li>
</ul>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> xmu.autodepartment.<span class="type">ControlCourse</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyClass</span></span>&#123;</span><br><span class="line">    <span class="keyword">var</span> myos=<span class="keyword">new</span> <span class="type">ControlCourse</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>使用通配符下划线（_）引入类或对象的所有成员</li>
</ul>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> scala.io.<span class="type">StdIn</span>._</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> i=readInt()</span><br><span class="line"><span class="keyword">var</span> f=readFloat()</span><br><span class="line"><span class="keyword">var</span> str=readLine()</span><br></pre></td></tr></table></figure>

<ul>
<li>Scala 隐式地添加了一些引用到每个程序前面，相当于每个Scala程序都隐式地以如下代码开始：</li>
</ul>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.lang._</span><br><span class="line"><span class="keyword">import</span> scala._</span><br><span class="line"><span class="keyword">import</span> <span class="type">Predef</span>._</span><br></pre></td></tr></table></figure>

<h1 id="函数式编程基础"><a href="#函数式编程基础" class="headerlink" title="函数式编程基础"></a>函数式编程基础</h1><h2 id="函数定义与使用"><a href="#函数定义与使用" class="headerlink" title="函数定义与使用"></a>函数定义与使用</h2><p>定义函数最通用的方法是作为某个类或者对象的成员，这种函数被称为方法，其定义的基本语法为</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">方法名</span></span>(参数列表):结果类型=&#123;方法体&#125;</span><br></pre></td></tr></table></figure>

<p><img data-src="scala-learning/image-20191216095217933.png" alt="image-20191216095217933"></p>
<p>字面量包括整数字面量、浮点数字面量、布尔型字面量、字符字面量、字符串字面量、符号字面量、函数字面量和元组字面量</p>
<p><img data-src="scala-learning/image-20191216095332315.png" alt="image-20191216095332315"></p>
<p>除了函数字面量我们会比较陌生以外，其他几种字面量都很容易理解</p>
<ul>
<li>函数字面量可以体现函数式编程的核心理念</li>
<li>在函数式编程中，函数是“头等公民”，可以像任何其他数据类型一样被传递和操作，也就是说，函数的使用方式和其他数据类型的使用方式完全一致了</li>
<li>这时，我们就可以像定义变量那样去定义一个函数，由此导致的结果是，函数也会和其他变量一样，开始有“值”</li>
<li>就像变量的“类型”和“值”是分开的两个概念一样，函数式编程中，函数的“类型”和“值”也成为两个分开的概念，函数的“值”，就是“函数字面量”</li>
</ul>
<p>下面一点点引导大家更好地理解函数的“类型”和“值”的概念</p>
<p>现在定义一个大家比较熟悉的传统类型的函数，定义的语法和我们之前介绍过的定义“类中的方法”类似（实际上，定义函数最常用的方法是作为某个对象的成员，这种函数被称为方法）：</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">counter</span></span>(value: <span class="type">Int</span>): <span class="type">Int</span> = &#123; value += <span class="number">1</span>&#125;</span><br></pre></td></tr></table></figure>

<p>上面定义个这个函数的“类型”如下：</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">(<span class="type">Int</span>) =&gt; <span class="type">Int</span></span><br></pre></td></tr></table></figure>

<p>实际上，只有多个参数时（不同参数之间用逗号隔开），圆括号才是必须的，当参数只有一个时，圆括号可以省略，如下：</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="type">Int</span> =&gt; <span class="type">Int</span></span><br></pre></td></tr></table></figure>

<p>上面就得到了函数的“类型”</p>
<p>下面看看如何得到函数的“值”</p>
<p>实际上，我们只要把函数定义中的类型声明部分去除，剩下的就是函数的“值”，如下：</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">(value) =&gt; &#123;value += <span class="number">1</span>&#125; <span class="comment">//只有一条语句时，大括号可以省略</span></span><br></pre></td></tr></table></figure>

<p>注意：上面就是函数的“值”，需要注意的是，采用“=&gt;”而不是“=”，这是Scala的语法要求</p>
<p>现在，我们再按照大家比较熟悉的定义变量的方式，采用Scala语法来定义一个函数。</p>
<p>声明一个变量时，我们采用的形式是：</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> num: <span class="type">Int</span> = <span class="number">5</span></span><br></pre></td></tr></table></figure>

<p>照葫芦画瓢，我们也可以按照上面类似的形式来定义Scala中的函数：</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> counter: <span class="type">Int</span> =&gt; <span class="type">Int</span> = &#123; (value) =&gt; value += <span class="number">1</span> &#125;</span><br></pre></td></tr></table></figure>

<p>从上面可以看出，在Scala中，函数已经是“头等公民”，单独剥离出来了“值”的概念，一个函数“值”就是函数字面量。这样，我们只要在某个需要声明函数的地方声明一个函数类型，在调用的时候传一个对应的函数字面量即可，和使用普通变量一模一样</p>
<p>我们不需要给每个函数命名，这时就可以使用匿名函数，如下：</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">(num: <span class="type">Int</span>) =&gt; num * <span class="number">2</span></span><br></pre></td></tr></table></figure>

<p>上面这种匿名函数的定义形式，我们经常称为“Lambda表达式”。“Lambda表达式”的形式如下：</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">(参数) =&gt; 表达式</span><br><span class="line"><span class="comment">//如果参数只有一个，参数的圆括号可以省略</span></span><br></pre></td></tr></table></figure>

<p>我们可以直接把匿名函数存放到变量中，下面是在Scala解释器中的执行过程：</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> myNumFunc: <span class="type">Int</span>=&gt;<span class="type">Int</span> = (num: <span class="type">Int</span>) =&gt; num * <span class="number">2</span> </span><br><span class="line">myNumFunc: <span class="type">Int</span> =&gt; <span class="type">Int</span> = &lt;function1&gt; <span class="comment">//这行是执行返回的结果</span></span><br><span class="line">scala&gt; println(myNumFunc(<span class="number">3</span>)) </span><br><span class="line"><span class="comment">//myNumFunc函数调用的时候，需要给出参数的值，这里传入3</span></span><br><span class="line"><span class="number">6</span></span><br></pre></td></tr></table></figure>

<p>实际上，Scala具有类型推断机制，可以自动推断变量类型，比如下面两条语句都是可以的：</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> number: <span class="type">Int</span> = <span class="number">5</span></span><br><span class="line"><span class="keyword">val</span> number =<span class="number">5</span> <span class="comment">//省略Int类型声明</span></span><br></pre></td></tr></table></figure>

<p>所以，上面的定义中，我们可以myNumFunc的类型声明，也就是去掉“Int=&gt;Int”，在Scala解释器中的执行过程如下：</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> myNumFunc = (num: <span class="type">Int</span>) =&gt; num * <span class="number">2</span></span><br><span class="line">myNumFunc: <span class="type">Int</span> =&gt; <span class="type">Int</span> = &lt;function1&gt;</span><br><span class="line">scala&gt; println(myNumFunc(<span class="number">3</span>))</span><br><span class="line"><span class="number">6</span></span><br></pre></td></tr></table></figure>

<p>下面我们再尝试一下，是否可以继续省略num的类型声明，在Scala解释器中的执行过程如下：</p>
<p><img data-src="scala-learning/image-20191216100052821.png" alt="image-20191216100052821"></p>
<p>可以看出，解释器会报错，因为，全部省略以后，实际上，解释器也无法推断出类型</p>
<p>下面我们尝试一下，省略num的类型声明，但是，给出myNumFunc的类型声明，在Scala解释器中的执行过程如下：</p>
<p><img data-src="scala-learning/image-20191216100115309.png" alt="image-20191216100115309"></p>
<p>不会报错，因为，给出了myNumFunc的类型为“Int=&gt;Int”以后，解释器可以推断出num类型为Int类型。</p>
<ul>
<li>当函数的每个参数在函数字面量内仅出现一次，可以省略“=&gt;”并用下划线“_”作为参数的占位符来简化函数字面量的表示，第一个下划线代表第一个参数，第二个下划线代表第二个参数，依此类推</li>
</ul>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> counter = (_:<span class="type">Int</span>) + <span class="number">1</span> <span class="comment">//有类型时括号不能省略，等效于“x:Int=&gt;x+1”</span></span><br><span class="line">counter: <span class="type">Int</span> =&gt; <span class="type">Int</span> = &lt;function1&gt;</span><br><span class="line">scala&gt; <span class="keyword">val</span> add = (_:<span class="type">Int</span>) + (_:<span class="type">Int</span>) <span class="comment">//等效于“(a:Int,b:Int)=&gt;a+b”</span></span><br><span class="line">add: (<span class="type">Int</span>, <span class="type">Int</span>) =&gt; <span class="type">Int</span> = &lt;function2&gt;</span><br><span class="line">scala&gt; <span class="keyword">val</span> m1=<span class="type">List</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line">m1: <span class="type">List</span>[<span class="type">Int</span>] = <span class="type">List</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line">scala&gt;<span class="keyword">val</span> m2=m1.map(_*<span class="number">2</span>)<span class="comment">//map接受一个函数作为参数，相当于“m1.map(x=&gt;x*2)”，参数的类型可以根据m1的元素类型推断出，所以可以省略。</span></span><br><span class="line">m2: <span class="type">List</span>[<span class="type">Int</span>] = <span class="type">List</span>(<span class="number">2</span>, <span class="number">4</span>, <span class="number">6</span>)</span><br></pre></td></tr></table></figure>

<h2 id="高阶函数"><a href="#高阶函数" class="headerlink" title="高阶函数"></a>高阶函数</h2><p>当一个函数包含其它函数作为其参数或者返回结果为一个函数时，该函数被称为高阶函数</p>
<p>例：假设需要分别计算从一个整数到另一个整数的“连加和”、“平方和”以及“2的幂次和”</p>
<p><strong>方案一：不采用高阶函数</strong></p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">powerOfTwo</span></span>(x: <span class="type">Int</span>): <span class="type">Int</span> = &#123;<span class="keyword">if</span>(x == <span class="number">0</span>) <span class="number">1</span> <span class="keyword">else</span> <span class="number">2</span> * powerOfTwo(x<span class="number">-1</span>)&#125;</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sumInts</span></span>(a: <span class="type">Int</span>, b: <span class="type">Int</span>): <span class="type">Int</span> = &#123;</span><br><span class="line">    <span class="keyword">if</span>(a &gt; b) <span class="number">0</span> <span class="keyword">else</span> a + sumInts(a + <span class="number">1</span>, b)</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sumSquares</span></span>(a: <span class="type">Int</span>, b: <span class="type">Int</span>): <span class="type">Int</span> = &#123;</span><br><span class="line">    <span class="keyword">if</span>(a &gt; b) <span class="number">0</span> <span class="keyword">else</span> a*a + sumSquares(a + <span class="number">1</span>, b)</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sumPowersOfTwo</span></span>(a: <span class="type">Int</span>, b: <span class="type">Int</span>): <span class="type">Int</span> = &#123;</span><br><span class="line">    <span class="keyword">if</span>(a &gt; b) <span class="number">0</span> <span class="keyword">else</span> powerOfTwo(a) + sumPowersOfTwo(a+<span class="number">1</span>, b)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>例：假设需要分别计算从一个整数到另一个整数的“连加和”、“平方和”以及“2的幂次和”</p>
<p><strong>方案二：采用高阶函数</strong></p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sum</span></span>(f: <span class="type">Int</span> =&gt; <span class="type">Int</span>, a: <span class="type">Int</span>, b: <span class="type">Int</span>):<span class="type">Int</span> = &#123;</span><br><span class="line">    <span class="keyword">if</span>(a &gt; b) <span class="number">0</span> <span class="keyword">else</span> f(a) + sum(f, a+<span class="number">1</span>, b)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">scala&gt; sum(x=&gt;x,<span class="number">1</span>,<span class="number">5</span>) <span class="comment">//直接传入一个匿名函数</span></span><br><span class="line"><span class="comment">//且省略了参数x的类型，因为可以由sum的参数类型推断出来</span></span><br><span class="line">res8: <span class="type">Int</span> = <span class="number">15</span></span><br><span class="line">scala&gt; sum(x=&gt;x*x,<span class="number">1</span>,<span class="number">5</span>) <span class="comment">//直接传入另一个匿名函数</span></span><br><span class="line">res9: <span class="type">Int</span> = <span class="number">55</span></span><br><span class="line">scala&gt; sum(powerOfTwo,<span class="number">1</span>,<span class="number">5</span>) <span class="comment">//传入一个已经定义好的方法</span></span><br><span class="line">res10: <span class="type">Int</span> = <span class="number">62</span></span><br></pre></td></tr></table></figure>

<h2 id="针对容器的操作"><a href="#针对容器的操作" class="headerlink" title="针对容器的操作"></a>针对容器的操作</h2><h3 id="遍历操作"><a href="#遍历操作" class="headerlink" title="遍历操作"></a>遍历操作</h3><ul>
<li>Scala容器的标准遍历方法foreach</li>
</ul>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">foreach</span></span>[<span class="type">U</span>](f: <span class="type">Elem</span> =&gt; <span class="type">U</span>) :<span class="type">Unit</span></span><br></pre></td></tr></table></figure>

<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> list = <span class="type">List</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line">list: <span class="type">List</span>[<span class="type">Int</span>] = <span class="type">List</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line">scala&gt; <span class="keyword">val</span> f=(i:<span class="type">Int</span>)=&gt;println(i)</span><br><span class="line">f: <span class="type">Int</span> =&gt; <span class="type">Unit</span> = &lt;function1&gt;</span><br><span class="line">scala&gt; list.foreach(f)</span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="number">2</span></span><br><span class="line"><span class="number">3</span></span><br></pre></td></tr></table></figure>

<p>简化写法：“list foreach(i=&gt;println(i))”或“list foreach println”</p>
<p>所有容器的根为Traverable特质，表示可遍历的，它为所有的容器类定义了抽象的foreach方法</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> university = <span class="type">Map</span>(<span class="string">&quot;XMU&quot;</span> -&gt;<span class="string">&quot;Xiamen University&quot;</span>, <span class="string">&quot;THU&quot;</span> -&gt;<span class="string">&quot;Tsinghua University&quot;</span>,<span class="string">&quot;PKU&quot;</span>-&gt;<span class="string">&quot;Peking University&quot;</span>)</span><br><span class="line">university: scala.collection.mutable.<span class="type">Map</span>[<span class="type">String</span>,<span class="type">String</span>] = ...</span><br><span class="line">scala&gt; university foreach&#123;kv =&gt; println(kv._1+<span class="string">&quot;:&quot;</span>+kv._2)&#125;</span><br><span class="line"><span class="type">XMU</span>:<span class="type">Xiamen</span> <span class="type">University</span></span><br><span class="line"><span class="type">THU</span>:<span class="type">Tsinghua</span> <span class="type">University</span></span><br><span class="line"><span class="type">PKU</span>:<span class="type">Peking</span> <span class="type">University</span></span><br></pre></td></tr></table></figure>

<p>简化写法：</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">university foreach&#123;x=&gt;x <span class="keyword">match</span> &#123;<span class="keyword">case</span> (k,v) =&gt; println(k+<span class="string">&quot;:&quot;</span>+v)&#125;&#125;</span><br><span class="line">university foreach&#123;<span class="keyword">case</span> (k,v) =&gt; println(k+<span class="string">&quot;:&quot;</span>+v)&#125;</span><br></pre></td></tr></table></figure>

<h3 id="映射操作"><a href="#映射操作" class="headerlink" title="映射操作"></a>映射操作</h3><ul>
<li>映射是指通过对容器中的元素进行某些运算来生成一个新的容器。两个典型的映射操作是map方法和flatMap方法</li>
<li>map方法（一对一映射）：将某个函数应用到集合中的每个元素，映射得到一个新的元素，map方法会返回一个与原容器类型大小都相同的新容器，只不过元素的类型可能不同</li>
</ul>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> books =<span class="type">List</span>(<span class="string">&quot;Hadoop&quot;</span>,<span class="string">&quot;Hive&quot;</span>,<span class="string">&quot;HDFS&quot;</span>)</span><br><span class="line">books: <span class="type">List</span>[<span class="type">String</span>] = <span class="type">List</span>(<span class="type">Hadoop</span>, <span class="type">Hive</span>, <span class="type">HDFS</span>)</span><br><span class="line">scala&gt; books.map(s =&gt; s.toUpperCase)</span><br><span class="line"><span class="comment">//toUpperCase方法将一个字符串中的每个字母都变成大写字母</span></span><br><span class="line">res56: <span class="type">List</span>[<span class="type">String</span>] = <span class="type">List</span>(<span class="type">HADOOP</span>, <span class="type">HIVE</span>, <span class="type">HDFS</span>)</span><br><span class="line">scala&gt; books.map(s =&gt; s.length) <span class="comment">//将字符串映射到它的长度</span></span><br><span class="line">res57: <span class="type">List</span>[<span class="type">Int</span>] = <span class="type">List</span>(<span class="number">6</span>, <span class="number">4</span>, <span class="number">4</span>) <span class="comment">//新列表的元素类型为Int</span></span><br></pre></td></tr></table></figure>

<ul>
<li>flatMap方法（一对多映射）：将某个函数应用到容器中的元素时，对每个元素都会返回一个容器（而不是一个元素），然后，flatMap把生成的多个容器“拍扁”成为一个容器并返回。返回的容器与原容器类型相同，但大小可能不同，其中元素的类型也可能不同</li>
</ul>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">scala&gt; books flatMap (s =&gt; s.toList)</span><br><span class="line">res58: <span class="type">List</span>[<span class="type">Char</span>] = <span class="type">List</span>(<span class="type">H</span>, a, d, o, o, p, <span class="type">H</span>, i, v, e, <span class="type">H</span>, <span class="type">D</span>, <span class="type">F</span>, <span class="type">S</span>)</span><br></pre></td></tr></table></figure>

<h3 id="过滤操作"><a href="#过滤操作" class="headerlink" title="过滤操作"></a>过滤操作</h3><ul>
<li>过滤：遍历一个容器，从中获取满足指定条件的元素，返回一个新的容器</li>
<li>filter方法：接受一个返回布尔值的函数f作为参数，并将f作用到每个元素上，将f返回真值的元素组成一个新容器返回</li>
</ul>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> university = <span class="type">Map</span>(<span class="string">&quot;XMU&quot;</span> -&gt;<span class="string">&quot;Xiamen University&quot;</span>, <span class="string">&quot;THU&quot;</span> -&gt;<span class="string">&quot;Tsinghua University&quot;</span>,<span class="string">&quot;PKU&quot;</span>-&gt;<span class="string">&quot;Peking University&quot;</span>,<span class="string">&quot;XMUT&quot;</span>-&gt;<span class="string">&quot;Xiamen University of Technology&quot;</span>)</span><br><span class="line">university: scala.collection.immutable.<span class="type">Map</span>[<span class="type">String</span>,<span class="type">String</span>] = ...</span><br><span class="line"> </span><br><span class="line"><span class="comment">//过滤出值中包含“Xiamen”的元素，contains为String的方法</span></span><br><span class="line">scala&gt; <span class="keyword">val</span> xmus = university filter &#123;kv =&gt; kv._2 contains <span class="string">&quot;Xiamen&quot;</span>&#125;</span><br><span class="line">universityOfXiamen: scala.collection.immutable.<span class="type">Map</span>[<span class="type">String</span>,<span class="type">String</span>] = <span class="type">Map</span>(<span class="type">XMU</span> -&gt; <span class="type">Xiamen</span> <span class="type">University</span>, <span class="type">XMUT</span> -&gt; <span class="type">Xiamen</span> <span class="type">University</span> of <span class="type">Technology</span>)</span><br><span class="line"> </span><br><span class="line">scala&gt; <span class="keyword">val</span> l=<span class="type">List</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>) filter &#123;_%<span class="number">2</span>==<span class="number">0</span>&#125;</span><br><span class="line"><span class="comment">//使用了占位符语法，过滤能被2整除的元素</span></span><br><span class="line">l: <span class="type">List</span>[<span class="type">Int</span>] = <span class="type">List</span>(<span class="number">2</span>, <span class="number">4</span>, <span class="number">6</span>)</span><br></pre></td></tr></table></figure>

<h3 id="规约操作"><a href="#规约操作" class="headerlink" title="规约操作"></a>规约操作</h3><ul>
<li>规约操作是对容器元素进行两两运算，将其“规约”为一个值</li>
<li>reduce方法：接受一个二元函数f作为参数，首先将f作用在某两个元素上并返回一个值，然后再将f作用在上一个返回值和容器的下一个元素上，再返回一个值，依此类推，最后容器中的所有值会被规约为一个值</li>
</ul>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> list =<span class="type">List</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>)</span><br><span class="line">list: <span class="type">List</span>[<span class="type">Int</span>] = <span class="type">List</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>)</span><br><span class="line">scala&gt;  list.reduce(_ + _) <span class="comment">//将列表元素累加，使用了占位符语法</span></span><br><span class="line">res16: <span class="type">Int</span> = <span class="number">15</span></span><br><span class="line">scala&gt;  list.reduce(_ * _) <span class="comment">//将列表元素连乘</span></span><br><span class="line">res17: <span class="type">Int</span> = <span class="number">120</span></span><br><span class="line">scala&gt; list map (_.toString) reduce ((x,y)=&gt;<span class="string">s&quot;f(<span class="subst">$x</span>,<span class="subst">$y</span>)&quot;</span>)</span><br><span class="line">res5: <span class="type">String</span> = f(f(f(f(<span class="number">1</span>,<span class="number">2</span>),<span class="number">3</span>),<span class="number">4</span>),<span class="number">5</span>) <span class="comment">//f表示传入reduce的二元函数</span></span><br></pre></td></tr></table></figure>

<ul>
<li>reduceLeft和reduceRight：前者从左到右进行遍历，后者从右到左进行遍历</li>
</ul>
<p><img data-src="scala-learning/image-20191216103846484.png" alt="image-20191216103846484"></p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> list = <span class="type">List</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>)</span><br><span class="line">list: <span class="type">List</span>[<span class="type">Int</span>] = <span class="type">List</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>)</span><br><span class="line">scala&gt; list reduceLeft &#123;_-_&#125;</span><br><span class="line">res24: <span class="type">Int</span> = <span class="number">-13</span></span><br><span class="line">scala&gt; list reduceRight &#123;_-_&#125;</span><br><span class="line">res25: <span class="type">Int</span> = <span class="number">3</span></span><br><span class="line">scala&gt; <span class="keyword">val</span> s = list map (_.toString)  <span class="comment">//将整型列表转换成字符串列表</span></span><br><span class="line">s: <span class="type">List</span>[<span class="type">String</span>] = <span class="type">List</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>)</span><br><span class="line">scala&gt; s reduceLeft &#123;(accu,x)=&gt;<span class="string">s&quot;(<span class="subst">$accu</span>-<span class="subst">$x</span>)&quot;</span>&#125;</span><br><span class="line">res28: <span class="type">String</span> = ((((<span class="number">1</span><span class="number">-2</span>)<span class="number">-3</span>)<span class="number">-4</span>)<span class="number">-5</span>)<span class="comment">//list reduceLeft&#123;_-_&#125;的计算过程</span></span><br><span class="line">scala&gt; s reduceRight &#123;(x,accu)=&gt;<span class="string">s&quot;(<span class="subst">$x</span>-<span class="subst">$accu</span>)&quot;</span>&#125;</span><br><span class="line">res30: <span class="type">String</span> = (<span class="number">1</span>-(<span class="number">2</span>-(<span class="number">3</span>-(<span class="number">4</span><span class="number">-5</span>))))<span class="comment">//list reduceRight&#123;_-_&#125;的计算过程</span></span><br></pre></td></tr></table></figure>

<ul>
<li>fold方法：一个双参数列表的函数，从提供的初始值开始规约。第一个参数列表接受一个规约的初始值，第二个参数列表接受与reduce中一样的二元函数参数</li>
<li>foldLeft和foldRight：前者从左到右进行遍历，后者从右到左进行遍历</li>
</ul>
<p><img data-src="scala-learning/image-20191216103918550.png" alt="image-20191216103918550"></p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> list =<span class="type">List</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>)</span><br><span class="line">list: <span class="type">List</span>[<span class="type">Int</span>] = <span class="type">List</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>)</span><br><span class="line">scala&gt; list.fold(<span class="number">10</span>)(_*_)</span><br><span class="line">res32: <span class="type">Int</span> = <span class="number">1200</span></span><br><span class="line">scala&gt; (list fold <span class="number">10</span>)(_*_) <span class="comment">//fold的中缀调用写法</span></span><br><span class="line">res33: <span class="type">Int</span> = <span class="number">1200</span></span><br><span class="line">scala&gt; (list foldLeft <span class="number">10</span>)(_-_)<span class="comment">//计算顺序(((((10-1)-2)-3)-4)-5)</span></span><br><span class="line">res34: <span class="type">Int</span> = <span class="number">-5</span> </span><br><span class="line">scala&gt; (list foldRight <span class="number">10</span>)(_-_) <span class="comment">//计算顺序(1-(2-(3-(4-(5-10)))))</span></span><br><span class="line">res35: <span class="type">Int</span> = <span class="number">-7</span></span><br></pre></td></tr></table></figure>

<h2 id="函数式编程实例WordCount"><a href="#函数式编程实例WordCount" class="headerlink" title="函数式编程实例WordCount"></a>函数式编程实例WordCount</h2><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.<span class="type">File</span></span><br><span class="line"><span class="keyword">import</span> scala.io.<span class="type">Source</span></span><br><span class="line"><span class="keyword">import</span> collection.mutable.<span class="type">Map</span></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">WordCount</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]) &#123;</span><br><span class="line">        <span class="keyword">val</span> dirfile=<span class="keyword">new</span> <span class="type">File</span>(<span class="string">&quot;testfiles&quot;</span>)</span><br><span class="line">        <span class="keyword">val</span> files  = dirfile.listFiles</span><br><span class="line">        <span class="keyword">val</span> results = <span class="type">Map</span>.empty[<span class="type">String</span>,<span class="type">Int</span>]</span><br><span class="line">        <span class="keyword">for</span>(file &lt;-files) &#123;</span><br><span class="line">            <span class="keyword">val</span> data= <span class="type">Source</span>.fromFile(file)</span><br><span class="line">            <span class="keyword">val</span> strs =data.getLines.flatMap&#123;s =&gt;s.split(<span class="string">&quot; &quot;</span>)&#125;</span><br><span class="line">            strs foreach &#123; word =&gt;</span><br><span class="line">                <span class="keyword">if</span> (results.contains(word))</span><br><span class="line">                results(word)+=<span class="number">1</span> <span class="keyword">else</span>  results(word)=<span class="number">1</span></span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        results foreach&#123;<span class="keyword">case</span> (k,v) =&gt; println(<span class="string">s&quot;<span class="subst">$k</span>:<span class="subst">$v</span>&quot;</span>)&#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>行1-3：导入需要的类；<br>行6：建立一个File对象，这里假设当前文件夹下有一个testfiles文件夹，且里面包含若干文本文件；<br>行7：调用File对象的listFiles方法，得到其下所有文件对象构成的数组，files的类型为Array[java.io.File]；<br>行8：建立一个可变的空的映射（Map）对象results，保存统计结果。映射中的条目都是一个(key,value)键值对，其中，key是单词，value是单词出现的次数；<br>行9：通过for循环对文件对象进行循环，分别处理各个文件；<br>行10：从File对象建立Source对象（参见1.2节介绍），方便文件的读取；<br>行11：getLines方法返回文件各行构成的迭代器对象，类型为Iterator[String]，flatMap进一步将每一行字符串拆分成单词，再返回所有这些单词构成的新字符串迭代器；<br>行12-15：对上述的字符串迭代器进行遍历，在匿名函数中，对于当前遍历到的某个单词，如果这个单词以前已经统计过，就把映射results中以该单词为key的映射条目的value增加1。如果以前没有被统计过，则为这个单词新创建一个映射条目，只需要直接对相应的key进行赋值，就实现了添加新的映射条目；<br>行17：对Map对象results进行遍历，输出统计结果。</p>
]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>Scala</tag>
      </tags>
  </entry>
</search>
